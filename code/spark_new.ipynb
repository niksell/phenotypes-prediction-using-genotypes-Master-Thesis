{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libs\n",
    "import findspark\n",
    "findspark.init(\"/home/antonis/spark-2.3.0-bin-hadoop2.7\")\n",
    "\n",
    "import os.path\n",
    "import pandas\n",
    "import math\n",
    "import time\n",
    "\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Output import Output\n",
    "from IO.Input import Input\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import countDistinct,avg,stddev\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                               OneHotEncoder , StringIndexer)\n",
    "import DataSet.SnpsSelection as s\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def writeCoef(path,snpsIds,sc,idToName,name = None):\n",
    "        \n",
    "    if not name:\n",
    "        print(\"give a name to file\")\n",
    "        return\n",
    "        \n",
    "    p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt \"  \n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(p):\n",
    "            \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "        i += 1\n",
    "        \n",
    "    snps = []\n",
    "    for i in range(len(snpsIds)):\n",
    "        s = snpsIds[i]\n",
    "        #snps.append(idToName[s])\n",
    "        snps.append(s)\n",
    "            \n",
    "    print(\"snpsIds = \",len(snpsIds))\n",
    "    print(\"idToName = \",len(idToName))\n",
    "        \n",
    "    write = open(p,'w')\n",
    "    for i in range(len(snps)):\n",
    "            \n",
    "        write.write(str(snps[i])+'\\t'+str(sc[i])+'\\n')\n",
    "            \n",
    "    write.close()\n",
    "\n",
    "\n",
    "def calcCoeff(path,coefs, columns):\n",
    "    \n",
    "    ids = {}\n",
    "    ids['coef']={}\n",
    "   \n",
    "    print(\"before = \",len(set(coefs)))\n",
    "    #for i in range(len(coefs)):\n",
    "     #   coefs[i] = abs(coefs[i])\n",
    "\n",
    "    print(\"after = \",len(set(coefs)))\n",
    "\n",
    "    idToName = {}\n",
    "    nameToId = {}\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]] = []\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]].append(i)\n",
    "        idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "    ids['coef']['nameToId'] = nameToId\n",
    "    ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "    sc = sorted(coefs,reverse=True)\n",
    "\n",
    "    top_30 = []\n",
    "\n",
    "    for i in range(30):\n",
    "\n",
    "        snp = ids['coef']['nameToId'][sc[i]][0]\n",
    "        ids['coef']['nameToId'][sc[i]].remove(snp)\n",
    "        top_30.append(columns[snp])\n",
    "     #   top_30.append(snp)\n",
    "\n",
    "    #snpReduc['low'] = top_30\n",
    "    writeCoef(path,top_30,sc,columns, 'mycutoffabs')\n",
    "    \n",
    "    \n",
    "def showMetrics(c,value=1):\n",
    "    \n",
    "    predictionAndLabels = c.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    print(\"confusion matrix = \", metrics.confusionMatrix().toArray())\n",
    "\n",
    "    print(\"accuracy = \", metrics.accuracy)\n",
    "    print(\"recal = \", metrics.recall(value))\n",
    "    print(\"precision = \", metrics.precision(value))\n",
    "    print(\"f1 = \", metrics.fMeasure(1.0))\n",
    "    \n",
    "    \n",
    "def showMyMetric(results,v1 = 1,v2 = 0):\n",
    "    \n",
    "    if v1 == v2:\n",
    "        print(\"wrong values!!!v1 is the same with v2!!!!\")\n",
    "       \n",
    "    \n",
    "    r = results.rdd\n",
    "    r3 = r.collect()\n",
    "\n",
    "    same0 = 0\n",
    "    same1 = 0\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    sumall = 0\n",
    "    for i in r3:\n",
    "\n",
    "        if i[v1] == 0:\n",
    "            sum0 += 1\n",
    "            if i[v2] == 0:\n",
    "                same0 += 1\n",
    "        elif i[v1] == 1:\n",
    "            sum1 += 1\n",
    "            if i[v2] == 1:\n",
    "                same1 += 1\n",
    "        sumall += 1\n",
    "\n",
    "    print('sum0 = ', sum0)\n",
    "    print('sum1 = ', sum1)\n",
    "    print('same0 = ', same0)\n",
    "    print('same1 = ', same1)\n",
    "    print('all = ', sumall)\n",
    "    print('all2 = ', sum0+sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = (SparkConf()\n",
    "    .set(\"spark.driver.maxResultSize\", \"20g\")\n",
    "    .set('spark_executor_cores',\"3\")\n",
    "    .set('spark.graphx.pregel.checkpointInterval','-1')\n",
    "    .set('spark.network.timeout','100000000')\n",
    "    .set('spark.executor.heartbeatInterval','10000000'))\n",
    "\n",
    "#spark = SparkSession.builder.appName('melanoma').getOrCreate()\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/'\n",
    "\n",
    "#pathSnp = '/media/antonis/red/newSet/maf/maf = 0.05/assoc/pvalue = 0.001/snpCodeTest.csv'\n",
    "#pathSnp = '/media/antonis/red/newSet/maf/maf = 0.05/assoc/pvalue = 0.01/snp2.txt'\n",
    "pathSnp = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/snp2.txt'\n",
    "#pathSnp = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/snpCodeTest1.csv'\n",
    "\n",
    "#pathSnp = '/media/antonis/Antonis_Moulopoulos/newSet/pvalue = 0.001/snp1.txt'\n",
    "#pathSnp = '/media/antonis/Antonis_Moulopoulos/newdata/maf = 0.05/pvalue = 0.001/snp2.txt'\n",
    "\n",
    "\n",
    "data = spark.read.option(\"maxColumns\", 80000).csv(pathSnp,inferSchema=True,header=True)\n",
    "data=data.withColumnRenamed('TARGET','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data columns =  12144\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"data columns = \",len(data.columns))\n",
    "\n",
    "features = []\n",
    "for i in data.columns:\n",
    "    if 'rs' in i:\n",
    "        features.append(i)\n",
    "        break\n",
    "print(len(features))\n",
    "\n",
    "#print((features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'label'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[len(data.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assempler = VectorAssembler(inputCols=features,outputCol='features')\n",
    "output = assempler.transform(data)\n",
    "final_data = output.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "final_data1 = final.select('features')\n",
    "corr = Correlation.corr(final_data1, \"features\")\n",
    "corr = corr.head()[0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpsRed = []\n",
    "snpsRed = s.lowCorrelation(corr, threshold=0.7, up=100, down=99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpsRed1 = []\n",
    "for i in snpsRed:\n",
    "    snpsRed1.append(features[i])\n",
    "\n",
    "assempler = VectorAssembler(inputCols=snpsRed1,outputCol='snpsRed')\n",
    "output = assempler.transform(data)\n",
    "final_data = output.select('snpsRed','label')\n",
    "#final_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select('snpsRed','label')\n",
    "final_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0,test_data = final_data.randomSplit([0.9,0.1],seed=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label0 =  240019\n",
      "label1 =  2157\n",
      "l1 =  1186.35\n",
      "train =  2285\n",
      "test =  239891\n",
      "all =  242176\n",
      "final_data =  242176\n"
     ]
    }
   ],
   "source": [
    "train1 = final_data.filter(\"label == 1\")\n",
    "train0 = final_data.filter(\"label == 0\")\n",
    "\n",
    "label1 = train1.count()\n",
    "label0 = train0.count()\n",
    "\n",
    "l1 = (label1/2) + ((label1/2) * 0.1)\n",
    "\n",
    "x = (l1 * 100) / label0\n",
    "\n",
    "\n",
    "x = x / 100\n",
    "\n",
    "\n",
    "tr1,tr11 = train1.randomSplit([0.5,0.5],seed=11)\n",
    "tr0,tr00 = train0.randomSplit([x,1-x],seed=11)\n",
    "\n",
    "train0 = tr0.union(tr1)\n",
    "test_data = tr00.union(tr11)\n",
    "\n",
    "t0 = train0.count()\n",
    "t1 = test_data.count()\n",
    "\n",
    "print(\"label0 = \",label0)\n",
    "print('label1 = ', label1)\n",
    "print(\"l1 = \",l1)\n",
    "print('train = ', t0)\n",
    "print('test = ', t1)\n",
    "print('all = ', t0 + t1)\n",
    "print('final_data = ',final_data.count())\n",
    "\n",
    "#train0,test_data = final_data.randomSplit([0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features',labelCol='label',maxIter=10)\n",
    "lr_model = log_reg.fit(train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7909133853963526'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = lr_model.transform(test_data)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "print(AUC)\n",
    "'''0.7909133853963526'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
