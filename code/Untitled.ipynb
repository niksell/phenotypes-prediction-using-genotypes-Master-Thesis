{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\anton\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import random\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Output import Output\n",
    "from IO.Input import Input\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "\n",
    "\n",
    "def setIdToName(aList):\n",
    "    \n",
    "    ids = {}\n",
    "    nameToId = {}\n",
    "    idToName = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in aList:\n",
    "        \n",
    "        nameToId[i] = count\n",
    "        idToName[count] = i\n",
    "        count += 1\n",
    "        \n",
    "    ids['nameToId'] = nameToId\n",
    "    ids['idToName'] = idToName\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    print(\"ok1\")\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    \n",
    "    \n",
    "    n = confusion_matrix.sum()\n",
    "    print(\"n  = \",n)\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    \n",
    "    print(\"val = \",phi2corr)\n",
    "    \n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "\n",
    "def cramers_stat(confusion_matrix):\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    \n",
    "    return np.sqrt(chi2 / (n*(min(confusion_matrix.shape)-1)))\n",
    "\n",
    "\n",
    "def createCrammerTable(X):\n",
    "    \n",
    "    cram = np.zeros((len(X.T),len(X.T)), dtype = np.float32)\n",
    "    \n",
    "    y = np.zeros((2,len(X)), dtype = np.int32)\n",
    "    \n",
    "    for i in range(len(X.T)):\n",
    "        print(\"i = \",i)\n",
    "        for j in range(i,len(X.T)):\n",
    "            \n",
    "            y[0,:] = X[:,i]\n",
    "            y[1,:] = X[:,j]\n",
    "            \n",
    "            v = cramers_stat(y)\n",
    "            \n",
    "            cram[i,j] = v\n",
    "            cram[j,i] = v\n",
    "            \n",
    "    return cram\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def tables(sampleX,sampleY,k):\n",
    "  \n",
    "    samples = {}\n",
    "    \n",
    "    for run in range(1,k+1):\n",
    "        \n",
    "        d1 = {}\n",
    "        \n",
    "\n",
    "        dataTestX = sampleX[run]\n",
    "        dataTestY = sampleY[run]\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        for i in sampleX.keys():\n",
    "\n",
    "            if i != run:\n",
    "\n",
    "                n += len(sampleX[i])\n",
    "\n",
    "        dataTrainX = np.zeros((n,len(sampleX[1].T)),dtype = int)\n",
    "        dataTrainY = np.zeros((n,),dtype = int)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sample in sampleX.keys():\n",
    "\n",
    "            if sample != run:\n",
    "\n",
    "                 for i in range(len(sampleX[sample])):\n",
    "                    for j in range(len(sampleX[sample].T)):\n",
    "                        dataTrainX[count,j] = sampleX[sample][i,j]\n",
    "\n",
    "                    dataTrainY[count] = sampleY[sample][i]\n",
    "                    count += 1\n",
    "\n",
    "        d1['trainX'] = dataTrainX\n",
    "        d1['trainY'] = dataTrainY\n",
    "        d1['testX'] = dataTestX\n",
    "        d1['testY'] = dataTestY\n",
    "        \n",
    "        samples[run] = d1\n",
    "    \n",
    "    return samples\n",
    "    \n",
    "def kSampleData(k,X,Y):\n",
    "    \n",
    "    x = int (len(X) / k)\n",
    "    allElements = np.zeros((len(X),),dtype = int)\n",
    "    \n",
    "    count1 = 1\n",
    "    sampleX = {}\n",
    "    sampleY = {}\n",
    "   \n",
    "    \n",
    "    while count1 <= k:\n",
    "        count2 = 1\n",
    "        sampleData = []\n",
    "        \n",
    "        if count1 == k:\n",
    "            x =  len(X) - ((k-1) * x)\n",
    "        \n",
    "        dataX = np.zeros((x,len(X.T)),dtype = int)\n",
    "        dataY = np.zeros((x,),dtype = int)\n",
    "        \n",
    "        while count2 <= x:\n",
    "            \n",
    "            aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            while allElements[aRand] == 1:\n",
    "                \n",
    "                aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            allElements[aRand] = 1\n",
    "            sampleData.append(aRand)\n",
    "            count2 += 1\n",
    "            \n",
    "        for i in range(len(sampleData)):\n",
    "            for j in range(len(X.T)):\n",
    "                dataX[i,j] = X[sampleData[i],j]\n",
    "            \n",
    "            dataY[i] = Y[sampleData[i]]\n",
    "            \n",
    "        sampleX[count1] = dataX\n",
    "        sampleY[count1] = dataY\n",
    "        count1 +=1\n",
    "        \n",
    "    return tables(sampleX,sampleY,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createNewTable(snps,X):\n",
    "    \n",
    "    newX = np.zeros((len(X),len(snps)),dtype = np.int32)\n",
    "    count=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(newX)):\n",
    "        for j in range(len(newX.T)):\n",
    "            newX[i,j] = -1\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        \n",
    "        newX[:,i] = X[:,snps[i]]\n",
    "        \n",
    "        \n",
    "    print(\"new shape = \",newX.shape)\n",
    "            \n",
    "    return newX \n",
    "\n",
    "\n",
    "\n",
    "def featuresIds(oldSnps,snps):\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        features[i] = snps[i]\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def crossValidiation(X, Y, k = 1, continious = True, classifier = None,OLS = False,Logistic = False):\n",
    "    \n",
    "    if not classifier:\n",
    "        print(\"wrong!!!!!!! you have to choise a classifier\")\n",
    "        return\n",
    "    \n",
    "    results = {}\n",
    "    accuracy = {}\n",
    "    auc = {}\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    f1Score = {}\n",
    "    \n",
    "    sumResults = 0.0\n",
    "    sumAccuracy = 0.0\n",
    "    sumAuc = 0.0\n",
    "    sumRecall = 0.0\n",
    "    sumPrecision = 0.0\n",
    "    sumF1Score = 0.0\n",
    "    \n",
    "    samples = kSampleData(k,X,Y)\n",
    "    \n",
    "    for run in range(1, k + 1):\n",
    "        \n",
    "        trainX = samples[run]['trainX']\n",
    "        trainY = samples[run]['trainY']\n",
    "        \n",
    "        #trainX,trainY = balancedData(trainX,trainY)\n",
    "        \n",
    "        testX = samples[run]['testX']\n",
    "        testY = samples[run]['testY']\n",
    "        \n",
    "        \n",
    "        if OLS:\n",
    "            classifier = sm.OLS(trainY,trainX)\n",
    "            yPredict = classifier.fit().predict(testX)\n",
    "        else:\n",
    "\n",
    "            classifier.fit(trainX, trainY)\n",
    "            yPredict = classifier.predict(testX)\n",
    "        \n",
    "        if continious:\n",
    "            \n",
    "            for i in range(len(yPredict)):\n",
    "                \n",
    "                if (abs(0 - yPredict[i]) - abs(1 - yPredict[i])) <= 1e-10 :\n",
    "                    yPredict[i] = 0\n",
    "                else:\n",
    "                    yPredict[i] = 1\n",
    "                    \n",
    "        if Logistic:\n",
    "            \n",
    "            probabilities = classifier.predict_proba(testX)\n",
    "            \n",
    "            for i in range(len(probabilities)):\n",
    "                if probabilities[i][1] >= 0.8:\n",
    "                    yPredict[i] = 1\n",
    "                else:\n",
    "                    yPredict[i] = 0\n",
    "          \n",
    "        accuracy[run] = metrics.accuracy_score(testY,yPredict)#(yPredict,testY)#\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(testY,yPredict)\n",
    "        auc[run] = metrics.auc(fpr,tpr)\n",
    "        recall[run] = metrics.recall_score(testY,yPredict)\n",
    "        precision[run] = metrics.precision_score(testY,yPredict)\n",
    "        f1Score[run] = f1_score(testY, yPredict, average='binary')\n",
    "        \n",
    "    \n",
    "    for i in accuracy.keys():\n",
    "        sumAccuracy = sumAccuracy + accuracy[i]\n",
    "        sumAuc = sumAuc + auc[i]\n",
    "        sumRecall = sumRecall + recall[i]\n",
    "        sumPrecision = sumPrecision + precision[i]\n",
    "        sumF1Score = sumF1Score + f1Score[i]\n",
    "    \n",
    "    results['accuracy'] = sumAccuracy / k\n",
    "    results['auc'] = sumAuc / k\n",
    "    results['recall'] = sumRecall / k\n",
    "    results['precision'] = sumPrecision / k\n",
    "    results['f1'] = sumF1Score / k\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def writeCoef(path,snpsIds,sc,idToName,name = None):\n",
    "        \n",
    "        if not name:\n",
    "            print(\"give a name to file\")\n",
    "            return\n",
    "        \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt \"  \n",
    "    \n",
    "        i=1\n",
    "        while os.path.exists(p):\n",
    "            \n",
    "            p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "            i += 1\n",
    "        \n",
    "        snps = []\n",
    "        for i in range(len(snpsIds)):\n",
    "            s = snpsIds[i]\n",
    "            snps.append(idToName[s])\n",
    "            \n",
    "        print(\"snpsIds = \",len(snpsIds))\n",
    "        print(\"idToName = \",len(idToName))\n",
    "        \n",
    "        write = open(p,'w')\n",
    "        for i in range(len(snps)):\n",
    "            \n",
    "            write.write(str(snps[i])+'\\t'+str(sc[i])+'\\n')\n",
    "            \n",
    "        write.close()\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('C:\\\\Users\\\\anton\\\\OneDrive\\\\Υπολογιστής\\\\d1.txt','r')\n",
    "\n",
    "columns = df.readline().split(',')\n",
    "lines = df.readlines()\n",
    "\n",
    "table = np.zeros((len(lines),len(columns)), dtype = np.int32)\n",
    "\n",
    "#table = np.zeros((100,100), dtype = np.int32)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    \n",
    "    row = lines[i].split(',')\n",
    "    for j in range(len(row)):\n",
    "        \n",
    "        table[i,j] = int(row[j])\n",
    "        \n",
    "'''for i in range(100):\n",
    "    \n",
    "    row = lines[i].split(',')\n",
    "    for j in range(100):\n",
    "        \n",
    "        table[i,j] = int(row[j])\n",
    "        '''\n",
    "        \n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=table, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cretaCramm():\n",
    "    \n",
    "    '''for i in range(len(df.columns)):\n",
    "    \n",
    "    for j in range(i,len(df.columns)):\n",
    "        \n",
    "        c1 = df.columns[i]\n",
    "        c2 = df.columns[j]\n",
    "        \n",
    "        y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "        \n",
    "        cr[i,j] =cramers_stat(y)\n",
    "        cr[j,i] =cramers_stat(y)'''\n",
    "\n",
    "\n",
    "    for i in range(100):\n",
    "       \n",
    "        for j in range(i,100):\n",
    "\n",
    "            c1 = df.columns[i]\n",
    "            c2 = df.columns[j]\n",
    "\n",
    "            y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "\n",
    "            cr[i,j] =cramers_stat(y)\n",
    "            cr[j,i] =cramers_stat(y)\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def cretaCramm1():\n",
    "    \n",
    "    '''for i in range(len(df.columns)):\n",
    "    \n",
    "    for j in range(i,len(df.columns)):\n",
    "        \n",
    "        c1 = df.columns[i]\n",
    "        c2 = df.columns[j]\n",
    "        \n",
    "        y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "        \n",
    "        cr[i,j] =cramers_stat(y)\n",
    "        cr[j,i] =cramers_stat(y)'''\n",
    "\n",
    "\n",
    "    for i in range(50):\n",
    "       \n",
    "        for j in range(i,100):\n",
    "\n",
    "            c1 = df.columns[i]\n",
    "            c2 = df.columns[j]\n",
    "\n",
    "            y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "\n",
    "            cr[i,j] =cramers_stat(y)\n",
    "            cr[j,i] =cramers_stat(y)\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def cretaCramm2():\n",
    "    \n",
    "    '''for i in range(len(df.columns)):\n",
    "    \n",
    "    for j in range(i,len(df.columns)):\n",
    "        \n",
    "        c1 = df.columns[i]\n",
    "        c2 = df.columns[j]\n",
    "        \n",
    "        y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "        \n",
    "        cr[i,j] =cramers_stat(y)\n",
    "        cr[j,i] =cramers_stat(y)'''\n",
    "\n",
    "\n",
    "    for i in range(50,100):\n",
    "       \n",
    "        for j in range(i,100):\n",
    "\n",
    "            c1 = df.columns[i]\n",
    "            c2 = df.columns[j]\n",
    "\n",
    "            y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "\n",
    "            cr[i,j] =cramers_stat(y)\n",
    "            cr[j,i] =cramers_stat(y)\n",
    "            \n",
    "            \n",
    "def cretaCrammDok(item):\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(item['start'],item['end']):\n",
    "       \n",
    "        cr[i,i] = 1.0\n",
    "        for j in range(i+1,len(df.columns)):\n",
    "\n",
    "            c1 = df.columns[i]\n",
    "            c2 = df.columns[j]\n",
    "\n",
    "            y = pd.crosstab(df[c1], df[c2]).as_matrix()\n",
    "\n",
    "            cr[i,j] =cramers_stat(y)\n",
    "            cr[j,i] =cramers_stat(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = np.zeros((len(df.columns),len(df.columns)),dtype = np.float16)\n",
    "\n",
    "for i in range(len(cr)):\n",
    "    \n",
    "    for j in range(len(cr.T)):\n",
    "        \n",
    "        cr[i,j] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12002, 12002)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "class myThread1 (threading.Thread):\n",
    "    def __init__(self, threadID, name, counter,par):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.counter = counter\n",
    "        self.par = par\n",
    "        \n",
    "    def run(self):\n",
    "      #  print (\"Starting \" + self.name)\n",
    "        cretaCrammDok(self.par)\n",
    "       # print (\"Exiting \" + self.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "k = 5000\n",
    "y = int (len(columns)/5000)\n",
    "\n",
    "items = {}\n",
    "\n",
    "for i in range(1,k+1):\n",
    "    \n",
    "    items[i] = {}\n",
    "    items[i]['start'] = (i-1)*y\n",
    "    items[i]['end'] = i*y\n",
    "    \n",
    "items[k] = {}\n",
    "items[k]['start'] = (k-1)*y\n",
    "items[k]['end'] = len(columns)\n",
    "\n",
    "print(len(items.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "count = 1\n",
    "for i in items.keys():\n",
    "\n",
    "    thread = myThread1(count, \"Thread-\"+str(count), count,items[i])\n",
    "    threads.append(thread)\n",
    "    count += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "t1 = timeit.default_timer()\n",
    "\n",
    "for i in threads:\n",
    "    i.start()\n",
    "    \n",
    "for i in threads:\n",
    "    i.join()\n",
    "    \n",
    "print('tghreads are finished')\n",
    "    \n",
    "t2 = timeit.default_timer()\n",
    "\n",
    "print (t2 - t1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
