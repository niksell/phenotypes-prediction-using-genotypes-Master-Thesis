{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libs\n",
    "import findspark\n",
    "findspark.init(\"/home/antonis/spark-2.3.0-bin-hadoop2.7\")\n",
    "\n",
    "import os.path\n",
    "import pandas\n",
    "import math\n",
    "import time\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Output import Output\n",
    "from IO.Input import Input\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import countDistinct,avg,stddev\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                               OneHotEncoder , StringIndexer)\n",
    "import DataSet.SnpsSelection as s\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "\n",
    "\n",
    "def writeCoef(path,snpsIds,sc,idToName,corr, name = None):\n",
    "        \n",
    "    if not name:\n",
    "        print(\"give a name to file\")\n",
    "        return\n",
    "        \n",
    "    p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt \"  \n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(p):\n",
    "            \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "        i += 1\n",
    "        \n",
    "    snps = []\n",
    "    for i in range(len(snpsIds)):\n",
    "        s = snpsIds[i]\n",
    "        #snps.append(idToName[s])\n",
    "        snps.append(s)\n",
    "            \n",
    "    print(\"snpsIds = \",len(snpsIds))\n",
    "    print(\"idToName = \",len(idToName))\n",
    "        \n",
    "    write = open(p,'w')\n",
    "    write.write(\"len = \"+str(len(sc))+'\\n')\n",
    "    write.write('corr = '+str(corr)+'\\n')\n",
    "    for i in range(len(snps)):\n",
    "            \n",
    "        write.write(str(snps[i])+'\\t'+str(sc[i])+'\\n')\n",
    "            \n",
    "    write.close()\n",
    "\n",
    "\n",
    "def calcCoeff(path,coefs, columns,corr,name = None):\n",
    "    \n",
    "    ids = {}\n",
    "    ids['coef']={}\n",
    "   \n",
    "    print(\"before = \",len(set(coefs)))\n",
    "    #for i in range(len(coefs)):\n",
    "     #   coefs[i] = abs(coefs[i])\n",
    "\n",
    "    print(\"after = \",len(set(coefs)))\n",
    "\n",
    "    idToName = {}\n",
    "    nameToId = {}\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]] = []\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]].append(i)\n",
    "        idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "    ids['coef']['nameToId'] = nameToId\n",
    "    ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "    sc = sorted(coefs,reverse=True)\n",
    "\n",
    "    top_30 = []\n",
    "\n",
    "    for i in range(30):\n",
    "\n",
    "        snp = ids['coef']['nameToId'][sc[i]][0]\n",
    "        ids['coef']['nameToId'][sc[i]].remove(snp)\n",
    "        top_30.append(columns[snp])\n",
    "     #   top_30.append(snp)\n",
    "\n",
    "    #snpReduc['low'] = top_30\n",
    "    writeCoef(path,top_30,sc,columns,corr, name = name)\n",
    "    \n",
    "    \n",
    "def showMetrics(c,value=1):\n",
    "    \n",
    "    predictionAndLabels = c.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    print(\"confusion matrix = \", metrics.confusionMatrix().toArray())\n",
    "\n",
    "    print(\"accuracy = \", metrics.accuracy)\n",
    "    print(\"recal = \", metrics.recall(value))\n",
    "    print(\"precision = \", metrics.precision(value))\n",
    "    print(\"f1 = \", metrics.fMeasure(1.0))\n",
    "    \n",
    "    \n",
    "def showMyMetric(results,v1 = 1,v2 = 0):\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if v1 == v2:\n",
    "        print(\"wrong values!!!v1 is the same with v2!!!!\")\n",
    "       \n",
    "    \n",
    "   # r = results.rdd\n",
    "    #r3 = r.collect()\n",
    "\n",
    "    r3 = results.collect()\n",
    "    \n",
    "    same0 = 0\n",
    "    same1 = 0\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    sumall = 0\n",
    "    for i in r3:\n",
    "\n",
    "        if i[v1] == 0:\n",
    "            sum0 += 1\n",
    "            if i[v2] == 0:\n",
    "                same0 += 1\n",
    "        elif i[v1] == 1:\n",
    "            sum1 += 1\n",
    "            if i[v2] == 1:\n",
    "                same1 += 1\n",
    "        sumall += 1\n",
    "\n",
    "    print('sum0 = ', sum0)\n",
    "    print('sum1 = ', sum1)\n",
    "    print('same0 = ', same0)\n",
    "    print('same1 = ', same1)\n",
    "    print('all = ', sumall)\n",
    "    print('all2 = ', sum0+sum1)\n",
    "    \n",
    "    metrics['sum0'] = sum0\n",
    "    metrics['sum1'] = sum1\n",
    "    metrics['same1'] = same1\n",
    "    metrics['same0'] = same0\n",
    "    \n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def calculateAvgMetrics(results,classLabel=1):\n",
    "    \n",
    "    metricss = {}\n",
    "    \n",
    "   # predictionAndLabels = results.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "   # metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    metrics = showMyMetric(results)\n",
    "    \n",
    "    #metrics[\"confusion_matrix\"] = metrics.confusionMatrix().toArray()\n",
    "    '''metricss[\"accuracy\"] =  metrics.accuracy\n",
    "    metricss[\"recal\"]=  metrics.recall(classLabel)\n",
    "    metricss[\"precision\"] = metrics.precision(classLabel)\n",
    "    metricss[\"f1\"] = metrics.fMeasure(float(classLabel))'''\n",
    "    \n",
    "    metricss[\"accuracy\"] = (metrics['same1'] + metrics['same0'])/ (metrics['sum1'] + metrics['sum0'])\n",
    "    metricss[\"recal\"]= (metrics['same1'])/ (metrics['sum1'])\n",
    "    metricss[\"precision\"] = (metrics['same1'] )/ (metrics['sum1']) +( metrics['sum0'] - metrics['same0'])\n",
    "    metricss[\"f1\"] = 2 * ((metricss['recal'] * metricss['precision']) / (metricss['recal'] + metricss['precision']))\n",
    "    \n",
    "    return metricss\n",
    "    \n",
    "    \n",
    "def split(numFold = 0, df = None):\n",
    "    \n",
    "    samples = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for i in range(1,numFold+1):\n",
    "        labels[i] = {}\n",
    "    \n",
    "    if numFold == 0:\n",
    "        \n",
    "        print(\"wrong!!!!! num fold is zero (0)\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    dfCount = df.count()\n",
    "    k = int (dfCount / numFold)\n",
    "    \n",
    "    print(\"df = \", dfCount)\n",
    "    print(\"k = \",k)\n",
    "\n",
    "    \n",
    "    dfsplit = df\n",
    "    \n",
    "    for i in range(1, numFold):\n",
    "        \n",
    "        x = (k*100) / dfCount\n",
    "        x = x / 100\n",
    "        \n",
    "        split1, split2 = dfsplit.randomSplit([x,1-x],seed=2018)\n",
    "    \n",
    "        labels[i]['label0'] = split1.filter('label == 0').count()\n",
    "        labels[i]['label1'] = split1.filter('label == 1').count()\n",
    "        \n",
    "        \n",
    "        dfsplit= split2\n",
    "        dfCount = dfCount - k\n",
    "        \n",
    "        samples[i] = split1\n",
    "        \n",
    "        \n",
    "    samples[numFold] = dfsplit\n",
    "    labels[numFold]['label0'] = dfsplit.filter('label == 0').count()\n",
    "    labels[numFold]['label1'] = dfsplit.filter('label == 1').count()\n",
    "    \n",
    "    return samples,labels\n",
    "\n",
    "\n",
    "def balanedData(df,label1,label0):\n",
    "    \n",
    "    #label1 = df.filter(\"label == 1\").count()\n",
    "    #label0 = df.filter(\"label == 0\").count()\n",
    "    print(\"label0 = \", label0)\n",
    "    print(\"label1 = \", label1)\n",
    "\n",
    "\n",
    "    l0 = label1 * 2\n",
    "\n",
    "    x = (l0 * 100) / label0\n",
    "\n",
    "\n",
    "    x = x / 100\n",
    "\n",
    "    print(\"label1 = \", label1)\n",
    "    print(\"l2 = \",l0)\n",
    "    print(\"label0 = \", label0)\n",
    "    print(\"x = \", x)\n",
    "    print()\n",
    "\n",
    "    t0 = df.filter('label == 0')\n",
    "    t1 = df.filter('label == 1')\n",
    "\n",
    "    train0,t2 = t0.randomSplit([x,1-x],seed = 11)\n",
    "    \n",
    "    train_data = train0.union(t1)\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def reduceDismension(train_data, test_data):\n",
    "    \n",
    "    li = len(train_data.columns)\n",
    "\n",
    "    input_data = train_data.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "    train0 = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "    input_data = None\n",
    "    \n",
    "    final_data1 = train0.select('features')\n",
    "    corr = Correlation.corr(final_data1, \"features\")\n",
    "    corr = corr.head()[0].toArray()\n",
    "\n",
    "    snpsRed = []\n",
    "    snpsRed = s.lowCorrelation(corr, threshold=0.7, up=100, down=99)#oso megalytero threshold toso perissotero omoia einai \n",
    "###############################################################################################################################\n",
    "    features = []\n",
    "    for i in range(0,len(train_data.columns)):\n",
    "        if 'rs' in train_data.columns[i] and train_data.columns[i] !='label':\n",
    "            features.append(train_data.columns[i])\n",
    "        \n",
    "    snpsRed1 = []\n",
    "    for i in snpsRed:\n",
    "        snpsRed1.append(features[i])\n",
    "\n",
    "    snpsRed1.append('label')\n",
    "\n",
    "    features = []\n",
    "    for i in range(0,len(train_data.columns)):\n",
    "        if train_data.columns[i] not in snpsRed1:\n",
    "            features.append(train_data.columns[i])\n",
    "\n",
    "\n",
    "    dok_train = train_data.drop(*features)\n",
    "    dok_test = test_data.drop(*features)\n",
    "\n",
    "    li = len(dok_train.columns)\n",
    "\n",
    "############################################################################################################################\n",
    "\n",
    "    input_data = dok_test.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "    test = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "    input_data = None\n",
    "    \n",
    "    input_data = dok_train.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "    train = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "    \n",
    "    input_data = None\n",
    "    \n",
    "    print(\"train = \",train.head()[1].toArray().shape)\n",
    "    print(\"test = \",test.head()[1].toArray().shape)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def crossVal(numFold = 0,samples = None, labels =None,classifier = None,name = None):\n",
    "    \n",
    "    avgMetrics = {}\n",
    "    avgMetrics[name] = {}\n",
    "    \n",
    "    '''if data == None:\n",
    "        \n",
    "        print(\"data not given\")\n",
    "        return'''\n",
    "    \n",
    "    if classifier == None:\n",
    "        \n",
    "        print(\"classifier not given\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    #samples = split(numFold = numFold, df = data)\n",
    "    \n",
    "    if samples == None:\n",
    "        return\n",
    "    \n",
    "    for i in range(1,numFold + 1):\n",
    "        \n",
    "        print(\"cross = \",i)\n",
    "         \n",
    "        test_data = samples['test'][i]\n",
    "        \n",
    "        '''\n",
    "        label0 = 0\n",
    "        label1 = 0\n",
    "        \n",
    "        if i <= 2:\n",
    "        \n",
    "            train_data = samples[3].union(samples[4])\n",
    "            \n",
    "            label0 = labels[3]['label0']+labels[4]['label0']\n",
    "            label1 = labels[3]['label1']+labels[4]['label1']\n",
    "            \n",
    "            s1 = 3\n",
    "            s2 = 4\n",
    "                   \n",
    "        else:\n",
    "            \n",
    "            train_data = samples[1].union(samples[2])\n",
    "            \n",
    "            label0 = labels[1]['label0']+labels[2]['label0']\n",
    "            label1 = labels[1]['label1']+labels[2]['label1']\n",
    "            \n",
    "            s1 = 1\n",
    "            s2 = 2\n",
    "            \n",
    "            \n",
    "        for j in range(1,numFold + 1):\n",
    "            \n",
    "            if j != i and j!= s2 and j != s1:\n",
    "                \n",
    "                train_data = train_data.union(samples[j])\n",
    "                label0 = label0 + labels[j]['label0']\n",
    "                label1 = label1 + labels[j]['label1']'''\n",
    "      \n",
    "      #  train,test = reduceDismension(train_data,test_data) \n",
    "        #train = balanedData(train)\n",
    "        \n",
    "        #train = balanedData(train_data,label1,label0)\n",
    "        \n",
    "        train = samples['train'][i]\n",
    "        \n",
    "        model = classifier.fit(train)\n",
    "           \n",
    "        results = model.transform(test_data)\n",
    "\n",
    "        evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "        AUC = evaluate.evaluate(results)\n",
    "        \n",
    "        \n",
    "        \n",
    "        results1 = results.select('prediction','label')\n",
    "    \n",
    "        r = calculateAvgMetrics(results1.rdd,classLabel=1)\n",
    "        r['auc'] = AUC\n",
    "        avgMetrics[name][i] = r\n",
    "    \n",
    "    return avgMetrics\n",
    "\n",
    "\n",
    "def writeResult(path,name,results=None,category='',thresh=-1, down=-1, up=-1):\n",
    "    \n",
    "    timee = time.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    folder = path + name  + \" ( \" + timee + \" ) \" + '_'\n",
    "    #file = path + name  + '.txt'\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(folder):\n",
    "        timee = time.strftime(\"%d-%m-%Y\")\n",
    "        folder = path + name + \" ( \" + timee + \" ) \" + '_' + str(i) + '_'\n",
    "       \n",
    "        i += 1\n",
    "        \n",
    "   # os.makedirs(folder)\n",
    "    \n",
    "    file = folder + name + '.txt'\n",
    "    \n",
    "    write = open(file,'w')\n",
    "    \n",
    "    write.write(timee + '\\n'+ '\\n')\n",
    "    write.write(name + '\\n')\n",
    "    write.write('threshold = ' + str(thresh) + '\\n')\n",
    "    write.write('down = ' + str(down) +'\\n')\n",
    "    write.write('up = '+ str(up) + '\\n')\n",
    "    write.write(\"Category = \" + category + '\\n')\n",
    "    for i in results.keys():\n",
    "        \n",
    "        #results1 = results[i]\n",
    "        \n",
    "        \n",
    "        #for j in results:\n",
    "            \n",
    "        write.write(str(i) + \" = \" + str(results[i]) + '\\n')\n",
    "            \n",
    "        \n",
    "        \n",
    "    write.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "def cramers_stat(confusion_matrix):\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    return np.sqrt(chi2 / (n*(min(confusion_matrix.shape)-1)))   \n",
    "\n",
    "\n",
    "\n",
    "def createCrammerTable(X):\n",
    "    \n",
    "    cram = np.zeros((len(X.columns),len(X.columns)), dtype = np.float16)\n",
    "    \n",
    "    for i in range(len(X.columns)):\n",
    "        for j in range(i,len(X.columns)):\n",
    "            \n",
    "            c1 = X.columns[i]\n",
    "            c2 = X.columns[j]\n",
    "            \n",
    "           # y = X.crosstab(c1,c2)\n",
    "        \n",
    "            y = pd.crosstab(X[c1],X[c1]).as_matrix()\n",
    "            \n",
    "           # y = y.drop(y.columns[0])\n",
    "            #y = y.toPandas().as_matrix()\n",
    "            \n",
    "           # y = y.as_matrix()\n",
    "            v = cramers_stat(y)\n",
    "            \n",
    "            cram[i,j] = v\n",
    "            cram[j,i] = v\n",
    "            \n",
    "    return cram\n",
    "    \n",
    "\n",
    "def writeNSemanticSnps(columns = None, snps = None, name =None):\n",
    "    \n",
    "    if not name:\n",
    "        print(\"give a name to file\")\n",
    "        return\n",
    "        \n",
    "    p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt\"\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(p):\n",
    "            \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "        i += 1\n",
    "     \n",
    "    write = open(p,'w')\n",
    "    \n",
    "    snps = []\n",
    "    for i in snps.keys():\n",
    "        s = snps[i]\n",
    "        write.write(columns[i] +',   ' + s + '\\n')\n",
    "                \n",
    "            \n",
    "    write.close()\n",
    "    \n",
    "\n",
    "def writeCramResultsToTable(columns = None,X = None):\n",
    "    \n",
    "    write = open('cramer.csv','w')\n",
    "    write.write('snps'+',')\n",
    "    for i in range(len(columns) - 1):\n",
    "        \n",
    "        write.write(columns[i]+',')\n",
    "        \n",
    "    write.write(columns[len(columns)-1]+'\\n')\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        write.write(columns[i]+',')\n",
    "        \n",
    "        for j in range(len(X.T)-1):\n",
    "            write.write(X[i,j]+',')\n",
    "\n",
    "        write.write(X[i,len(X)-1]+'\\n')\n",
    "        \n",
    "    write.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMyMetric1(results,v1 = 1,v2 = 0):\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if v1 == v2:\n",
    "        print(\"wrong values!!!v1 is the same with v2!!!!\")\n",
    "       \n",
    "    \n",
    "   # r = results.rdd\n",
    "    #r3 = r.collect()\n",
    "\n",
    "    r3 = results.collect()\n",
    "    \n",
    "    same0 = 0\n",
    "    same1 = 0\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    sumall = 0\n",
    "    for i in r3:\n",
    "\n",
    "        if i[v1] == 0:\n",
    "            sum0 += 1\n",
    "            if i[v2] == 0:\n",
    "                same0 += 1\n",
    "        elif i[v1] == 1:\n",
    "            sum1 += 1\n",
    "            if i[v2] == 1:\n",
    "                same1 += 1\n",
    "        sumall += 1\n",
    "\n",
    "    print('sum0 = ', sum0)\n",
    "    print('sum1 = ', sum1)\n",
    "    print('same0 = ', same0)\n",
    "    print('same1 = ', same1)\n",
    "    print('all = ', sumall)\n",
    "    print('all2 = ', sum0+sum1)\n",
    "    \n",
    "    metrics['sum0'] = sum0\n",
    "    metrics['sum1'] = sum1\n",
    "    metrics['same1'] = same1\n",
    "    metrics['same0'] = same0\n",
    "    \n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def calculateAvgMetrics1(results,classLabel=1):\n",
    "    \n",
    "    metricss = {}\n",
    "    \n",
    "   # predictionAndLabels = results.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "   # metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    metrics = showMyMetric1(results)\n",
    "    \n",
    "    #metrics[\"confusion_matrix\"] = metrics.confusionMatrix().toArray()\n",
    "    '''metricss[\"accuracy\"] =  metrics.accuracy\n",
    "    metricss[\"recal\"]=  metrics.recall(classLabel)\n",
    "    metricss[\"precision\"] = metrics.precision(classLabel)\n",
    "    metricss[\"f1\"] = metrics.fMeasure(float(classLabel))'''\n",
    "    \n",
    "    metricss[\"accuracy\"] = (metrics['same1'] + metrics['same0'])/ (metrics['sum1'] + metrics['sum0'])\n",
    "    metricss[\"recal\"]= (metrics['same1'])/ (metrics['sum1'])\n",
    "    metricss[\"precision\"] = (metrics['same1'] )/ (metrics['sum1']) +( metrics['sum0'] - metrics['same0'])\n",
    "    metricss[\"f1\"] = 2 * ((metricss['recal'] * metricss['precision']) / (metricss['recal'] + metricss['precision']))\n",
    "    \n",
    "    return metricss\n",
    "\n",
    "def showMyMetric2(results,v1 = 1,v2 = 0):\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if v1 == v2:\n",
    "        print(\"wrong values!!!v1 is the same with v2!!!!\")\n",
    "       \n",
    "    \n",
    "   # r = results.rdd\n",
    "    #r3 = r.collect()\n",
    "\n",
    "    r3 = results.collect()\n",
    "    \n",
    "    same0 = 0\n",
    "    same1 = 0\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    sumall = 0\n",
    "    for i in r3:\n",
    "\n",
    "        if i[v1] == 0:\n",
    "            sum0 += 1\n",
    "            if i[v2] == 0:\n",
    "                same0 += 1\n",
    "        elif i[v1] == 1:\n",
    "            sum1 += 1\n",
    "            if i[v2] == 1:\n",
    "                same1 += 1\n",
    "        sumall += 1\n",
    "\n",
    "    print('sum0 = ', sum0)\n",
    "    print('sum1 = ', sum1)\n",
    "    print('same0 = ', same0)\n",
    "    print('same1 = ', same1)\n",
    "    print('all = ', sumall)\n",
    "    print('all2 = ', sum0+sum1)\n",
    "    \n",
    "    metrics['sum0'] = sum0\n",
    "    metrics['sum1'] = sum1\n",
    "    metrics['same1'] = same1\n",
    "    metrics['same0'] = same0\n",
    "    \n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def calculateAvgMetrics2(results,classLabel=1):\n",
    "    \n",
    "    metricss = {}\n",
    "    \n",
    "   # predictionAndLabels = results.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "   # metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    metrics = showMyMetric2(results)\n",
    "    \n",
    "    #metrics[\"confusion_matrix\"] = metrics.confusionMatrix().toArray()\n",
    "    '''metricss[\"accuracy\"] =  metrics.accuracy\n",
    "    metricss[\"recal\"]=  metrics.recall(classLabel)\n",
    "    metricss[\"precision\"] = metrics.precision(classLabel)\n",
    "    metricss[\"f1\"] = metrics.fMeasure(float(classLabel))'''\n",
    "    \n",
    "    metricss[\"accuracy\"] = (metrics['same1'] + metrics['same0'])/ (metrics['sum1'] + metrics['sum0'])\n",
    "    metricss[\"recal\"]= (metrics['same1'])/ (metrics['sum1'])\n",
    "    metricss[\"precision\"] = (metrics['same1'] )/ (metrics['sum1']) +( metrics['sum0'] - metrics['same0'])\n",
    "    metricss[\"f1\"] = 2 * ((metricss['recal'] * metricss['precision']) / (metricss['recal'] + metricss['precision']))\n",
    "    \n",
    "    return metricss\n",
    "\n",
    "def showMyMetric3(results,v1 = 1,v2 = 0):\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if v1 == v2:\n",
    "        print(\"wrong values!!!v1 is the same with v2!!!!\")\n",
    "       \n",
    "    \n",
    "   # r = results.rdd\n",
    "    #r3 = r.collect()\n",
    "\n",
    "    r3 = results.collect()\n",
    "    \n",
    "    same0 = 0\n",
    "    same1 = 0\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    sumall = 0\n",
    "    for i in r3:\n",
    "\n",
    "        if i[v1] == 0:\n",
    "            sum0 += 1\n",
    "            if i[v2] == 0:\n",
    "                same0 += 1\n",
    "        elif i[v1] == 1:\n",
    "            sum1 += 1\n",
    "            if i[v2] == 1:\n",
    "                same1 += 1\n",
    "        sumall += 1\n",
    "\n",
    "    print('sum0 = ', sum0)\n",
    "    print('sum1 = ', sum1)\n",
    "    print('same0 = ', same0)\n",
    "    print('same1 = ', same1)\n",
    "    print('all = ', sumall)\n",
    "    print('all2 = ', sum0+sum1)\n",
    "    \n",
    "    metrics['sum0'] = sum0\n",
    "    metrics['sum1'] = sum1\n",
    "    metrics['same1'] = same1\n",
    "    metrics['same0'] = same0\n",
    "    \n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def calculateAvgMetrics3(results,classLabel=1):\n",
    "    \n",
    "    metricss = {}\n",
    "    \n",
    "   # predictionAndLabels = results.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "   # metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    metrics = showMyMetric3(results)\n",
    "    \n",
    "    #metrics[\"confusion_matrix\"] = metrics.confusionMatrix().toArray()\n",
    "    '''metricss[\"accuracy\"] =  metrics.accuracy\n",
    "    metricss[\"recal\"]=  metrics.recall(classLabel)\n",
    "    metricss[\"precision\"] = metrics.precision(classLabel)\n",
    "    metricss[\"f1\"] = metrics.fMeasure(float(classLabel))'''\n",
    "    \n",
    "    metricss[\"accuracy\"] = (metrics['same1'] + metrics['same0'])/ (metrics['sum1'] + metrics['sum0'])\n",
    "    metricss[\"recal\"]= (metrics['same1'])/ (metrics['sum1'])\n",
    "    metricss[\"precision\"] = (metrics['same1'] )/ (metrics['sum1']) +( metrics['sum0'] - metrics['same0'])\n",
    "    metricss[\"f1\"] = 2 * ((metricss['recal'] * metricss['precision']) / (metricss['recal'] + metricss['precision']))\n",
    "    \n",
    "    return metricss\n",
    "\n",
    "def class1(numFold,classifier,name,samples,labels):\n",
    "    \n",
    "     for i in range(1,numFold + 1):\n",
    "        \n",
    "        print(\"name = \",name)\n",
    "        print(\"cross = \",i)\n",
    "         \n",
    "        test_data = samples['test'][i]\n",
    "        \n",
    "        train = samples['train'][i]\n",
    "        \n",
    "        model = classifier.fit(train)\n",
    "           \n",
    "        results = model.transform(test_data)\n",
    "\n",
    "        evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "        AUC = evaluate.evaluate(results)\n",
    "        \n",
    "        results1 = results.select('prediction','label')\n",
    "    \n",
    "        r = calculateAvgMetrics1(results1.rdd,classLabel=1)\n",
    "        r['auc'] = AUC\n",
    "        avgMetrics[name][i] = r\n",
    "        \n",
    "def class2(numFold,classifier,name,samples,labels):\n",
    "    \n",
    "     for i in range(1,numFold + 1):\n",
    "        \n",
    "        print(\"name = \",name)\n",
    "        print(\"cross = \",i)\n",
    "         \n",
    "        test_data = samples['test'][i]\n",
    "        \n",
    "        train = samples['train'][i]\n",
    "        \n",
    "        model = classifier.fit(train)\n",
    "           \n",
    "        results = model.transform(test_data)\n",
    "\n",
    "        evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "        AUC = evaluate.evaluate(results)\n",
    "        \n",
    "        results1 = results.select('prediction','label')\n",
    "    \n",
    "        r = calculateAvgMetrics2(results1.rdd,classLabel=1)\n",
    "        r['auc'] = AUC\n",
    "        avgMetrics[name][i] = r\n",
    "        \n",
    "def class3(numFold,classifier,name,samples,labels):\n",
    "    \n",
    "     for i in range(1,numFold + 1):\n",
    "        \n",
    "        print(\"name = \",name)\n",
    "        print(\"cross = \",i)\n",
    "         \n",
    "        test_data = samples['test'][i]\n",
    "        \n",
    "        train = samples['train'][i]\n",
    "        \n",
    "        model = classifier.fit(train)\n",
    "           \n",
    "        results = model.transform(test_data)\n",
    "\n",
    "        evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "        AUC = evaluate.evaluate(results)\n",
    "        \n",
    "        results1 = results.select('prediction','label')\n",
    "    \n",
    "        r = calculateAvgMetrics3(results1.rdd,classLabel=1)\n",
    "        r['auc'] = AUC\n",
    "        avgMetrics[name][i] = r\n",
    "\n",
    "def crossVal1(numFold = 0,samples = None, labels =None,classifier = None,name = None):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if classifier == None:\n",
    "        \n",
    "        print(\"classifier not given\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    if samples == None:\n",
    "        return\n",
    "    \n",
    "    \n",
    "    if name == 'reg':\n",
    "        class1(numFold,classifier,name,samples,labels)\n",
    "        \n",
    "    elif name =='tree':\n",
    "        class2(numFold,classifier,name,samples,labels)\n",
    "        \n",
    "    elif name =='svm':\n",
    "        class3(numFold,classifier,name,samples,labels)\n",
    "    \n",
    "   \n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "class myThread1 (threading.Thread):\n",
    "    def __init__(self, threadID, name, counter,classifier,samples,labels,name1,folds):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.counter = counter\n",
    "        self.classifier = classifier\n",
    "        self.samples= samples\n",
    "        self.labels = labels\n",
    "        self.name1 = name1\n",
    "        self.folds = folds\n",
    "        \n",
    "    def run(self):\n",
    "     \n",
    "        crossVal1(numFold = self.folds,samples = self.samples, labels = self.labels,classifier = self.classifiers)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = (SparkConf()\n",
    "    .set(\"spark.driver.maxResultSize\", \"20g\")\n",
    "    .set('spark_executor_cores',\"3\")\n",
    "    .set('spark.graphx.pregel.checkpointInterval','-1')\n",
    "    .set('spark.network.timeout','100000000')\n",
    "    .set('spark.executor.heartbeatInterval','10000000'))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#spark = SparkSession.builder.appName('melanoma').getOrCreate()\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/media/antonis/red\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/'\n",
    "\n",
    "#pathSnp = '/media/antonis/red/newSet/maf/maf = 0.05/assoc/pvalue = 0.001/snpCodeTest.csv'\n",
    "#pathSnp = '/media/antonis/red/newSet/maf/maf = 0.05/assoc/pvalue = 0.01/snp2.txt'\n",
    "#pathSnp = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/snp2.txt'\n",
    "pathSnp = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/snpCodeTest1.csv'\n",
    "\n",
    "#pathSnp = '/media/antonis/Antonis_Moulopoulos/newSet/pvalue = 0.001/snp1.txt'\n",
    "#pathSnp = '/media/antonis/Antonis_Moulopoulos/newdata/maf = 0.05/pvalue = 0.001/snp2.txt'\n",
    "\n",
    "\n",
    "data = spark.read.option(\"maxColumns\", 80000).csv(pathSnp,inferSchema=True,header=True)\n",
    "data=data.withColumnRenamed('TARGET','label')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data columns = \",len(data.columns))\n",
    "\n",
    "features = []\n",
    "for i in data.columns:\n",
    "    if 'rs' not in i and i !='label':\n",
    "        features.append(i)\n",
    "print(len(features))\n",
    "#print((features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = data.drop('patients')\n",
    "for i in features:\n",
    "    d = d.drop(i)\n",
    "print(\"columns = \",len(d.columns))\n",
    "\n",
    "#train_data,test_data = d.randomSplit([0.8,0.2],seed=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson's Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label0 = d.filter('label==0').count()\n",
    "label1 = d.filter('label==1').count()\n",
    "\n",
    "d1 = balanedData(d,label1,label0)\n",
    "\n",
    "li = len(d.columns)\n",
    "\n",
    "input_data = d1.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "train0 = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "input_data = None\n",
    "  \n",
    "    \n",
    "    \n",
    "final_data1 = train0.select('features')\n",
    "corr = Correlation.corr(final_data1, \"features\")\n",
    "corr = corr.head()[0].toArray()\n",
    "\n",
    "\n",
    "thres = 0.7\n",
    "down =99\n",
    "up =100\n",
    "\n",
    "snpsRed = []\n",
    "snpsRed = s.lowCorrelation(corr, threshold=thres, up=up, down=down)#oso megalytero threshold toso perissotero omoia einai \n",
    "###############################################################################################################################\n",
    "features = []\n",
    "for i in range(0,len(d.columns)):\n",
    "    if 'rs' in d.columns[i] and d.columns[i] !='label':\n",
    "        features.append(d.columns[i])\n",
    "        \n",
    "snpsRed1 = []\n",
    "for i in snpsRed:\n",
    "    snpsRed1.append(features[i])\n",
    "\n",
    "snpsRed1.append('label')\n",
    "\n",
    "features = []\n",
    "for i in range(0,len(d.columns)):\n",
    "    if d.columns[i] not in snpsRed1:\n",
    "        features.append(d.columns[i])\n",
    "\n",
    "\n",
    "d = d.drop(*features)\n",
    "  \n",
    "\n",
    "li = len(d.columns)\n",
    "\n",
    "############################################################################################################################\n",
    "\n",
    "    \n",
    "\n",
    "input_data = d.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "d = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "print(\"train = \",d.head()[1].toArray().shape)\n",
    "   \n",
    "input_data = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAMMER V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''label0 = d.filter('label==0').count()\n",
    "label1 = d.filter('label==1').count()\n",
    "\n",
    "d1 = balanedData(d,label1,label0)\n",
    "\n",
    "d1 = d1.drop('label')\n",
    "\n",
    "d1 = d1.toPandas()\n",
    "\n",
    "cram = createCrammerTable(d1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.7\n",
    "down =100\n",
    "up =100\n",
    "\n",
    "snpsRed = []\n",
    "snpsRelabel = s.lowCorrelation(cram, threshold=thres, up=up, down=down)#oso megalytero threshold toso perissotero omoia einai \n",
    "\n",
    "###############################################################################################################################\n",
    "features = []\n",
    "for i in range(0,len(d.columns)):\n",
    "    if 'rs' in d.columns[i] and d.columns[i] !='label':\n",
    "        features.append(d.columns[i])\n",
    "        \n",
    "snpsRed1 = []\n",
    "for i in snpsRed:\n",
    "    snpsRed1.append(features[i])\n",
    "\n",
    "snpsRed1.append('label')\n",
    "\n",
    "features = []\n",
    "for i in range(0,len(d.columns)):\n",
    "    if d.columns[i] not in snpsRed1:\n",
    "        features.append(d.columns[i])\n",
    "\n",
    "\n",
    "d = d.drop(*features)\n",
    "  \n",
    "\n",
    "li = len(d.columns)\n",
    "\n",
    "############################################################################################################################\n",
    "\n",
    "    \n",
    "\n",
    "input_data = d.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "d = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "print(\"train = \",d.head()[1].toArray().shape)\n",
    "   \n",
    "input_data = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds =5\n",
    "\n",
    "samples, labels = split(folds,d)\n",
    "\n",
    "train = {}\n",
    "test = {}\n",
    "\n",
    "for i in range(1,folds + 1):\n",
    "        \n",
    "        test[i] = samples[i]\n",
    "        label0 = 0\n",
    "        label1 = 0\n",
    "        \n",
    "        if i <= 2:\n",
    "        \n",
    "            train_data = samples[3].union(samples[4])\n",
    "            \n",
    "            label0 = labels[3]['label0']+labels[4]['label0']\n",
    "            label1 = labels[3]['label1']+labels[4]['label1']\n",
    "            \n",
    "            s1 = 3\n",
    "            s2 = 4\n",
    "                   \n",
    "        else:\n",
    "            \n",
    "            train_data = samples[1].union(samples[2])\n",
    "            \n",
    "            label0 = labels[1]['label0']+labels[2]['label0']\n",
    "            label1 = labels[1]['label1']+labels[2]['label1']\n",
    "            \n",
    "            s1 = 1\n",
    "            s2 = 2\n",
    "            \n",
    "            \n",
    "        for j in range(1,folds + 1):\n",
    "            \n",
    "            if j != i and j!= s2 and j != s1:\n",
    "                \n",
    "                train_data = train_data.union(samples[j])\n",
    "                label0 = label0 + labels[j]['label0']\n",
    "                label1 = label1 + labels[j]['label1']\n",
    "                \n",
    "        train[i] = balanedData(train_data,label1,label0)\n",
    "        \n",
    "samples['train'] = train\n",
    "samples['test'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "log_reg = LogisticRegression(featuresCol='features',labelCol='label',maxIter=10)\n",
    "\n",
    "results = crossVal(numFold = folds,samples= samples, labels = labels,classifier = log_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = {}\n",
    "print\n",
    "for i in results[1].keys():\n",
    "    avg[i] = 0\n",
    "    \n",
    "for i in results.keys():\n",
    "    for j in results[i].keys():\n",
    "        avg[j] = avg[j] + results[i][j]\n",
    "        \n",
    "for i in avg.keys():\n",
    "    avg[i] = float(avg[i]/folds)\n",
    "\n",
    "\n",
    "\n",
    "writeResult(path,'regression_pearson',results=avg,category='pearson',thresh=thres, down=down, up=up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "lsvc = LinearSVC(featuresCol='features',labelCol='label',maxIter=10)\n",
    "lsvc.setThreshold(0.5)\n",
    "results = crossVal(numFold = folds,data = samples, labels = labels,classifier = lsvc)\n",
    "writeResult(path,'svm_cram',results=results,category='cram',thresh=thres, down=down, up=up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol='features',labelCol='label', numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=50, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)\n",
    "\n",
    "results = crossVal(numFold = folds,data = samples, labels = labels,classifier = rf)\n",
    "\n",
    "writeResult(path,'rf_cram',results=results,category='cram',thresh=thres, down=down, up=up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeD = DecisionTreeClassifier(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "results = crossVal(numFold = folds,data = samples, labels = labels,classifier = treeD)\n",
    "\n",
    "writeResult(path,'tree_cram',results=results,category='cram',thresh=thres, down=down, up=up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossVal1(classifier = None):\n",
    "    \n",
    "    numFold = 10\n",
    "    avgMetrics = {}\n",
    "  \n",
    "    \n",
    "    '''if data == None:\n",
    "        \n",
    "        print(\"data not given\")\n",
    "        return'''\n",
    "    \n",
    "    if classifier == None:\n",
    "        \n",
    "        print(\"classifier not given\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    #samples = split(numFold = numFold, df = data)\n",
    "    \n",
    "    if samples == None:\n",
    "        return\n",
    "    \n",
    "    for i in range(1,numFold + 1):\n",
    "        \n",
    "        print(\"cross = \",i)\n",
    "         \n",
    "        test_data = samples['test'][i]\n",
    "       \n",
    "        \n",
    "        train = samples['train'][i]\n",
    "        \n",
    "        model = classifier.fit(train)\n",
    "           \n",
    "        results = model.transform(test_data)\n",
    "\n",
    "        evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "        AUC = evaluate.evaluate(results)\n",
    "        \n",
    "        \n",
    "        \n",
    "        results1 = results.select('prediction','label')\n",
    "    \n",
    "        r = calculateAvgMetrics(results1.rdd,classLabel=1)\n",
    "        r['auc'] = AUC\n",
    "        avgMetrics[i] = r\n",
    "    \n",
    "    return avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgMetrics = {}\n",
    "avgMetrics['reg'] = {}\n",
    "avgMetrics['svm'] = {}\n",
    "avgMetrics['tree'] = {}\n",
    "\n",
    "log_reg = LogisticRegression(featuresCol='features',labelCol='label',maxIter=10)\n",
    "\n",
    "lsvc = LinearSVC(featuresCol='features',labelCol='label',maxIter=10)\n",
    "lsvc.setThreshold(0.5)\n",
    "\n",
    "\n",
    "treeD = DecisionTreeClassifier(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "items = {}\n",
    "\n",
    "\n",
    "items['reg'] = log_reg\n",
    "items['svm'] = lsvc\n",
    "items['tree'] = treeD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "count = 1\n",
    "for i in items.keys():\n",
    "\n",
    "    thread = myThread1(count, \"Thread-\"+str(count), count,items[i],samples,labels,i,5)\n",
    "    threads.append(thread)\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgMetrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
