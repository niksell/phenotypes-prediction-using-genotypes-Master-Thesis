{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANTONIS\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\ANTONIS\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\ANTONIS\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Write import Write\n",
    "from IO.Read import Read\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "\n",
    "\n",
    "def setIdToName(aList):\n",
    "    \n",
    "    ids = {}\n",
    "    nameToId = {}\n",
    "    idToName = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in aList:\n",
    "        \n",
    "        nameToId[i] = count\n",
    "        idToName[count] = i\n",
    "        count += 1\n",
    "        \n",
    "    ids['nameToId'] = nameToId\n",
    "    ids['idToName'] = idToName\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def createNewIds(oldsnps,snps):\n",
    "    \n",
    "    nameToId = {}\n",
    "    idToName = {}\n",
    "    newIds = {}\n",
    "    \n",
    "    oldIds = oldsnps['snps']['idToName']\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        \n",
    "        nameToId[oldIds[snps[i]]] = i\n",
    "        idToName[i] = oldIds[snps[i]]\n",
    "        \n",
    "    newIds['nameToId'] = nameToId\n",
    "    newIds['idToName'] = idToName\n",
    "        \n",
    "    return newIds\n",
    "\n",
    "def setSnpsCode(patients,chromosomes):\n",
    "    \n",
    "    for i in patients.keys():\n",
    "        patients[i].snpCode(chromosomes)\n",
    "        \n",
    "    return patients\n",
    "    \n",
    "\n",
    "def tables(sampleX,sampleY,k):\n",
    "  \n",
    "    samples = {}\n",
    "    \n",
    "    for run in range(1,k+1):\n",
    "        \n",
    "        d1 = {}\n",
    "        \n",
    "\n",
    "        dataTestX = sampleX[run]\n",
    "        dataTestY = sampleY[run]\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        for i in sampleX.keys():\n",
    "\n",
    "            if i != run:\n",
    "\n",
    "                n += len(sampleX[i])\n",
    "\n",
    "        dataTrainX = np.zeros((n,len(sampleX[1].T)),dtype = int)\n",
    "        dataTrainY = np.zeros((n,),dtype = int)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sample in sampleX.keys():\n",
    "\n",
    "            if sample != run:\n",
    "\n",
    "                 for i in range(len(sampleX[sample])):\n",
    "                    for j in range(len(sampleX[sample].T)):\n",
    "                        dataTrainX[count,j] = sampleX[sample][i,j]\n",
    "\n",
    "                    dataTrainY[count] = sampleY[sample][i]\n",
    "                    count += 1\n",
    "\n",
    "        d1['trainX'] = dataTrainX\n",
    "        d1['trainY'] = dataTrainY\n",
    "        d1['testX'] = dataTestX\n",
    "        d1['testY'] = dataTestY\n",
    "        \n",
    "        samples[run] = d1\n",
    "    \n",
    "    return samples\n",
    "    \n",
    "def kSampleData(k,X,Y):\n",
    "    \n",
    "    x = int (len(X) / k)\n",
    "    allElements = np.zeros((len(X),),dtype = int)\n",
    "    \n",
    "    count1 = 1\n",
    "    sampleX = {}\n",
    "    sampleY = {}\n",
    "   \n",
    "    \n",
    "    while count1 <= k:\n",
    "        count2 = 1\n",
    "        sampleData = []\n",
    "        \n",
    "        if count1 == k:\n",
    "            x =  len(X) - ((k-1) * x)\n",
    "        \n",
    "        dataX = np.zeros((x,len(X.T)),dtype = int)\n",
    "        dataY = np.zeros((x,),dtype = int)\n",
    "        \n",
    "        while count2 <= x:\n",
    "            \n",
    "            aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            while allElements[aRand] == 1:\n",
    "                \n",
    "                aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            allElements[aRand] = 1\n",
    "            sampleData.append(aRand)\n",
    "            count2 += 1\n",
    "            \n",
    "        for i in range(len(sampleData)):\n",
    "            for j in range(len(X.T)):\n",
    "                dataX[i,j] = X[sampleData[i],j]\n",
    "            \n",
    "            dataY[i] = Y[sampleData[i]]\n",
    "            \n",
    "        sampleX[count1] = dataX\n",
    "        sampleY[count1] = dataY\n",
    "        count1 +=1\n",
    "        \n",
    "    return tables(sampleX,sampleY,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createNewTable(snps,X):\n",
    "    \n",
    "    newX = np.zeros((len(X),len(snps)),dtype = int)\n",
    "    count=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(newX)):\n",
    "        for j in range(len(newX.T)):\n",
    "            newX[i,j] = -1\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        \n",
    "        newX[:,i] = X[:,snps[i]]\n",
    "        \n",
    "        \n",
    "    print(\"new shape = \",newX.shape)\n",
    "            \n",
    "    return newX \n",
    "\n",
    "\n",
    "\n",
    "def featuresIds(oldSnps,snps):\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        features[i] = snps[i]\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def crossValidiation(X, Y, k = 1, continious = True, classifier = None,OLS = False,Logistic = False):\n",
    "    \n",
    "    if not classifier:\n",
    "        print(\"wrong!!!!!!! you have to choise a classifier\")\n",
    "        return\n",
    "    \n",
    "    results = {}\n",
    "    accuracy = {}\n",
    "    auc = {}\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    f1Score = {}\n",
    "    \n",
    "    sumResults = 0.0\n",
    "    sumAccuracy = 0.0\n",
    "    sumAuc = 0.0\n",
    "    sumRecall = 0.0\n",
    "    sumPrecision = 0.0\n",
    "    sumF1Score = 0.0\n",
    "    \n",
    "    samples = kSampleData(k,X,Y)\n",
    "    \n",
    "    for run in range(1, k + 1):\n",
    "        \n",
    "        trainX = samples[run]['trainX']\n",
    "        trainY = samples[run]['trainY']\n",
    "        \n",
    "        #trainX,trainY = balancedData(trainX,trainY)\n",
    "        \n",
    "        testX = samples[run]['testX']\n",
    "        testY = samples[run]['testY']\n",
    "        \n",
    "        \n",
    "        if OLS:\n",
    "            classifier = sm.OLS(trainY,trainX)\n",
    "            yPredict = classifier.fit().predict(testX)\n",
    "        else:\n",
    "\n",
    "            classifier.fit(trainX, trainY)\n",
    "            yPredict = classifier.predict(testX)\n",
    "        \n",
    "        if continious:\n",
    "            \n",
    "            for i in range(len(yPredict)):\n",
    "                \n",
    "                if (abs(0 - yPredict[i]) - abs(1 - yPredict[i])) <= 1e-10 :\n",
    "                    yPredict[i] = 0\n",
    "                else:\n",
    "                    yPredict[i] = 1\n",
    "                    \n",
    "        if Logistic:\n",
    "            \n",
    "            probabilities = classifier.predict_proba(testX)\n",
    "            \n",
    "            for i in range(len(probabilities)):\n",
    "                if probabilities[i][1] >= 0.8:\n",
    "                    yPredict[i] = 1\n",
    "                else:\n",
    "                    yPredict[i] = 0\n",
    "          \n",
    "        accuracy[run] = metrics.accuracy_score(testY,yPredict)#(yPredict,testY)#\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(testY,yPredict)\n",
    "        auc[run] = metrics.auc(fpr,tpr)\n",
    "        recall[run] = metrics.recall_score(testY,yPredict)\n",
    "        precision[run] = metrics.precision_score(testY,yPredict)\n",
    "        f1Score[run] = f1_score(testY, yPredict, average='binary')\n",
    "        \n",
    "    \n",
    "    for i in accuracy.keys():\n",
    "        sumAccuracy = sumAccuracy + accuracy[i]\n",
    "        sumAuc = sumAuc + auc[i]\n",
    "        sumRecall = sumRecall + recall[i]\n",
    "        sumPrecision = sumPrecision + precision[i]\n",
    "        sumF1Score = sumF1Score + f1Score[i]\n",
    "    \n",
    "    results['accuracy'] = sumAccuracy / k\n",
    "    results['auc'] = sumAuc / k\n",
    "    results['recall'] = sumRecall / k\n",
    "    results['precision'] = sumPrecision / k\n",
    "    results['f1'] = sumF1Score / k\n",
    "    \n",
    "    return results\n",
    "\n",
    "def writeResultConf(path,name,results):\n",
    "    \n",
    "    timee = time.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    folder = path + name + 'Confu' + \" ( \" + timee + \" ) \" + '_'\n",
    "    #file = path + name + 'Confu' + '.txt'\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(folder):\n",
    "        timee = time.strftime(\"%d-%m-%Y\")\n",
    "        folder = path + name + 'Confu' + \" ( \" + timee + \" ) \" + '_' + str(i) + '_'\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    " #   os.makedirs(folder)\n",
    "    \n",
    "    file = folder + name + 'Confu' + '.txt' \n",
    "    \n",
    "    write = open(file,'w')\n",
    "    \n",
    "    write.write(timee + '\\n'+ '\\n')\n",
    "    write.write(name + '\\n')\n",
    "    \n",
    "    for i in results:\n",
    "        \n",
    "        results1 = results[i]\n",
    "        write.write(\"Category = \" + i + '\\n')\n",
    "        \n",
    "        for j in results1:\n",
    "            \n",
    "            write.write(j + \" = \" + str(results1[j]) + '\\n')\n",
    "            \n",
    "        write.write('\\n')\n",
    "        write.write('\\n')\n",
    "        \n",
    "    write.close()\n",
    "\n",
    "    \n",
    "\n",
    "def writeResult(path,name,results,category):\n",
    "    \n",
    "    timee = time.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    folder = path + name  + \" ( \" + timee + \" ) \" + '_'\n",
    "    #file = path + name  + '.txt'\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(folder):\n",
    "        timee = time.strftime(\"%d-%m-%Y\")\n",
    "        folder = path + name + \" ( \" + timee + \" ) \" + '_' + str(i) + '_'\n",
    "       \n",
    "        i += 1\n",
    "        \n",
    "   # os.makedirs(folder)\n",
    "    \n",
    "    file = folder + name + '.txt'\n",
    "    \n",
    "    write = open(file,'w')\n",
    "    \n",
    "    write.write(timee + '\\n'+ '\\n')\n",
    "    write.write(name + '\\n')\n",
    "    write.write(\"Category = \" + category + '\\n')\n",
    "    for i in results[category]:\n",
    "        \n",
    "        #results1 = results[i]\n",
    "        \n",
    "        \n",
    "        #for j in results:\n",
    "            \n",
    "        write.write(i + \" = \" + str(results[category][i]) + '\\n')\n",
    "            \n",
    "        \n",
    "        \n",
    "    write.close()\n",
    "\n",
    "def balancedData(X,Y):\n",
    "    \n",
    "    cases = 0\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 1:\n",
    "            cases += 1\n",
    "            \n",
    "    Xbalanced = np.zeros((2*cases,len(X.T)))\n",
    "    Ybalanced = np.zeros(2*cases)\n",
    "    controls = 0\n",
    "    count = 0\n",
    "    selected = np.zeros(len(X))\n",
    "    '''for i in range(len(Y)):\n",
    "        if(Y[i] == 0 and controls < cases):\n",
    "            Xbalanced[count,:] = X[i,:]\n",
    "            Ybalanced[count] = Y[i]\n",
    "            controls +=1\n",
    "            count += 1\n",
    "        elif Y[i] == 1:\n",
    "            Xbalanced[count,:] = X[i,:]\n",
    "            Ybalanced[count] = Y[i]\n",
    "            count += 1'''\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        \n",
    "        if Y[i] == 1:\n",
    "            Xbalanced[count,:] = X[i,:]\n",
    "            Ybalanced[count] = Y[i]\n",
    "            count += 1\n",
    "            selected[i]=i\n",
    "    \n",
    "    while(controls<cases):\n",
    "        aRand = randint(0,len(X)-1)\n",
    "        while(selected[aRand] == 1):\n",
    "            aRand = randint(0,len(X)-1)\n",
    "            \n",
    "        Xbalanced[count,:] = X[aRand,:]\n",
    "        Ybalanced[count] = Y[aRand]\n",
    "        controls +=1\n",
    "        count += 1\n",
    "    \n",
    "    print(\"len x = \", Xbalanced.shape)\n",
    "    print(\"len y = \", Ybalanced.shape)\n",
    "    \n",
    "    return Xbalanced, Ybalanced\n",
    "\n",
    "\n",
    "def casePatient(X,Y):\n",
    "    \n",
    "    cases = 0\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 1:\n",
    "            cases += 1\n",
    "            \n",
    "    xCase = np.zeros((cases,len(X.T)))\n",
    "    count = 0\n",
    "    for i in range(len(Y)):\n",
    "        \n",
    "        if Y[i] == 1:\n",
    "            xCase[count,:] = X[i,:]\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "    \n",
    "    \n",
    "    print('cases = ', cases)\n",
    "    print('xCase shape = ', xCase.shape)\n",
    "    \n",
    "    return xCase\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\maf\\\\maf = 0.05\\\\assoc\\\\pvalue = 0.001\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\maf\\\\maf = 0.05\\\\pvalue = 0.01\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\maf\\\\maf = 0.05\\\\pvalue = 0.005\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\maf\\\\maf = 0.05\\\\pvalue = 0.05\\\\'\n",
    "\n",
    "#path = 'D:\\\\newSet\\\\maf\\\\maf = 0.05\\\\assoc\\\\pvalue = 0.001\\\\'\n",
    "\n",
    "numberOfChromosomes = 22#'ari8mos twn xromoswmatwn'\n",
    "patientsTrain = {}\n",
    "patientsTest = {}\n",
    "allPatients = {}\n",
    "\n",
    "chromosomes = {}\n",
    "\n",
    "read = Read(path,numberOfChromosomes)\n",
    "write = Write(path,numberOfChromosomes)\n",
    "\n",
    "patients = read.readPatients('Patients.txt')\n",
    "chromosomes = read.readSnps(\".assoc\")\n",
    "write.writePatientsList(patients,'patient.txt')\n",
    "write.writeSnpsList(chromosomes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run train_lgen bat and test_leg bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mphka\n",
      "mphka2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4980, 7799)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "snps = read.getListOfSnps()\n",
    "ids = {} \n",
    "\n",
    "\n",
    "ids['patients'] = setIdToName(list(patients.keys()))\n",
    "ids['snps'] = setIdToName(snps)\n",
    "\n",
    "\n",
    "if os.path.exists(path + 'snpCode.txt'):\n",
    "    print(\"mphka\")\n",
    "    X, Y = read.readSnpsCode(patients,ids)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    write.writeSnpLog(read.getNumberOfPatients(),read.getNumberOfSnps(),chromosomes)\n",
    "    X, Y = read.readSnpsCode(patients,ids)\n",
    "    \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 0 :\n",
    "        Y[i] = -1\n",
    "\n",
    "sum0 = 0\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "sumelse = 0\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 0 :\n",
    "        sum0 += 1\n",
    "    elif Y[i] == 1:\n",
    "        sum1 +=1\n",
    "    elif Y[i] == -1:\n",
    "        sum2 +=1\n",
    "    else:\n",
    "        sumelse +=1\n",
    "print(\"sum0 = \", sum0)\n",
    "print(\"sum1 = \", sum1)\n",
    "print(\"sum-1 = \", sum2)\n",
    "print(\"sumelse = \", sumelse)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mergex =  (4980, 7799)\n",
      "xTrain =  (4482, 7799)\n",
      "xTest =  (498, 7799)\n",
      "yTrain =  (4482,)\n",
      "yTest =  (498,)\n"
     ]
    }
   ],
   "source": [
    "#X,Y =balancedData(X,Y)\n",
    "\n",
    "xTraining, xTest, yTraining1, yTest = train_test_split(X, Y, test_size=0.1, random_state=randint(0,2018))\n",
    "print(\"mergex = \",X.shape)\n",
    "print(\"xTrain = \",xTraining.shape)\n",
    "print(\"xTest = \",xTest.shape)\n",
    "print(\"yTrain = \",yTraining1.shape)\n",
    "print(\"yTest = \",yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xC = casePatient(X,Y)\n",
    "#cor = Correlation(xC)\n",
    "\n",
    "cor = Correlation(X)\n",
    "\n",
    "\n",
    "#cor = RSquare(X)\n",
    "\n",
    "#cor = Correlation(xTraining)\n",
    "#cor = RSquare(xTraining)\n",
    "snpReduc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snpsIds =  0\n",
      "idToName =  7799\n"
     ]
    }
   ],
   "source": [
    "down = 40\n",
    "up = 100 \n",
    "threshold = 0.7\n",
    "snpReduc['high'] = cor.getHighCorrelationSnps(threshold, down=down,up=up,c=-2)\n",
    "write.writeSnpsUsed(snpReduc['high'],ids['snps']['idToName'],chromosomes,'high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snpsIds =  7515\n",
      "idToName =  7799\n"
     ]
    }
   ],
   "source": [
    "\n",
    "down = 97\n",
    "up = 100 \n",
    "threshold = 0.7\n",
    "#snpReduc['low'] = cor.getLowCorrelationSnps(threshold, down=down,up=up)\n",
    "snpReduc['low97'] = cor.getLowCorrelationSnps(threshold, down=down,up=up,c=-2)\n",
    "write.writeSnpsUsed(snpReduc['low97'],ids['snps']['idToName'],chromosomes,'97%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snpsIds =  883\n",
      "idToName =  7799\n"
     ]
    }
   ],
   "source": [
    "down = 100\n",
    "up = 100 \n",
    "threshold = 0.7\n",
    "#snpReduc['low'] = cor.getLowCorrelationSnps(threshold, down=down,up=up)\n",
    "snpReduc['low100'] = cor.getLowCorrelationSnps(threshold, down=down,up=up,c=-2)\n",
    "write.writeSnpsUsed(snpReduc['low100'],ids['snps']['idToName'],chromosomes,'100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7515\n",
      "883\n"
     ]
    }
   ],
   "source": [
    "print(len(snpReduc['low97']))\n",
    "print(len(snpReduc['low100']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''print(ids['snps']['nameToId']['rs75570604'])\n",
    "get = cor.getCorrMatrix()\n",
    "\n",
    "summ = 0 \n",
    "\n",
    "for i in range(len(get)):\n",
    "    if get[6555,i] - 0.7 < 1e-10 :\n",
    "        summ += 1'''\n",
    "\n",
    "'''for i in range(len(get)):\n",
    "    sum1 = 0\n",
    "    for j in range(len(get.T)):\n",
    "        if get[i,j] - 0.7 < 1e-10 :\n",
    "            sum1 += 1\n",
    "    if sum1 == len(get.T)-1:\n",
    "        summ += 1\n",
    "'''\n",
    "\n",
    "'''for i in range(len(get)):\n",
    "    sum1 = 0\n",
    "    for j in range(len(get.T)):\n",
    "        if get[i,j] - 0.7 > 1e-10 :\n",
    "            sum1 += 1\n",
    "    if sum1 > summ:\n",
    "        summ = sum1'''\n",
    "\n",
    "\n",
    "'''print(summ)\n",
    "print(len(get))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = []\n",
    "#categories = ['low','high']\n",
    "#categories = ['low']\n",
    "categories = ['low97','low100']\n",
    "writeResults2={}\n",
    "writeResults={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''featuresIdss = {}\n",
    "featuresIdss['low'] = featuresIds(snpReduc['low'])'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "\n",
    "test = SelectKBest(score_func=chi2,k = 1000)\n",
    "fit1 = test.fit(xTraining, yTraining1)\n",
    "xTraining1 = fit1.transform(xTraining)\n",
    "\n",
    "fit2 = test.fit(xTest, yTest)\n",
    "xTest1 = fit2.transform(xTest)\n",
    "\n",
    "fit3 = test.fit(X, Y)\n",
    "XX = fit3.transform(X)\n",
    "\n",
    "print(\"xtest\", xTest1.shape)\n",
    "print(\"xtraining\", xTraining1.shape)\n",
    "print(\"X\", XX.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "for i in categories:\n",
    "    r1={}\n",
    "    writeResults={}\n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    #clf.fit(xTraining1, yTraining1)\n",
    "   \n",
    "    param_grid = {\n",
    "              \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "               \"warm_start\":[True,False]}\n",
    "    \n",
    "    '''param_grid = { \n",
    "         'n_estimators':[2000,3000,5000], \n",
    "         'max_depth':[5,15,30], \n",
    "         'min_samples_split':[2,3], \n",
    "        'min_samples_leaf':[1,2],\n",
    "        \"warm_start\":[True,False],\n",
    "                \"oob_score\":[True,False]}\n",
    "    '''\n",
    "    \n",
    "    # run grid search\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid,cv = 10,verbose=1)\n",
    "    \n",
    "    grid_search.fit(xTraining1, yTraining1)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #yPredict4 = clf.predict(xTest1)\n",
    "    yPredict4 = grid_search.predict(xTest1)\n",
    "\n",
    "    print(metrics.accuracy_score(yTest,yPredict4))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "    error4 = mean_squared_error(yTest, yPredict4)\n",
    "    print(\"error 4 = \",error4)\n",
    "    RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "    print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict4)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict4)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict4)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict4)\n",
    "    r1['f1'] = f1_score(yTest, yPredict4, average='binary')\n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = grid_search, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "   # results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #writeResult(path,'rfr'+i,writeResults,i)\n",
    "   # writeResultConf(path,'rfr'+i,writeResults2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(xTraining1, yTraining1)\n",
    "yPredict4 = clf.predict(xTest1)\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(yTest,yPredict4))\n",
    "print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "error4 = mean_squared_error(yTest, yPredict4)\n",
    "print(\"error 4 = \",error4)\n",
    "RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low97\n",
      "new shape =  (4980, 7515)\n",
      "new shape =  (4482, 7515)\n",
      "new shape =  (498, 7515)\n",
      "(4980, 22545)\n",
      "(4482, 22545)\n",
      "(498, 22545)\n",
      "0.957831325301\n",
      "[[386  10]\n",
      " [ 11  91]]\n",
      "error 2 =  0.0421686746988\n",
      "RMSE2 =  0.205350127097\n",
      "AUC =  0.933452168746\n",
      "recal =  0.892156862745\n",
      "precision =  0.90099009901\n",
      "f1Score =  0.896551724138\n",
      "\n",
      "accuracy =  0.938554216867\n",
      "AUC =  0.895068810682\n",
      "recal =  0.821409923542\n",
      "precision =  0.870594811333\n",
      "f1 =  0.844220997063\n",
      "\n",
      "Category =  low100\n",
      "new shape =  (4980, 883)\n",
      "new shape =  (4482, 883)\n",
      "new shape =  (498, 883)\n",
      "(4980, 2649)\n",
      "(4482, 2649)\n",
      "(498, 2649)\n",
      "0.931726907631\n",
      "[[380  16]\n",
      " [ 18  84]]\n",
      "error 2 =  0.0682730923695\n",
      "RMSE2 =  0.261291202243\n",
      "AUC =  0.89156268568\n",
      "recal =  0.823529411765\n",
      "precision =  0.84\n",
      "f1Score =  0.831683168317\n",
      "\n",
      "accuracy =  0.908032128514\n",
      "AUC =  0.855220935123\n",
      "recal =  0.765930881724\n",
      "precision =  0.780709781382\n",
      "f1 =  0.772883311306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    r1['down'] = down\n",
    "    r1['up'] = up\n",
    "    r1['thres'] = threshold\n",
    "    writeResults={}\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''  test = SelectKBest(score_func=chi2,k = 500)\n",
    "    fit1 = test.fit(xTraining1, yTraining1)\n",
    "    xTraining1 = fit1.transform(xTraining1)\n",
    "\n",
    "    fit2 = test.fit(xTest1, yTest)\n",
    "    xTest1 = fit2.transform(xTest1)\n",
    "\n",
    "    fit3 = test.fit(XX, Y)\n",
    "    XX = fit3.transform(XX)\n",
    "\n",
    "    print(\"xtest\", xTest1.shape)\n",
    "    print(\"xtraining\", xTraining1.shape)\n",
    "    print(\"X\", XX.shape)\n",
    "    '''\n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    #clf = NuSVC(kernel='rbf',nu=0.01)\n",
    "    clf.fit(xTraining1, yTraining1)\n",
    "    yPredict2 = clf.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict2))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "    error2 = mean_squared_error(yTest, yPredict2)\n",
    "    print(\"error 2 = \",error2)\n",
    "    RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "    print(\"RMSE2 = \",RMSE2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict2)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict2)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict2)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict2)\n",
    "    r1['f1'] = f1_score(yTest, yPredict2, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "   # results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    writeResult(path,'svm'+i,writeResults,i)\n",
    "    writeResultConf(path,'svm'+i,writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low97\n",
      "new shape =  (4980, 7515)\n",
      "new shape =  (4482, 7515)\n",
      "new shape =  (498, 7515)\n",
      "(4980, 22545)\n",
      "(4482, 22545)\n",
      "(498, 22545)\n",
      "0.809236947791\n",
      "[[396   0]\n",
      " [ 95   7]]\n",
      "error 2 =  0.190763052209\n",
      "RMSE2 =  0.436764298231\n",
      "AUC =  0.53431372549\n",
      "recal =  0.0686274509804\n",
      "precision =  1.0\n",
      "f1Score =  0.128440366972\n",
      "\n",
      "accuracy =  0.80843373494\n",
      "AUC =  0.53172318974\n",
      "recal =  0.0634463794793\n",
      "precision =  1.0\n",
      "f1 =  0.118827454727\n",
      "\n",
      "Category =  low100\n",
      "new shape =  (4980, 883)\n",
      "new shape =  (4482, 883)\n",
      "new shape =  (498, 883)\n",
      "(4980, 2649)\n",
      "(4482, 2649)\n",
      "(498, 2649)\n",
      "0.853413654618\n",
      "[[396   0]\n",
      " [ 73  29]]\n",
      "error 2 =  0.146586345382\n",
      "RMSE2 =  0.382865962683\n",
      "AUC =  0.642156862745\n",
      "recal =  0.28431372549\n",
      "precision =  1.0\n",
      "f1Score =  0.442748091603\n",
      "\n",
      "accuracy =  0.850803212851\n",
      "AUC =  0.63692309548\n",
      "recal =  0.273846190961\n",
      "precision =  1.0\n",
      "f1 =  0.427022207713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    r1['down'] = down\n",
    "    r1['up'] = up\n",
    "    r1['thres'] = threshold\n",
    "    writeResults={}\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''  test = SelectKBest(score_func=chi2,k = 500)\n",
    "    fit1 = test.fit(xTraining1, yTraining1)\n",
    "    xTraining1 = fit1.transform(xTraining1)\n",
    "\n",
    "    fit2 = test.fit(xTest1, yTest)\n",
    "    xTest1 = fit2.transform(xTest1)\n",
    "\n",
    "    fit3 = test.fit(XX, Y)\n",
    "    XX = fit3.transform(XX)\n",
    "\n",
    "    print(\"xtest\", xTest1.shape)\n",
    "    print(\"xtraining\", xTraining1.shape)\n",
    "    print(\"X\", XX.shape)\n",
    "    '''\n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    \n",
    "    clf = SVC()\n",
    "    #clf = NuSVC(kernel='rbf',nu=0.01)\n",
    "    clf.fit(xTraining1, yTraining1)\n",
    "    yPredict2 = clf.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict2))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "    error2 = mean_squared_error(yTest, yPredict2)\n",
    "    print(\"error 2 = \",error2)\n",
    "    RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "    print(\"RMSE2 = \",RMSE2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict2)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict2)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict2)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict2)\n",
    "    r1['f1'] = f1_score(yTest, yPredict2, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "   # results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    writeResult(path,'svmnonlinear'+i,writeResults,i)\n",
    "    writeResultConf(path,'svmnonlinear'+i,writeResults2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low97\n",
      "new shape =  (4980, 7515)\n",
      "new shape =  (4482, 7515)\n",
      "new shape =  (498, 7515)\n",
      "(4980, 22545)\n",
      "(4482, 22545)\n",
      "(498, 22545)\n",
      "0.957831325301\n",
      "[[392   4]\n",
      " [ 17  85]]\n",
      "error 4 =  0.0421686746988\n",
      "RMSE4 =  0.205350127097\n",
      "AUC =  0.911616161616\n",
      "recal =  0.833333333333\n",
      "precision =  0.955056179775\n",
      "f1Score =  0.890052356021\n",
      "\n",
      "accuracy =  0.942570281124\n",
      "AUC =  0.8953020223\n",
      "recal =  0.815389972627\n",
      "precision =  0.895422447248\n",
      "f1 =  0.853226640615\n",
      "\n",
      "Category =  low100\n",
      "new shape =  (4980, 883)\n",
      "new shape =  (4482, 883)\n",
      "new shape =  (498, 883)\n",
      "(4980, 2649)\n",
      "(4482, 2649)\n",
      "(498, 2649)\n",
      "0.94578313253\n",
      "[[388   8]\n",
      " [ 19  83]]\n",
      "error 4 =  0.0542168674699\n",
      "RMSE4 =  0.232845157712\n",
      "AUC =  0.896761734997\n",
      "recal =  0.813725490196\n",
      "precision =  0.912087912088\n",
      "f1Score =  0.860103626943\n",
      "\n",
      "accuracy =  0.932530120482\n",
      "AUC =  0.868528002344\n",
      "recal =  0.760049968781\n",
      "precision =  0.895480314828\n",
      "f1 =  0.821648002003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    writeResults={}\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "   \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''test = SelectKBest(score_func=chi2,k = 500)\n",
    "    fit1 = test.fit(xTraining1, yTraining1)\n",
    "    xTraining1 = fit1.transform(xTraining1)\n",
    "\n",
    "    fit2 = test.fit(xTest1, yTest)\n",
    "    xTest1 = fit2.transform(xTest1)\n",
    "\n",
    "    fit3 = test.fit(XX, Y)\n",
    "    XX = fit3.transform(XX)\n",
    "\n",
    "    print(\"xtest\", xTest1.shape)\n",
    "    print(\"xtraining\", xTraining1.shape)\n",
    "    print(\"X\", XX.shape)'''\n",
    "   \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "     \n",
    "\n",
    "    #lr_clf = linear_model.LogisticRegression()\n",
    " \n",
    "    lr_clf = linear_model.LogisticRegressionCV()\n",
    "    lr_clf.fit(xTraining1, yTraining1)\n",
    "    \n",
    "    yPredict4 = lr_clf.predict(xTest1)\n",
    "\n",
    "    print(metrics.accuracy_score(yTest,yPredict4))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "    error4 = mean_squared_error(yTest, yPredict4)\n",
    "    print(\"error 4 = \",error4)\n",
    "    RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "    print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict4)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict4)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict4)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict4)\n",
    "    r1['f1'] = f1_score(yTest, yPredict4, average='binary')\n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = lr_clf, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "   # results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    writeResult(path,'llrcv'+i,writeResults,i)\n",
    "    writeResultConf(path,'llrcv'+i,writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape =  (4980, 7515)\n",
      "before =  6769\n",
      "after =  6769\n",
      "snpsIds =  30\n",
      "idToName =  7799\n",
      "new shape =  (4980, 883)\n",
      "before =  883\n",
      "after =  883\n",
      "snpsIds =  30\n",
      "idToName =  7799\n"
     ]
    }
   ],
   "source": [
    "for iCat in categories:\n",
    "    \n",
    "    ids['coef']={}\n",
    "    XX = createNewTable(snpReduc[iCat],X)\n",
    "\n",
    "    lr_clf = linear_model.LogisticRegressionCV()\n",
    "    lr_clf.fit(XX, Y)\n",
    "\n",
    "    coefs=lr_clf.coef_[0]\n",
    "    print(\"before = \",len(set(coefs)))\n",
    "    ''' for i in range(len(coefs)):\n",
    "        coefs[i] = abs(coefs[i])'''\n",
    "\n",
    "    print(\"after = \",len(set(coefs)))\n",
    "\n",
    "    idToName = {}\n",
    "    nameToId = {}\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]] = []\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]].append(i)\n",
    "        idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "    ids['coef']['nameToId'] = nameToId\n",
    "    ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "    sc = sorted(coefs )\n",
    "\n",
    "    top_30 = []\n",
    "\n",
    "    for i in sc[-30:]:\n",
    "\n",
    "        snp = ids['coef']['nameToId'][i][0]\n",
    "        ids['coef']['nameToId'][i].remove(snp)\n",
    "        top_30.append(snpReduc[iCat][snp])\n",
    "     #   top_30.append(snp)\n",
    "\n",
    "    #snpReduc['low'] = top_30\n",
    "\n",
    "    write.writeSnpsUsed(top_30,ids['snps']['idToName'],chromosomes,iCat+'_not_abs_balanced')\n",
    "    #write.writeSnpsUsed(top_30,ids['snps']['idToName'],chromosomes,'top_30_all_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape =  (4980, 7515)\n",
      "before =  6769\n",
      "after =  6769\n",
      "snpsIds =  30\n",
      "idToName =  7799\n",
      "new shape =  (4980, 883)\n",
      "before =  883\n",
      "after =  883\n",
      "snpsIds =  30\n",
      "idToName =  7799\n"
     ]
    }
   ],
   "source": [
    "for iCat in categories:\n",
    "    \n",
    "    ids['coef']={}\n",
    "    XX = createNewTable(snpReduc[iCat],X)\n",
    "\n",
    "    lr_clf = linear_model.LogisticRegressionCV()\n",
    "    lr_clf.fit(XX, Y)\n",
    "\n",
    "    coefs=lr_clf.coef_[0]\n",
    "    print(\"before = \",len(set(coefs)))\n",
    "    for i in range(len(coefs)):\n",
    "        coefs[i] = abs(coefs[i])\n",
    "\n",
    "    print(\"after = \",len(set(coefs)))\n",
    "\n",
    "    idToName = {}\n",
    "    nameToId = {}\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]] = []\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]].append(i)\n",
    "        idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "    ids['coef']['nameToId'] = nameToId\n",
    "    ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "    sc = sorted(coefs )\n",
    "\n",
    "    top_30 = []\n",
    "\n",
    "    for i in sc[-30:]:\n",
    "\n",
    "        snp = ids['coef']['nameToId'][i][0]\n",
    "        ids['coef']['nameToId'][i].remove(snp)\n",
    "        top_30.append(snpReduc[iCat][snp])\n",
    "     #   top_30.append(snp)\n",
    "\n",
    "    #snpReduc['low'] = top_30\n",
    "\n",
    "    write.writeSnpsUsed(top_30,ids['snps']['idToName'],chromosomes,iCat+'_abs_balanced')\n",
    "    #write.writeSnpsUsed(top_30,ids['snps']['idToName'],chromosomes,'top_30_all_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for iCat in categories:\\n    \\n    ids[\\'coef\\']={}\\n  #  XX = createNewTable(snpReduc[iCat],X)\\n\\n    lr_clf = linear_model.LogisticRegressionCV()\\n    lr_clf.fit(X, Y)\\n\\n    coefs=lr_clf.coef_[0]\\n    print(\"before = \",len(set(coefs)))\\n    for i in range(len(coefs)):\\n        coefs[i] = abs(coefs[i])\\n\\n    print(\"after = \",len(set(coefs)))\\n\\n    idToName = {}\\n    nameToId = {}\\n\\n    for i in range(len(coefs)):\\n        nameToId[coefs[i]] = []\\n\\n    for i in range(len(coefs)):\\n        nameToId[coefs[i]].append(i)\\n        idToName[i] = coefs[i]\\n\\n\\n    ids[\\'coef\\'][\\'nameToId\\'] = nameToId\\n    ids[\\'coef\\'][\\'idToName\\'] = idToName\\n\\n\\n    sc = sorted(coefs )\\n\\n    top_30 = []\\n\\n    for i in sc[-30:]:\\n\\n        snp = ids[\\'coef\\'][\\'nameToId\\'][i][0]\\n        ids[\\'coef\\'][\\'nameToId\\'][i].remove(snp)\\n       # top_30.append(snpReduc[iCat][snp])\\n        top_30.append(snp)\\n\\n    #snpReduc[\\'low\\'] = top_30\\n\\n  #  write.writeSnpsUsed(top_30,ids[\\'snps\\'][\\'idToName\\'],chromosomes,iCat+\\'_abs_balanced\\')\\n    write.writeSnpsUsed(top_30,ids[\\'snps\\'][\\'idToName\\'],chromosomes,\\'_all_abs\\')\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for iCat in categories:\n",
    "    \n",
    "    ids['coef']={}\n",
    "  #  XX = createNewTable(snpReduc[iCat],X)\n",
    "\n",
    "    lr_clf = linear_model.LogisticRegressionCV()\n",
    "    lr_clf.fit(X, Y)\n",
    "\n",
    "    coefs=lr_clf.coef_[0]\n",
    "    print(\"before = \",len(set(coefs)))\n",
    "    for i in range(len(coefs)):\n",
    "        coefs[i] = abs(coefs[i])\n",
    "\n",
    "    print(\"after = \",len(set(coefs)))\n",
    "\n",
    "    idToName = {}\n",
    "    nameToId = {}\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]] = []\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]].append(i)\n",
    "        idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "    ids['coef']['nameToId'] = nameToId\n",
    "    ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "    sc = sorted(coefs )\n",
    "\n",
    "    top_30 = []\n",
    "\n",
    "    for i in sc[-30:]:\n",
    "\n",
    "        snp = ids['coef']['nameToId'][i][0]\n",
    "        ids['coef']['nameToId'][i].remove(snp)\n",
    "       # top_30.append(snpReduc[iCat][snp])\n",
    "        top_30.append(snp)\n",
    "\n",
    "    #snpReduc['low'] = top_30\n",
    "\n",
    "  #  write.writeSnpsUsed(top_30,ids['snps']['idToName'],chromosomes,iCat+'_abs_balanced')\n",
    "    write.writeSnpsUsed(top_30,ids['snps']['idToName'],chromosomes,'_all_abs')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low97\n",
      "new shape =  (4980, 7515)\n",
      "new shape =  (4482, 7515)\n",
      "new shape =  (498, 7515)\n",
      "(4980, 22545)\n",
      "(4482, 22545)\n",
      "(498, 22545)\n",
      "0.451807228916\n",
      "[[135 261]\n",
      " [ 12  90]]\n",
      "error 6 =  0.548192771084\n",
      "RMSE6 =  0.740400412672\n",
      "AUC =  0.611631016043\n",
      "recal =  0.882352941176\n",
      "precision =  0.25641025641\n",
      "f1Score =  0.397350993377\n",
      "\n",
      "accuracy =  0.505823293173\n",
      "AUC =  0.642777859447\n",
      "recal =  0.874362913852\n",
      "precision =  0.27679361389\n",
      "f1 =  0.420040948537\n",
      "\n",
      "\n",
      "Category =  low100\n",
      "new shape =  (4980, 883)\n",
      "new shape =  (4482, 883)\n",
      "new shape =  (498, 883)\n",
      "(4980, 2649)\n",
      "(4482, 2649)\n",
      "(498, 2649)\n",
      "0.455823293173\n",
      "[[133 263]\n",
      " [  8  94]]\n",
      "error 6 =  0.544176706827\n",
      "RMSE6 =  0.737683337773\n",
      "AUC =  0.628713606655\n",
      "recal =  0.921568627451\n",
      "precision =  0.263305322129\n",
      "f1Score =  0.409586056645\n",
      "\n",
      "accuracy =  0.43734939759\n",
      "AUC =  0.61262128912\n",
      "recal =  0.908986033872\n",
      "precision =  0.255123523267\n",
      "f1 =  0.397409879847\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    writeResults={}\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "   \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "      test = SelectKBest(score_func=chi2,k = 500)\n",
    "    fit1 = test.fit(xTraining1, yTraining1)\n",
    "    xTraining1 = fit1.transform(xTraining1)\n",
    "\n",
    "    fit2 = test.fit(xTest1, yTest)\n",
    "    xTest1 = fit2.transform(xTest1)\n",
    "\n",
    "    fit3 = test.fit(XX, Y)\n",
    "    XX = fit3.transform(XX)\n",
    "\n",
    "    print(\"xtest\", xTest1.shape)\n",
    "    print(\"xtraining\", xTraining1.shape)\n",
    "    print(\"X\", XX.shape)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "    \n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(xTraining1, yTraining1)\n",
    "    yPredict6 = gnb.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict6))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "    error6 = mean_squared_error(yTest, yPredict6)\n",
    "    print(\"error 6 = \",error6)\n",
    "    RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "    print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "    r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10,classifier = gnb, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    print()\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "  #  results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    writeResult(path,'gnb'+i,writeResults,i)\n",
    "    writeResultConf(path,'gnb'+i,writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4482,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xTraining.shape\n",
    "yTraining1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERNOULLI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low97\n",
      "new shape =  (4980, 7515)\n",
      "new shape =  (4482, 7515)\n",
      "new shape =  (498, 7515)\n",
      "(4980, 22545)\n",
      "(4482, 22545)\n",
      "(498, 22545)\n",
      "0.769076305221\n",
      "[[305  91]\n",
      " [ 24  78]]\n",
      "error 6 =  0.230923694779\n",
      "RMSE6 =  0.48054520576\n",
      "AUC =  0.767453951277\n",
      "recal =  0.764705882353\n",
      "precision =  0.461538461538\n",
      "f1Score =  0.575645756458\n",
      "\n",
      "accuracy =  0.787751004016\n",
      "AUC =  0.773184835001\n",
      "recal =  0.747926321653\n",
      "precision =  0.488265010107\n",
      "f1 =  0.589837517265\n",
      "\n",
      "\n",
      "Category =  low100\n",
      "new shape =  (4980, 883)\n",
      "new shape =  (4482, 883)\n",
      "new shape =  (498, 883)\n",
      "(4980, 2649)\n",
      "(4482, 2649)\n",
      "(498, 2649)\n",
      "0.939759036145\n",
      "[[379  17]\n",
      " [ 13  89]]\n",
      "error 6 =  0.0602409638554\n",
      "RMSE6 =  0.245440346837\n",
      "AUC =  0.914809863339\n",
      "recal =  0.872549019608\n",
      "precision =  0.839622641509\n",
      "f1Score =  0.855769230769\n",
      "\n",
      "accuracy =  0.934738955823\n",
      "AUC =  0.898480536383\n",
      "recal =  0.836908973694\n",
      "precision =  0.844452892416\n",
      "f1 =  0.839752578934\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''xTraining1 = createNewTable(snpReduc['low'],xTraining)\n",
    "lr_clf = linear_model.LogisticRegressionCV()\n",
    "lr_clf.fit(xTraining1, yTraining1)\n",
    "\n",
    "coefs=lr_clf.coef_[0]\n",
    "top_20 = np.argpartition(coefs, -50)[-50:]\n",
    "#top_20 = np.argpartition(coefs, 50)[:50]\n",
    "removedSnps = []\n",
    "for i in range(len(snpReduc['low'])):\n",
    "    if i not in top_20:\n",
    "        removedSnps.append(snpReduc['low'][i])'''\n",
    "\n",
    "\n",
    "\n",
    "for i in categories:\n",
    "   \n",
    "    r1 = {}\n",
    "    writeResults={}\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "   \n",
    "   \n",
    "  \n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    test = SelectKBest(score_func=chi2,k = 500)\n",
    "    fit1 = test.fit(xTraining1, yTraining1)\n",
    "    xTraining1 = fit1.transform(xTraining1)\n",
    "\n",
    "    fit2 = test.fit(xTest1, yTest)\n",
    "    xTest1 = fit2.transform(xTest1)\n",
    "\n",
    "    fit3 = test.fit(XX, Y)\n",
    "    XX = fit3.transform(XX)\n",
    "    print(\"xtest\", xTest1.shape)\n",
    "    print(\"xtraining\", xTraining1.shape)\n",
    "    print(\"X\", XX.shape)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "    \n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "\n",
    "    bern = BernoulliNB()\n",
    "    bern.fit(xTraining1, yTraining1)\n",
    "    yPredict6 = bern.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict6))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "    error6 = mean_squared_error(yTest, yPredict6)\n",
    "    print(\"error 6 = \",error6)\n",
    "    RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "    print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "    r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10,classifier = bern, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    print()\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "  #  results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    writeResult(path,'bernoulli'+i,writeResults,i)\n",
    "    writeResultConf(path,'bernoulli'+i,writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l= [5,6,7,2,3,4,10,6,7,9,8,5]\\ntop_3 = np.argpartition(l,3)[:3]\\nprint(top_3)\\nremovedSnps=[]\\nfor i in range(len(l)):\\n    if i not in top_3:\\n        removedSnps.append(l[i])\\nprint(removedSnps)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''l= [5,6,7,2,3,4,10,6,7,9,8,5]\n",
    "top_3 = np.argpartition(l,3)[:3]\n",
    "print(top_3)\n",
    "removedSnps=[]\n",
    "for i in range(len(l)):\n",
    "    if i not in top_3:\n",
    "        removedSnps.append(l[i])\n",
    "print(removedSnps)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"XX = createNewTable(snpReduc['low'],X)\\n#enc = OneHotEncoder(n_values =3) \\n#enc.fit(XX) \\n#XX = enc.fit_transform(XX)\\n#XX = XX.toarray()\\nprint(XX.shape)\\n\\nre = cross_val_score(bern, XX, Y, cv=10)\\nprint(sum(re)/10)\\n\\nprint()\\nXX = X\\n#enc = OneHotEncoder(n_values =3) \\n#enc.fit(XX) \\n#XX = enc.fit_transform(XX)\\n#XX = XX.toarray()\\nprint(XX.shape)\\nre = cross_val_score(bern, XX, Y, cv=10)\\nprint(sum(re)/10)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''XX = createNewTable(snpReduc['low'],X)\n",
    "#enc = OneHotEncoder(n_values =3) \n",
    "#enc.fit(XX) \n",
    "#XX = enc.fit_transform(XX)\n",
    "#XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "re = cross_val_score(bern, XX, Y, cv=10)\n",
    "print(sum(re)/10)\n",
    "\n",
    "print()\n",
    "XX = X\n",
    "#enc = OneHotEncoder(n_values =3) \n",
    "#enc.fit(XX) \n",
    "#XX = enc.fit_transform(XX)\n",
    "#XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "re = cross_val_score(bern, XX, Y, cv=10)\n",
    "print(sum(re)/10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low97\n",
      "new shape =  (4980, 7515)\n",
      "new shape =  (4482, 7515)\n",
      "new shape =  (498, 7515)\n",
      "(4980, 22545)\n",
      "(4482, 22545)\n",
      "(498, 22545)\n",
      "0.68875502008\n",
      "[[317  79]\n",
      " [ 76  26]]\n",
      "error 4 =  0.31124497992\n",
      "RMSE4 =  0.557893340989\n",
      "AUC =  0.527703505645\n",
      "recal =  0.254901960784\n",
      "precision =  0.247619047619\n",
      "f1Score =  0.251207729469\n",
      "\n",
      "accuracy =  0.69859437751\n",
      "AUC =  0.535029726735\n",
      "recal =  0.257977883007\n",
      "precision =  0.259768567804\n",
      "f1 =  0.257712301245\n",
      "\n",
      "Category =  low100\n",
      "new shape =  (4980, 883)\n",
      "new shape =  (4482, 883)\n",
      "new shape =  (498, 883)\n",
      "(4980, 2649)\n",
      "(4482, 2649)\n",
      "(498, 2649)\n",
      "0.684738955823\n",
      "[[315  81]\n",
      " [ 76  26]]\n",
      "error 4 =  0.315261044177\n",
      "RMSE4 =  0.561481116492\n",
      "AUC =  0.525178253119\n",
      "recal =  0.254901960784\n",
      "precision =  0.242990654206\n",
      "f1Score =  0.248803827751\n",
      "\n",
      "accuracy =  0.692369477912\n",
      "AUC =  0.528628721165\n",
      "recal =  0.251890405107\n",
      "precision =  0.250674639965\n",
      "f1 =  0.25092672988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    writeResults={}\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "   \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' test = SelectKBest(score_func=chi2,k = 500)\n",
    "    fit1 = test.fit(xTraining1, yTraining1)\n",
    "    xTraining1 = fit1.transform(xTraining1)\n",
    "\n",
    "    fit2 = test.fit(xTest1, yTest)\n",
    "    xTest1 = fit2.transform(xTest1)\n",
    "\n",
    "    fit3 = test.fit(XX, Y)\n",
    "    XX = fit3.transform(XX)\n",
    "    print(\"xtest\", xTest1.shape)\n",
    "    print(\"xtraining\", xTraining1.shape)\n",
    "    print(\"X\", XX.shape)\n",
    "    '''\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    clf= tree.DecisionTreeClassifier()\n",
    "    \n",
    "    #clf = BaggingClassifier(clf1, n_estimators=100, max_samples=2,\n",
    "     #                   random_state=1)\n",
    "    \n",
    "    clf.fit(xTraining1, yTraining1)\n",
    "    yPredict4 = clf.predict(xTest1)\n",
    "\n",
    "    print(metrics.accuracy_score(yTest,yPredict4))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "    error4 = mean_squared_error(yTest, yPredict4)\n",
    "    print(\"error 4 = \",error4)\n",
    "    RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "    print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict4)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict4)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict4)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict4)\n",
    "    r1['f1'] = f1_score(yTest, yPredict4, average='binary')\n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    results['down'] = down\n",
    "    results['up'] = up\n",
    "    results['thres'] = threshold\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len_snps'] = len(snpReduc[i])\n",
    "   # results['len snps'] = 500\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    writeResult(path,'tree'+i,writeResults,i)\n",
    "    writeResultConf(path,'tree'+i,writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz \n",
    "\n",
    "for iCat in categories:\n",
    "    featuresName = []\n",
    "    for i in range(len(snpReduc[iCat])):\n",
    "        snp = snpReduc[iCat][i]\n",
    "        featuresName.append(ids['snps']['idToName'][snp])\n",
    "    xTraining1 = createNewTable(snpReduc[iCat],xTraining)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(xTraining1, yTraining1)\n",
    "    treeee = open(path+iCat+'_balancedTree.dot','w')\n",
    "    dot_data = tree.export_graphviz(clf, out_file=treeee, \n",
    "                            feature_names=featuresName,leaves_parallel =True,max_depth = 6)  \n",
    "    graph = graphviz.Source(dot_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "'''enc = OneHotEncoder(n_values =3) \n",
    "enc.fit(X) \n",
    "XX = enc.fit_transform(X)\n",
    "XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "enc.fit(xTraining) \n",
    "xTraining1 = enc.fit_transform(xTraining)\n",
    "xTraining1 = xTraining1.toarray()\n",
    "print(xTraining1.shape)\n",
    "\n",
    "enc.fit(xTest) \n",
    "xTest1 = enc.fit_transform(xTest)\n",
    "xTest1 = xTest1.toarray()\n",
    "print(xTest1.shape)'''\n",
    "    \n",
    "\n",
    "bern = BernoulliNB()\n",
    "bern.fit(xTraining, yTraining1)\n",
    "yPredict6 = bern.predict(xTest)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "\n",
    "\n",
    "writeResults2['all'] = r1\n",
    "    \n",
    "print()\n",
    "\n",
    "results = crossValidiation(X, Y, k = 10,classifier = bern, continious = False)\n",
    "results['down'] = down\n",
    "results['up'] = up\n",
    "results['thres'] = threshold    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len_snps'] = len(X.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'bernoulli_all',writeResults,'all')\n",
    "#writeResultConf(path,'bernoulli_all',writeResults2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "'''enc = OneHotEncoder(n_values =3) \n",
    "enc.fit(X) \n",
    "XX = enc.fit_transform(X)\n",
    "XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "enc.fit(xTraining) \n",
    "xTraining1 = enc.fit_transform(xTraining)\n",
    "xTraining1 = xTraining1.toarray()\n",
    "print(xTraining1.shape)\n",
    "\n",
    "enc.fit(xTest) \n",
    "xTest1 = enc.fit_transform(xTest)\n",
    "xTest1 = xTest1.toarray()\n",
    "print(xTest1.shape)'''\n",
    "    \n",
    "\n",
    "bern = SVC(kernel='linear')\n",
    "bern.fit(xTraining, yTraining1)\n",
    "yPredict6 = bern.predict(xTest)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "   \n",
    "writeResults2['all'] = r1\n",
    "    \n",
    "print()\n",
    "\n",
    "results = crossValidiation(X, Y, k = 10,classifier = bern, continious = False)\n",
    "results['down'] = down\n",
    "results['up'] = up\n",
    "results['thres'] = threshold  \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len_snps'] = len(X.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'svm_all',writeResults,'all')\n",
    "#writeResultConf(path,'svm_all',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "'''enc = OneHotEncoder(n_values =3) \n",
    "enc.fit(X) \n",
    "XX = enc.fit_transform(X)\n",
    "XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "enc.fit(xTraining) \n",
    "xTraining1 = enc.fit_transform(xTraining)\n",
    "xTraining1 = xTraining1.toarray()\n",
    "print(xTraining1.shape)\n",
    "\n",
    "enc.fit(xTest) \n",
    "xTest1 = enc.fit_transform(xTest)\n",
    "xTest1 = xTest1.toarray()\n",
    "print(xTest1.shape)'''\n",
    "    \n",
    "\n",
    "bern = linear_model.LogisticRegressionCV()\n",
    "bern.fit(xTraining, yTraining1)\n",
    "yPredict6 = bern.predict(xTest)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "   \n",
    "#writeResults2['all'] = r1\n",
    "\n",
    "print()\n",
    "\n",
    "results = crossValidiation(X, Y, k = 10,classifier = bern, continious = False)\n",
    "results['down'] = down\n",
    "results['up'] = up\n",
    "results['thres'] = threshold    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len_snps'] = len(X.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'llr_all_CV',writeResults,'all')\n",
    "#writeResultConf(path,'llr_all_CV',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "#enc = OneHotEncoder(n_values =3) \n",
    "#enc.fit(X) \n",
    "#XX = enc.fit_transform(X)\n",
    "#XX = XX.toarray()\n",
    "#print(XX.shape)\n",
    "\n",
    "#enc.fit(xTraining) \n",
    "#xTraining1 = enc.fit_transform(xTraining)\n",
    "#xTraining1 = xTraining1.toarray()\n",
    "#print(xTraining1.shape)\n",
    "\n",
    "#enc.fit(xTest) \n",
    "#xTest1 = enc.fit_transform(xTest)\n",
    "#xTest1 = xTest1.toarray()\n",
    "#print(xTest1.shape)\n",
    "    \n",
    "\n",
    "bern = tree.DecisionTreeClassifier()\n",
    "bern.fit(xTraining, yTraining1)\n",
    "yPredict6 = bern.predict(xTest)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "   \n",
    "writeResults2['all'] = r1\n",
    "\n",
    "print()\n",
    "\n",
    "results = crossValidiation(X, Y, k = 10,classifier = bern, continious = False)\n",
    "results['down'] = down\n",
    "results['up'] = up\n",
    "results['thres'] = threshold    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len_snps'] = len(X.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'tree_all',writeResults,'all')\n",
    "#writeResultConf(path,'tree_all',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresName = []\n",
    "for i in range(len(ids['snps']['idToName'])):\n",
    "   # snp = ids['snps']['idToName'][i]\n",
    "    featuresName.append(ids['snps']['idToName'][i])\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "treeee = open(path+'all_balancedTree.dot','w')\n",
    "dot_data = tree.export_graphviz(clf, out_file=treeee, \n",
    "                            feature_names=featuresName,leaves_parallel =True,max_depth = 6)  \n",
    "graph = graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1={}\n",
    "writeResults={}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "clf = RandomForestClassifier()\n",
    "#clf.fit(xTraining1, yTraining1)\n",
    "   \n",
    "param_grid = {\n",
    "              \"n_estimators\" : [9, 18, 27, 36, 45, 54, 63],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "               \"warm_start\":[True,False]}\n",
    "    \n",
    "'''param_grid = { \n",
    "         'n_estimators':[2000,3000,5000], \n",
    "         'max_depth':[5,15,30], \n",
    "         'min_samples_split':[2,3], \n",
    "        'min_samples_leaf':[1,2],\n",
    "        \"warm_start\":[True,False],\n",
    "                \"oob_score\":[True,False]}\n",
    "'''\n",
    "    \n",
    "    # run grid search\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid,cv = 10,verbose=1)\n",
    "    \n",
    "\n",
    "\n",
    "results = crossValidiation(X, Y, k = 10, classifier = grid_search, continious = False)\n",
    "results['down'] = down\n",
    "results['up'] = up\n",
    "results['thres'] = threshold\n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "results['len_snps'] = len(X.T)\n",
    "   # results['len snps'] = 500\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'rfrall',writeResults,'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
