{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANTONIS\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\ANTONIS\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class PatientPhenotype:\n",
    "    \n",
    "    def __init__(self, eid, case, sex, yearBirth):\n",
    "        \n",
    "        self.eid = eid.strip()\n",
    "        self.case = int (case.strip())\n",
    "        self.sex = sex.strip()\n",
    "        self.yearBirth = yearBirth.strip()\n",
    "        self.snps = {}\n",
    "        \n",
    "    def getEid(self):\n",
    "        return self.eid\n",
    "     \n",
    "    def getCase(self):\n",
    "        return self.case\n",
    "    \n",
    "    def getSex(self):\n",
    "        return self.sex\n",
    "    \n",
    "    def getYearBirth(self):\n",
    "        return self.yearBirth\n",
    "        \n",
    "    def addSnps(self, snpId, allele1,allele2):\n",
    "        self.snps[snpId] = Snp(snpId,allele1,allele2)\n",
    "        \n",
    "    def snpCode(self,chromosomes = {}, snp = '', code = -1):\n",
    "    \n",
    "        if len(chromosomes.keys()) > 0:\n",
    "    \n",
    "             for i in range(len(chromosomes.keys())):\n",
    "    \n",
    "                chro = 'chr'+str(i+1)\n",
    "            \n",
    "                for snp in chromosomes[chro].keys():\n",
    "                \n",
    "                    allele1 = chromosomes[chro][snp][0].strip()\n",
    "                    allele2 = chromosomes[chro][snp][1].strip()\n",
    "                    \n",
    "                    self.snps[snp.strip()].setSnpCode(allele1,allele2)\n",
    "                    \n",
    "        else:\n",
    "            \n",
    "            self.snps[snp.strip()].setCode(code)\n",
    "            \n",
    "    def getSnpCode(self,snpId):\n",
    "        return self.snps[snpId].getSnpCode()\n",
    "    \n",
    "    def getAllele1(self,snpId):\n",
    "        return self.snps[snpId].getAllele1()\n",
    "    \n",
    "    def getAllele2(self,snpId):\n",
    "        return self.snps[snpId].getAllele2()\n",
    "        \n",
    "    def getSize(self):\n",
    "        return len(self.snps)\n",
    "        \n",
    "        \n",
    "class Snp:\n",
    "    \n",
    "    def __init__(self,snpId,allele1,allele2):\n",
    "        \n",
    "        self.snpId = snpId\n",
    "        self.allele1 = allele1\n",
    "        self.allele2 = allele2\n",
    "        self.snpCode = -1\n",
    "        \n",
    "    def getId(self):\n",
    "        \n",
    "        return self.snpId\n",
    "        \n",
    "    def getAllele1(self):\n",
    "        \n",
    "        return self.allele1\n",
    "        \n",
    "    def getAllele2(self):\n",
    "        \n",
    "        return self.allele2\n",
    "        \n",
    "    def setSnpCode(self,allele1,allele2):\n",
    "      \n",
    "        if self.allele1.strip() == allele1.strip() and self.allele2.strip() == allele1.strip():\n",
    "            code = 2\n",
    "           \n",
    "        elif self.allele1.strip() == allele1.strip() and self.allele2.strip() != allele1.strip():\n",
    "            code = 1\n",
    "           \n",
    "        elif self.allele1.strip() != allele1.strip() and self.allele2.strip() == allele1.strip():\n",
    "            code = 1\n",
    "            \n",
    "        elif self.allele1.strip() != allele1.strip() and self.allele2.strip() != allele1.strip():\n",
    "            code = 0\n",
    "            \n",
    "        self.snpCode = code\n",
    "        \n",
    "    def setCode(self,aCode):\n",
    "        \n",
    "        self.snpCode = aCode\n",
    "        \n",
    "    def getSnpCode(self):\n",
    "        \n",
    "        return self.snpCode\n",
    "    \n",
    "class Read:\n",
    "    def __init__(self,path,numberOfChromosomes):\n",
    "        \n",
    "        self.chromosomes = {}\n",
    "        self.numberOfSnps = 0\n",
    "        self.path = path\n",
    "        self.numberOfChromosomes = numberOfChromosomes\n",
    "        \n",
    "    def readPatients(self,kind):\n",
    "        \n",
    "        patients = {}\n",
    "        \n",
    "        try:\n",
    "            f = open(self.path + kind,'r')\n",
    "            f.readline()\n",
    "            \n",
    "            \n",
    "            try:\n",
    "\n",
    "                for line in f:\n",
    "                    patients[line.split()[0].strip()] = PatientPhenotype(line.split()[0],line.split()[3],line.split()[1],line.split()[2])\n",
    "                    \n",
    "                f.close()\n",
    "\n",
    "            except Exception as x:\n",
    "                print(\"error = \",x)\n",
    "                f.close()\n",
    "                \n",
    "        except Exception as x:\n",
    "            \n",
    "            print(\"error = \",x)\n",
    "            f.close()\n",
    "        \n",
    "        return patients\n",
    "        \n",
    "    \n",
    "    def readSnps(self,fileKind):\n",
    "        \n",
    "        for i in range(self.numberOfChromosomes):\n",
    "    \n",
    "            chro = 'chr'+str(i+1)\n",
    "            path = self.path + chro + fileKind\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                f = open(path,'r')\n",
    "                f.readline()\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    self.chromosomes[chro] = self.__readSnpsOfChromosome(f)\n",
    "\n",
    "                    f.close()\n",
    "\n",
    "                except Exception as x:\n",
    "                    print(\"error = \",x)\n",
    "                    f.close()\n",
    "                    \n",
    "            except Exception as x:\n",
    "            \n",
    "                print(\"error = \",x)\n",
    "                f.close()\n",
    "                \n",
    "    \n",
    "                \n",
    "        return self.chromosomes\n",
    "    \n",
    "    def __readSnpsOfChromosome(self,file):\n",
    "        \n",
    "        snps = {} \n",
    "       \n",
    "        for line in file:\n",
    "            \n",
    "            alleles = []\n",
    "            alleles.append(line.split()[3].strip())\n",
    "            alleles.append(line.split()[6].strip())\n",
    "            \n",
    "            try:\n",
    "                if line.split()[1].strip() != '.':\n",
    "                    snps[line.split()[1].strip()] = alleles\n",
    "                    self.numberOfSnps += 1\n",
    "                    \n",
    "            except Exception as x:\n",
    "                print(\"error = \",x)\n",
    "                \n",
    "                file.close()\n",
    "                \n",
    "        return snps\n",
    "        \n",
    "    def readLgen(self,patients,kind = ''):\n",
    "        \n",
    "        \n",
    "        for i in range(self.numberOfChromosomes):\n",
    "            \n",
    "            chro = 'chr'+str(i+1)\n",
    "            path = self.path + chro + kind +'.lgen'\n",
    "    \n",
    "            if os.path.exists(path):\n",
    "                \n",
    "                try:\n",
    "                    f = open(path,'r')\n",
    "                \n",
    "                    for line in f:\n",
    "                        try:\n",
    "                            if line.split()[0].strip() in patients.keys():\n",
    "\n",
    "                                patients[line.split()[0].strip()].addSnps(line.split()[2].strip(),line.split()[3].strip(),\n",
    "                                                                                        line.split()[4].strip())\n",
    "                        except Exception as x:\n",
    "                            print(\"error = \",x)\n",
    "                            f.close()\n",
    "                            \n",
    "                    f.close()\n",
    "              \n",
    "                except Exception as x:\n",
    "                        print(\"error = \",x)\n",
    "                        f.close()\n",
    "                \n",
    "       \n",
    "        return patients\n",
    "    \n",
    "    def getListOfSnps(self):\n",
    "        snps = []\n",
    "        for i in range(self.numberOfChromosomes):\n",
    "            chro = 'chr'+str(i+1)\n",
    "            for snp in self.chromosomes[chro].keys():\n",
    "                snps.append(snp)\n",
    "        \n",
    "        return snps\n",
    "        \n",
    "    def getNumberOfSnps(self):\n",
    "        \n",
    "        return self.numberOfSnps\n",
    "    \n",
    "    \n",
    "    def readSnpsCode(self,patients,kind = ''):\n",
    "        \n",
    "        try:\n",
    "            read = open(self.path + kind + 'snpCode.txt','r')\n",
    "            read.readline()\n",
    "            read.readline()\n",
    "            print(\"mphka2\")\n",
    "            for line in read:   \n",
    "\n",
    "                try:\n",
    "                    patient = line.split('\\t')[0].strip()\n",
    "                    snp = line.split('\\t')[1].strip()\n",
    "                    code = int (line.split('\\t')[2].strip())\n",
    "                    allele1 = line.split('\\t')[3].strip()\n",
    "                    allele2 = line.split('\\t')[4].strip()\n",
    "                    if patient in patients.keys() and snp != '.':\n",
    "                        patients[patient].addSnps(snp,allele1,allele2)\n",
    "                        patients[patient].snpCode(snp = snp,code = code)\n",
    "                except Exception as x:\n",
    "                    print(\"error = \",x)\n",
    "                    read.close()\n",
    "            \n",
    "            read.close()\n",
    "    \n",
    "        except Exception as x:\n",
    "            print(\"error = \",x)\n",
    "            read.close()\n",
    "            \n",
    "        return patients\n",
    "            \n",
    "        \n",
    "    \n",
    "class Write:\n",
    "    \n",
    "    def __init__(self,path,numberOfChromosomes):\n",
    "        \n",
    "        self.path = path\n",
    "        self.numberOfChromosomes = numberOfChromosomes\n",
    "        \n",
    "    def writePatientsList(self,patients,kind):\n",
    "        \n",
    "        path = self.path + kind\n",
    "        \n",
    "        try:\n",
    "            write = open(path,'w')\n",
    "            for patient in patients.keys():\n",
    "                write.write(patient.strip() + '\\n')\n",
    "            \n",
    "            write.close()\n",
    "        except Exception as x:\n",
    "            print(\"error = \",x)\n",
    "            write.close()\n",
    "        \n",
    "        \n",
    "    def writeSnpsList(self,chromosomes):\n",
    "        \n",
    "        for i in range(self.numberOfChromosomes):\n",
    "    \n",
    "            chro = 'chr'+str(i+1)\n",
    "            try:\n",
    "                path = self.path + chro + 'snpList.txt'\n",
    "                write = open(path,'w')\n",
    "\n",
    "                for snp in chromosomes[chro].keys():\n",
    "                    write.write(snp.strip() + '\\n')\n",
    "\n",
    "                write.close()\n",
    "            except Exception as x:\n",
    "                print(\"error = \",x)\n",
    "                write.close()\n",
    "            \n",
    "    def writeSnpsUsed(self,snpsIds,idToName,chromosomes,name = None):\n",
    "        \n",
    "        if not name:\n",
    "            print(\"give a name to file\")\n",
    "            return\n",
    "        \n",
    "        path = self.path + name\n",
    "        \n",
    "        if os.path.exists(path):\n",
    "            print(\"the file already exists........ give another name\")\n",
    "            return\n",
    "        \n",
    "        snps = []\n",
    "        for i in snpsIds:\n",
    "            snps.append(idToName[i])\n",
    "            \n",
    "        print(\"snpsIds = \",len(snpsIds))\n",
    "        print(\"idToName = \",len(idToName))\n",
    "        \n",
    "        write = open(path,'w')\n",
    "        try:\n",
    "            for i in range(1,23):\n",
    "            \n",
    "                chro = 'chr'+str(i)\n",
    "                chromList = chromosomes[chro]\n",
    "\n",
    "                if len(list(set(chromList) - set(snps))) < len(chromList):\n",
    "                    write.write(\"chromosome\"+(i)+'\\n')\n",
    "                    for j in snps:\n",
    "                        if j in chromosomes[chro]:\n",
    "                            write.write(j + '\\n')\n",
    "                    write.write('\\n')\n",
    "\n",
    "            write.close()\n",
    "        except Exception as x:\n",
    "            print(\"error = \",x)\n",
    "            write.close()\n",
    "            \n",
    "    def saveData(self,ids,patients,patientKind,data,chroms = {}):\n",
    "    \n",
    "        self.__snpCodeLog(ids['patients']['idToName'],ids['snps']['idToName'],patients,data,patientKind)\n",
    "        \n",
    "    def __patientsLogFile(self,ids,patientKind):\n",
    "        \n",
    "        write = open(self.path + patientKind + 'Ids.txt','w')\n",
    "        \n",
    "        write.write(str(len(ids['nameToId'])) + '\\n')\n",
    "        \n",
    "        for patient in ids['nameToId'].keys():\n",
    "            \n",
    "            write.write(patient.strip() + '\\t' + str(ids['nameToId'][patient]).strip() + '\\n')\n",
    "            \n",
    "        write.close()\n",
    "        \n",
    "    def __snpsLogFile(self,ids,chroms):\n",
    "        \n",
    "        if len(chroms.keys()) > 0:\n",
    "        \n",
    "            write = open(self.path + 'SnpsIds.txt','w')\n",
    "        \n",
    "            write.write(str(len(ids['nameToId'])) + '\\n')\n",
    "        \n",
    "            for chro in chroms.keys():\n",
    "              \n",
    "                for snp in chroms[chro].keys():\n",
    "                    write.write(snp.strip() + '\\t' + str(ids['nameToId'][snp.strip()]).strip() + '\\n')\n",
    "            \n",
    "            write.close()\n",
    "            \n",
    "    def __snpCodeLog(self,patientsIds,snpsIds,patients,data,patientKind):\n",
    "        \n",
    "        write = open(self.path + patientKind + 'snpCode.txt','w')\n",
    "        \n",
    "        write.write(str(len(patientsIds)) + '\\n')\n",
    "        write.write(str(len(snpsIds)) + '\\n')\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data.T)):\n",
    "                allele1 = patients[patientsIds[i]].getAllele1(snpsIds[j])\n",
    "                allele2 = patients[patientsIds[i]].getAllele2(snpsIds[j])\n",
    "                write.write(patientsIds[i].strip() + '\\t' + snpsIds[j].strip() + '\\t' + str(data[i,j]).strip() + '\\t' \n",
    "                                                                            + allele1.strip() + '\\t' + allele2.strip() + '\\n')\n",
    "                \n",
    "        write.close()\n",
    "        \n",
    "        \n",
    "            \n",
    "class DataSet:\n",
    "    \n",
    "    def __init__(self,patients,ids):\n",
    "        \n",
    "        self.n = len(ids['patients']['nameToId'].keys())\n",
    "        self.m =len(ids['snps']['nameToId'].keys()) \n",
    "        self.patients = patients\n",
    "        self.ids = ids\n",
    "                     \n",
    "        self.xTable = np.zeros((self.n,self.m),dtype = int)\n",
    "        self.yTable = np.zeros((self.n,),dtype = int)\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                self.xTable[i,j] = -1\n",
    "                     \n",
    "        self.__fillXTable()\n",
    "        self.__fillYTable()\n",
    "                     \n",
    "                     \n",
    "    def __fillXTable(self):\n",
    "    \n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "        \n",
    "                patient = self.ids['patients']['idToName'][i]\n",
    "                snp = self.ids['snps']['idToName'][j]\n",
    "        \n",
    "                self.xTable[i,j] = self.patients[patient].getSnpCode(snp)\n",
    "                     \n",
    "    def __fillYTable(self):\n",
    "    \n",
    "        for i in range(self.n):\n",
    "    \n",
    "            patient = self.ids['patients']['idToName'][i]\n",
    "            self.yTable[i] = self.patients[patient].getCase()\n",
    "        \n",
    "    def getXTable(self):\n",
    "                     \n",
    "        return self.xTable\n",
    "                     \n",
    "    def getYTable(self):\n",
    "                     \n",
    "        return self.yTable\n",
    "    \n",
    "\n",
    "def setIdToName(aList):\n",
    "    \n",
    "    ids = {}\n",
    "    nameToId = {}\n",
    "    idToName = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in aList:\n",
    "        \n",
    "        nameToId[i] = count\n",
    "        idToName[count] = i\n",
    "        count += 1\n",
    "        \n",
    "    ids['nameToId'] = nameToId\n",
    "    ids['idToName'] = idToName\n",
    "    \n",
    "    return ids\n",
    "\n",
    "\n",
    "def setSnpsCode(patients,chromosomes):\n",
    "    \n",
    "    for i in patients.keys():\n",
    "        patients[i].snpCode(chromosomes)\n",
    "        \n",
    "    return patients\n",
    "    \n",
    "    \n",
    "def mergeXTrainXTestTable(test,train):\n",
    "    \n",
    "    n = len(test) + len(train)\n",
    "    m = len(test.T)\n",
    "    count = 0\n",
    "    \n",
    "    mergeTable = np.zeros((n,m),dtype = int)\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        for j in range(len(train.T)):\n",
    "            mergeTable[count,j] = train[i,j]\n",
    "        count += 1\n",
    "    \n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        for j in range(len(test.T)):\n",
    "            mergeTable[count,j] = test[i,j]\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "    return mergeTable\n",
    "\n",
    "\n",
    "def mergeYTrainYTestTable(test,train):\n",
    "    \n",
    "    n = len(test) + len(train)\n",
    "   \n",
    "    count = 0\n",
    "    \n",
    "    mergeTable = np.zeros((n,),dtype = int)\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        mergeTable[count] = train[i]\n",
    "        count += 1\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        mergeTable[count] = test[i]\n",
    "        count += 1\n",
    "        \n",
    "    return mergeTable\n",
    "\n",
    "def createAllPatientsStructure(patients,patientsTest,patientsTrain,snps):\n",
    "    \n",
    "    for i in patientsTest.keys():\n",
    "        patients[i]=patientsTest[i]\n",
    "        \n",
    "    for i in patientsTrain.keys():\n",
    "        patients[i]=patientsTrain[i]\n",
    "        \n",
    "    return patients\n",
    "\n",
    "def seperatePatients(patients,allPatients):\n",
    "    \n",
    "    for patient in patients.keys():\n",
    "        \n",
    "        patients[patient] = allPatients[patient]\n",
    "        \n",
    "    return patients\n",
    "\n",
    "\n",
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "\n",
    "def tables(sampleX,sampleY,k):\n",
    "  \n",
    "    samples = {}\n",
    "    \n",
    "    for run in range(1,k+1):\n",
    "        \n",
    "        d1 = {}\n",
    "        \n",
    "\n",
    "        dataTestX = sampleX[run]\n",
    "        dataTestY = sampleY[run]\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        for i in sampleX.keys():\n",
    "\n",
    "            if i != run:\n",
    "\n",
    "                n += len(sampleX[i])\n",
    "\n",
    "        dataTrainX = np.zeros((n,len(sampleX[1].T)),dtype = int)\n",
    "        dataTrainY = np.zeros((n,),dtype = int)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sample in sampleX.keys():\n",
    "\n",
    "            if sample != run:\n",
    "\n",
    "                 for i in range(len(sampleX[sample])):\n",
    "                    for j in range(len(sampleX[sample].T)):\n",
    "                        dataTrainX[count,j] = sampleX[sample][i,j]\n",
    "\n",
    "                    dataTrainY[count] = sampleY[sample][i]\n",
    "                    count += 1\n",
    "\n",
    "        d1['trainX'] = dataTrainX\n",
    "        d1['trainY'] = dataTrainY\n",
    "        d1['testX'] = dataTestX\n",
    "        d1['testY'] = dataTestY\n",
    "        \n",
    "        samples[run] = d1\n",
    "    \n",
    "    return samples\n",
    "    \n",
    "def kSampleData(k,X,Y):\n",
    "    \n",
    "    x = int (len(X) / k)\n",
    "    allElements = np.zeros((len(X),),dtype = int)\n",
    "    \n",
    "    count1 = 1\n",
    "    sampleX = {}\n",
    "    sampleY = {}\n",
    "   \n",
    "    \n",
    "    while count1 <= k:\n",
    "        count2 = 1\n",
    "        sampleData = []\n",
    "        \n",
    "        if count1 == k:\n",
    "            x =  len(X) - ((k-1) * x)\n",
    "        \n",
    "        dataX = np.zeros((x,len(X.T)),dtype = int)\n",
    "        dataY = np.zeros((x,),dtype = int)\n",
    "        \n",
    "        while count2 <= x:\n",
    "            \n",
    "            aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            while allElements[aRand] == 1:\n",
    "                \n",
    "                aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            allElements[aRand] = 1\n",
    "            sampleData.append(aRand)\n",
    "            count2 += 1\n",
    "            \n",
    "        for i in range(len(sampleData)):\n",
    "            for j in range(len(X.T)):\n",
    "                dataX[i,j] = X[sampleData[i],j]\n",
    "            \n",
    "            dataY[i] = Y[sampleData[i]]\n",
    "            \n",
    "        sampleX[count1] = dataX\n",
    "        sampleY[count1] = dataY\n",
    "        count1 +=1\n",
    "        \n",
    "    return tables(sampleX,sampleY,k)\n",
    "\n",
    "\n",
    "def calculateJaccardSim(X):\n",
    "    \n",
    "    xNew = np.zeros((len(X.T),len(X.T)),dtype = float)\n",
    "    \n",
    "    for i in range(len(X.T)):\n",
    "        \n",
    "        for j in range(i+1,len(X.T)):\n",
    "            \n",
    "            result = metrics.jaccard_similarity_score(X[:,i],X[:,j])\n",
    "            \n",
    "            xNew[i,j] = result\n",
    "            xNew[j,i] = result\n",
    "            \n",
    "        xNew[i,i] = 1.0\n",
    "        \n",
    "    \n",
    "    return xNew            \n",
    "\n",
    "    \n",
    "def reduceFeatures(X,a,b,c = 10,method = 'Cosine_Similarity'):\n",
    "    \n",
    "    snpsOut = []\n",
    "    snpsIn = []\n",
    "    snps1 = []\n",
    "    snps2 = []\n",
    "    snpsRandom = []\n",
    "    \n",
    "    snpsReturn = {}\n",
    "    \n",
    "    if method == 'Cosine_Similarity':\n",
    "        \n",
    "        snpsCount = {}\n",
    "        print(\"size = \",len(X.T))\n",
    "        for i in range(len(X.T)):\n",
    "            \n",
    "            snpsCount[i] = 0\n",
    "        \n",
    "        #xNew = metrics.pairwise.cosine_similarity(X.T)\n",
    "        xNew = X\n",
    "        print(\"xNew shape \",xNew.shape)\n",
    "       \n",
    "        for i in range(len(xNew)):\n",
    "            for j in range(i+1,len(xNew.T)):\n",
    "                    \n",
    "                if ((xNew[i,j] - a >= 1e-10) and (xNew[i,j] - b) <= 1e-10):\n",
    "       \n",
    "                    snpsCount[j] = snpsCount[j] + 1\n",
    "                    snpsCount[i] = snpsCount[i] + 1\n",
    "                    \n",
    "        countBigThanZero = 0  \n",
    "       \n",
    "        \n",
    "        for i in snpsCount.keys():\n",
    "            if snpsCount[i] > 0:\n",
    "                countBigThanZero += 1\n",
    "        \n",
    "        print(\"countBigZero = \",countBigThanZero)\n",
    "         \n",
    "        for i in snpsCount.keys():\n",
    "            \n",
    "            if snpsCount[i] > 0:\n",
    "                snpsIn.append(i)\n",
    "            \n",
    "            if snpsCount[i] > countBigThanZero * c / 100:           \n",
    "                snps1.append(i)\n",
    "        \n",
    "        for i in range(len(X.T)):\n",
    "            if i not in snps1:\n",
    "                snps2.append(i)\n",
    "                \n",
    "        for i in snps2:\n",
    "            flag = 0\n",
    "            for j in snps2:\n",
    "                 if (1 - xNew[i,j]) <= 1e-2 and j != i:\n",
    "                        flag = 1\n",
    "                        break\n",
    "            if flag == 0:\n",
    "                snpsOut.append(i)\n",
    "                \n",
    "                \n",
    "        snpsSelected = np.zeros((len(X.T),1),dtype = int)\n",
    "     \n",
    "        for i in snpsOut:\n",
    "            snpsSelected[i] = 1\n",
    "        \n",
    "        if len(snpsOut) < len(X.T)/2:\n",
    "            size = len(snpsOut) + 1\n",
    "        elif len(snpsOut) == len(X.T):\n",
    "            size = 0\n",
    "        else:\n",
    "            size = len(X.T) - len(snpsOut) + 1\n",
    "        \n",
    "        for i in range(1,size):\n",
    "            \n",
    "            aRand = randint(0,len(X.T)-1)\n",
    "    \n",
    "            while(snpsSelected[aRand] == 1):\n",
    "\n",
    "                aRand = randint(0,len(X.T)-1)\n",
    "                \n",
    "            snpsSelected[aRand] = 1\n",
    "            snpsRandom.append(aRand)\n",
    "        \n",
    "       \n",
    "        \n",
    "        print(\"snps = \",len(snpsOut))\n",
    "        print(\"len snpsIn = \",len(snpsIn))\n",
    "        print(\"len snpsRandom = \",len(snpsRandom))\n",
    "        \n",
    "        snpsReturn['snpsOutArea'] = snpsOut\n",
    "        snpsReturn['snpsInArea'] = snpsIn\n",
    "        snpsReturn['snpsRandom'] = snpsRandom\n",
    "        \n",
    "    elif method == 'jaccard1':\n",
    "    \n",
    "        snpsPairs = {}\n",
    "        print(\"size = \",len(X.T))\n",
    "        for i in range(len(X.T)):\n",
    "            snpsPairs[i] = 0\n",
    "            \n",
    "        \n",
    "        xNew = X\n",
    "        print(\"xNew shape \",xNew.shape)\n",
    "       \n",
    "        for i in range(len(xNew)):\n",
    "            for j in range(i+1,len(xNew.T)):\n",
    "                    \n",
    "                if (xNew[i,j] - a <= 1e-10) :\n",
    "                    \n",
    "                    snpsPairs[i] = snpsPairs[i] + 1\n",
    "                    snpsPairs[j] = snpsPairs[j] + 1\n",
    "                    \n",
    "                \n",
    "        for i in snpsPairs.keys():\n",
    "            if snpsPairs[i] >= c * len(X.T) / 100:\n",
    "                snpsOut.append(i)\n",
    "       \n",
    "                   \n",
    "        \n",
    "        \n",
    "        print(\"snps = \",len(snpsOut))\n",
    "        print(\"len snpsIn = \",len(snpsIn))\n",
    "        print(\"len snpsRandom = \",len(snpsRandom))\n",
    "        \n",
    "        snpsReturn['snpsOutArea'] = snpsOut\n",
    "        snpsReturn['snpsInArea'] = snpsIn\n",
    "        snpsReturn['snpsRandom'] = snpsRandom\n",
    "        \n",
    "    \n",
    "            \n",
    "    return snpsReturn\n",
    "\n",
    "\n",
    "def createNewTable(snps,X):\n",
    "    \n",
    "    newX = np.zeros((len(X),len(snps)),dtype = int)\n",
    "    \n",
    "    for i in range(len(newX)):\n",
    "        for j in range(len(newX.T)):\n",
    "            newX[i,j] = -1\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        for j in range(len(X)):\n",
    "            \n",
    "            newX[j,i] = X[j,snps[i]]\n",
    "            \n",
    "    print(\"new shape = \",newX.shape)\n",
    "            \n",
    "    return newX\n",
    "\n",
    "\n",
    "\n",
    "def crossValidiation(X, Y, k = 1, continious = True, classifier = None,OLS = False,Logistic = False):\n",
    "    \n",
    "    if not classifier:\n",
    "        print(\"wrong!!!!!!! you have to choise a classifier\")\n",
    "        return\n",
    "    \n",
    "    results = {}\n",
    "    crossVal = {}\n",
    "    auc = {}\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    f1Score = {}\n",
    "    \n",
    "    sumResults = 0.0\n",
    "    sumCross = 0.0\n",
    "    sumAuc = 0.0\n",
    "    sumRecall = 0.0\n",
    "    sumPrecision = 0.0\n",
    "    sumF1Score = 0.0\n",
    "    \n",
    "    samples = kSampleData(k,X,Y)\n",
    "    \n",
    "    for run in range(1, k + 1):\n",
    "        \n",
    "        trainX = samples[run]['trainX']\n",
    "        trainY = samples[run]['trainY']\n",
    "        \n",
    "        testX = samples[run]['testX']\n",
    "        testY = samples[run]['testY']\n",
    "        \n",
    "        \n",
    "        if OLS:\n",
    "            classifier = sm.OLS(trainY,trainX)\n",
    "            yPredict = classifier.fit().predict(testX)\n",
    "        else:\n",
    "\n",
    "            classifier.fit(trainX, trainY)\n",
    "            yPredict = classifier.predict(testX)\n",
    "        \n",
    "        if continious:\n",
    "            \n",
    "            for i in range(len(yPredict)):\n",
    "                \n",
    "                if (abs(0 - yPredict[i]) - abs(1 - yPredict[i])) <= 1e-10 :\n",
    "                    yPredict[i] = 0\n",
    "                else:\n",
    "                    yPredict[i] = 1\n",
    "                    \n",
    "        if Logistic:\n",
    "            \n",
    "            probabilities = classifier.predict_proba(testX)\n",
    "            \n",
    "            for i in range(len(probabilities)):\n",
    "                if probabilities[i][1] >= 0.8:\n",
    "                    yPredict[i] = 1\n",
    "                else:\n",
    "                    yPredict[i] = 0\n",
    "          \n",
    "        crossVal[run] = metrics.accuracy_score(testY,yPredict)#(yPredict,testY)#\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(testY,yPredict)#(yPredict,testY)#(testY,yPredict)\n",
    "        auc[run] = metrics.auc(fpr,tpr)\n",
    "        recall[run] = metrics.recall_score(testY,yPredict)#(yPredict,testY)#(testY,yPredict)\n",
    "        precision[run] = metrics.precision_score(testY,yPredict)#(yPredict,testY)#(testY,yPredict)\n",
    "        f1Score[run] = f1_score(testY, yPredict, average='binary')\n",
    "        \n",
    "    \n",
    "    for i in crossVal.keys():\n",
    "        sumCross = sumCross + crossVal[i]\n",
    "        sumAuc = sumAuc + auc[i]\n",
    "        sumRecall = sumRecall + recall[i]\n",
    "        sumPrecision = sumPrecision + precision[i]\n",
    "        sumF1Score = sumF1Score + f1Score[i]\n",
    "    \n",
    "    results['cross'] = sumCross / k\n",
    "    results['auc'] = sumAuc / k\n",
    "    results['recall'] = sumRecall / k\n",
    "    results['precision'] = sumPrecision / k\n",
    "    results['f1'] = sumF1Score / k\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "def binaryDecode(X):\n",
    "    \n",
    "    xNew = np.zeros((len(X),len(X.T),3))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X.T)):\n",
    "            \n",
    "            if X[i,j] == 0:\n",
    "                xNew[i,j,0] = 1\n",
    "                xNew[i,j,1] = 0\n",
    "                xNew[i,j,2] = 0\n",
    "                \n",
    "            elif X[i,j] == 1:\n",
    "                xNew[i,j,0] = 0\n",
    "                xNew[i,j,1] = 1\n",
    "                xNew[i,j,2] = 0\n",
    "                \n",
    "            elif X[i,j] == 2:\n",
    "                xNew[i,j,0] = 0\n",
    "                xNew[i,j,1] = 0\n",
    "                xNew[i,j,2] = 1\n",
    "    \n",
    "    return xNew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\p = 0.0001\\\\' #bake ton fakelo pou 8a epe3ergas8eis\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\pValues\\\\pvalue = 1e-05\\\\'\n",
    "\n",
    "numberOfChromosomes = 22#'ari8mos twn xromoswmatwn'\n",
    "patientsTrain = {}\n",
    "patientsTest = {}\n",
    "allPatients = {}\n",
    "\n",
    "chromosomes = {}\n",
    "\n",
    "read = Read(path,numberOfChromosomes)\n",
    "write = Write(path,numberOfChromosomes)\n",
    "\n",
    "patients = read.readPatients('Patients.txt')\n",
    "chromosomes = read.readSnps(\".assoc\")\n",
    "write.writePatientsList(patients,'patient.txt')\n",
    "\n",
    "write.writeSnpsList(chromosomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run train_lgen bat and test_leg bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mphka\n",
      "mphka2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "snps = read.getListOfSnps()\n",
    "ids = {} \n",
    "idsTest = {}\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(path + 'snpCode.txt'):\n",
    "    print(\"mphka\")\n",
    "    patients = read.readSnpsCode(patients)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    patients = read.readLgen(patients)\n",
    "    \n",
    "   \n",
    "    patients = setSnpsCode(patients,chromosomes)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "ids['patients'] = setIdToName(list(patients.keys()))\n",
    "ids['snps'] = setIdToName(snps)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainSet = DataSet(patients,ids)\n",
    "\n",
    "\n",
    "X = trainSet.getXTable()\n",
    "Y = trainSet.getYTable()\n",
    "\n",
    "if not os.path.exists(path + 'snpCode.txt'):\n",
    "    print(\"mphka 3\")\n",
    "    write.saveData(ids,patientsTrain,'Train',xTraining,chromosomes)\n",
    "    write.saveData(idsTest,patientsTest,'Test',xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len =  4980\n",
      "index =  85.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=len(X.T))\n",
    "\n",
    "pca.fit(X)\n",
    "\n",
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "index = 0\n",
    "for i in range(0,len(var1)):\n",
    "    if var[i] > 85:\n",
    "        index = i\n",
    "        break\n",
    "        \n",
    "print(\"len = \",len(var1))\n",
    "print(\"index = \",index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=139)\n",
    "pca.fit(X)\n",
    "xTraining1 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XX = binaryDecode(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_clf = linear_model.LogisticRegression()  \n",
    "lr_clf.fit(mergeXtable, mergeYtable)\n",
    "xTraining = lr_clf.fit_transform(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt = xNew = calculateJaccardSim(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = {}\n",
    "sn = {}\n",
    "s = []\n",
    "for i in range(5415):\n",
    "    count[i] = 0\n",
    "    sn[i] = []\n",
    "for i in range(5415):\n",
    "    for j in range(i+1, 5415):\n",
    "        if Xt[i,j] - 0.3 >= 1e-10 and Xt[i,j] - 0.6 <= 1e-10 :\n",
    "            count[i] = count[i] + 1\n",
    "            count[j] = count[j] + 1\n",
    "            sn[i].append(j)\n",
    "\n",
    "\n",
    "    \n",
    "c = 0\n",
    "for i in sn.keys():\n",
    "    \n",
    "    c = c + len((sn[0]))\n",
    "              \n",
    "print(\"c = \",c)\n",
    "            \n",
    "'''c = 0\n",
    "for i in count.keys():\n",
    "    if count[i] >= 25 * 5415 /100:\n",
    "        c +=1\n",
    "   # if len(sn[i]) > 0:\n",
    "    #    print(\"i = \",i)\n",
    "    #    print(sn[i])\n",
    "    #    print()\n",
    "        \n",
    "print(\"c = \",c)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snpsReduced = reduceFeatures(Xt,0.8,0.0,c = 25,method = 'jaccard1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xTraining = createNewTable(snpsReduced['snpsOutArea'],X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snps1 = snpsReduced['snpsOutArea']\n",
    "snps2 = snpsReduced['snpsRandom']\n",
    "snps3 = snpsReduced['snpsInArea']\n",
    "\n",
    "count = 0\n",
    "for i in snps2:\n",
    "    if i in snps1:\n",
    "        count += 1\n",
    "        \n",
    "print(\"random - outArea = \",count)\n",
    "\n",
    "count = 0\n",
    "for i in snps2:\n",
    "    if i in snps3:\n",
    "        count += 1\n",
    "        \n",
    "print(\"random - inArea = \",count)\n",
    "\n",
    "count = 0\n",
    "for i in snps1:\n",
    "    if i in snps3:\n",
    "        count += 1\n",
    "        \n",
    "print(\"outArea - inArea = \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "sel = VarianceThreshold(threshold=(.4 * (1 - .9)))\n",
    "xTraining = sel.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTraining = SelectKBest(chi2, k=400).fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators = 500, random_state = 2016, verbose = 20,max_depth = None,n_jobs=2)\n",
    "rfr.fit(X, Y)\n",
    "xTraining = rfr.transform(X)\n",
    "print(xTraining.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xTraining1, xTest1, yTraining1, yTest = train_test_split(xTraining, Y, test_size=0.1, random_state=0)\n",
    "print(\"mergex = \",xTraining.shape)\n",
    "print(\"xTrain = \",xTraining1.shape)\n",
    "print(\"xTest = \",xTest1.shape)\n",
    "print(\"yTrain = \",yTraining1.shape)\n",
    "print(\"yTest = \",yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators = 100, random_state = 2017, verbose = 10,\n",
    "                            max_depth = None,n_jobs=-1)\n",
    "rfr.fit(xTraining1, yTraining1)\n",
    "yPredict3 = rfr.predict(xTest1)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(yPredict3)):\n",
    "    count += yPredict3[i]\n",
    "\n",
    "mo3 = count / len(yPredict3)\n",
    "\n",
    "for i in range(len(yPredict3)):\n",
    "    #if yPredict3[i] < mo3:\n",
    "    if (abs(0 - yPredict3[i]) - abs(1- yPredict3[i])) < 1e-10 :\n",
    "        yPredict3[i] = 0\n",
    "    else:\n",
    "        yPredict3[i] = 1\n",
    "        \n",
    "print(metrics.accuracy_score(yTest,yPredict3))\n",
    "print(metrics.confusion_matrix(yTest,yPredict3))\n",
    "error3 = mean_squared_error(yTest, yPredict3)\n",
    "print(\"error 3 = \",error3)\n",
    "RMSE3 = mean_squared_error(yTest,yPredict3)**0.5\n",
    "print(\"RMSE3 = \",RMSE3)\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = rfr))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict3)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict3))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict3))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict3, average='binary'))\n",
    "print()\n",
    "results = crossValidiation(xTraining,Y, k = 10, classifier = rfr)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(xTraining1, yTraining1)\n",
    "yPredict1 = regr.predict(xTest1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 1 =  0.178714859438\n",
      "0.821285140562\n",
      "[[384  17]\n",
      " [ 72  25]]\n",
      "RMSE1 =  0.422746802989\n",
      "AUC =  0.6076689719\n",
      "recal =  0.257731958763\n",
      "precision =  0.595238095238\n",
      "f1Score =  0.359712230216\n",
      "\n",
      "cros validation =  0.863855421687\n",
      "AUC =  0.737259013624\n",
      "recal =  0.523186022966\n",
      "precision =  0.739566731182\n",
      "f1 =  0.609212747129\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(yPredict1)):\n",
    "    count += yPredict1[i]\n",
    "\n",
    "mo = count / len(yPredict1)\n",
    "\n",
    "for i in range(len(yPredict1)):\n",
    "    if abs(0 - yPredict1[i]) - abs(1-yPredict1[i]) < 1e-10 :\n",
    "        yPredict1[i] = 0\n",
    "    else:\n",
    "        yPredict1[i] = 1\n",
    "\n",
    "error1 = mean_squared_error(yTest, yPredict1)\n",
    "print(\"error 1 = \",error1)\n",
    "print(metrics.accuracy_score(yTest,yPredict1))\n",
    "print(metrics.confusion_matrix(yTest,yPredict1))\n",
    "RMSE1 = mean_squared_error(yTest,yPredict1)**0.5\n",
    "print(\"RMSE1 = \",RMSE1)\n",
    "\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = regr))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict1)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict1))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict1))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict1, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = regr)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'lr',area = 'snpsOutArea')\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
    " # kernel='rbf', max_iter=-1, probability=False, shrinking=True, tol=0.001,\n",
    " # verbose=False)\n",
    "\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(xTraining1, yTraining1)\n",
    "yPredict2 = clf.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict2))\n",
    "print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "error2 = mean_squared_error(yTest, yPredict2)\n",
    "print(\"error 2 = \",error2)\n",
    "RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "print(\"RMSE2 = \",RMSE2)\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = clf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = clf,continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'svm',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel ='poly')\n",
    "clf.fit(xTraining1, yTraining1)\n",
    "yPredict2 = clf.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict2))\n",
    "print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "error2 = mean_squared_error(yTest, yPredict2)\n",
    "print(\"error 2 = \",error2)\n",
    "RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "print(\"RMSE2 = \",RMSE2)\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = clf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = clf,continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'svm',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(xTraining1, yTraining1)\n",
    "yPredict2 = clf.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict2))\n",
    "print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "error2 = mean_squared_error(yTest, yPredict2)\n",
    "print(\"error 2 = \",error2)\n",
    "RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "print(\"RMSE2 = \",RMSE2)\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = clf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = clf, continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'svmlr',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re = cross_val_score(clf, xTraining, Y, cv=10)\n",
    "print(sum(re)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_clf = linear_model.LogisticRegression()  \n",
    "lr_clf.fit(xTraining1, yTraining1)\n",
    "yPredict4 = lr_clf.predict(xTest1)\n",
    "\n",
    "print(metrics.accuracy_score(yTest,yPredict4))\n",
    "print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "error4 = mean_squared_error(yTest, yPredict4)\n",
    "print(\"error 4 = \",error4)\n",
    "RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = lr_clf, continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'llr',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re = cross_val_score(lr_clf, xTraining, Y, cv=10)\n",
    "print(sum(re)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perceptron = linear_model.Perceptron(penalty='l1', alpha=0.00000001, fit_intercept=True,\n",
    "              n_iter=100, shuffle=True, verbose=2016, eta0=0.00000001, n_jobs=-1, random_state=2016, warm_start=True)\n",
    "\n",
    "perceptron.fit(xTraining1, yTraining1)\n",
    "yPredict4 = perceptron.predict(xTest1)\n",
    "\n",
    "print(metrics.accuracy_score(yTest,yPredict4))\n",
    "print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "error4 = mean_squared_error(yTest, yPredict4)\n",
    "print(\"error 4 = \",error4)\n",
    "RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = perceptron, continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'perce',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re = cross_val_score(perceptron, xTraining, Y, cv=10)\n",
    "print(sum(re)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ols = sm.OLS(yTraining1,xTraining1)#OLS(yTraining,xtraining)\n",
    "yPredict5 = ols.fit().predict(xTest1)\n",
    "\n",
    "mo5 = 0\n",
    "s5 = 0\n",
    "for i in yPredict5:\n",
    "    s5 += i\n",
    "    \n",
    "mo5 = s5 / len(yPredict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(yPredict5)):\n",
    "    \n",
    "    if abs(0 - yPredict5[i]) < abs(1 - yPredict5[i]):\n",
    "    \n",
    "    #if yPredict5[i] <mo5:\n",
    "        yPredict5[i]=0\n",
    "    else:\n",
    "        yPredict5[i]=1\n",
    "\n",
    "print(metrics.accuracy_score(yTest,yPredict5))\n",
    "print(metrics.confusion_matrix(yTest,yPredict5))\n",
    "error5 = mean_squared_error(yTest, yPredict5)\n",
    "print(\"error 5 = \",error5)\n",
    "RMSE5 = mean_squared_error(yTest,yPredict5)**0.5\n",
    "print(\"RMSE5 = \",RMSE5)\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = ols,OLS = True))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict5)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict5))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict5))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict5, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10, classifier = ols,OLS = True)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'ols',area = 'snpsOutArea')\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(xTraining1, yTraining1)\n",
    "yPredict6 = gnb.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "#print(\"cros validation = \",crossValidiation(mergeXtable, mergeYtable, k = 10, classifier = gnb))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "print()\n",
    "\n",
    "results = crossValidiation(xTraining, Y, k = 10,classifier = gnb, continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'gnb',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re = cross_val_score(gnb, xTraining, Y, cv=10)\n",
    "print(sum(re)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(xTraining1, yTraining1)\n",
    "\n",
    "yPredict7 = dt.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict7))\n",
    "print(metrics.confusion_matrix(yTest,yPredict7))\n",
    "error6 = mean_squared_error(yTest, yPredict7)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict7)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "results = crossValidiation(xTraining,Y, k = 10, classifier = dt, continious = False)\n",
    "#results = crossValidiation1(mergeXtable, mergeYtable, k = 10, classifier = 'dt',area = 'snpsOutArea',continious = False)\n",
    "print(\"cros validation = \",results['cross'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re = cross_val_score(dt, xTraining, Y, cv=10)\n",
    "print(sum(re)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
