{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import random\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Output import Output\n",
    "from IO.Input import Input\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "import DataSet.SnpsSelection as s\n",
    "\n",
    "def setIdToName(aList):\n",
    "    \n",
    "    ids = {}\n",
    "    nameToId = {}\n",
    "    idToName = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in aList:\n",
    "        \n",
    "        nameToId[i] = count\n",
    "        idToName[count] = i\n",
    "        count += 1\n",
    "        \n",
    "    ids['nameToId'] = nameToId\n",
    "    ids['idToName'] = idToName\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    print(\"ok1\")\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    \n",
    "    \n",
    "    n = confusion_matrix.sum()\n",
    "    print(\"n  = \",n)\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    \n",
    "    print(\"val = \",phi2corr)\n",
    "    \n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "\n",
    "def cramers_stat(confusion_matrix):\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "\n",
    "    return np.sqrt(chi2 / (n*(min(confusion_matrix.shape)-1)))\n",
    "\n",
    "\n",
    "def createCrammerTable(X):\n",
    "    \n",
    "    cram = np.zeros((len(X.T),len(X.T)), dtype = np.float32)\n",
    "    \n",
    "    y = np.zeros((2,len(X)), dtype = np.int32)\n",
    "    \n",
    "    for i in range(len(X.T)):\n",
    "        print(\"i = \",i)\n",
    "        for j in range(i,len(X.T)):\n",
    "            \n",
    "            y[0,:] = X[:,i]\n",
    "            y[1,:] = X[:,j]\n",
    "            \n",
    "            v = cramers_stat(y)\n",
    "            \n",
    "            cram[i,j] = v\n",
    "            cram[j,i] = v\n",
    "            \n",
    "    return cram\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def tables(sampleX,sampleY,k):\n",
    "  \n",
    "    samples = {}\n",
    "    \n",
    "    for run in range(1,k+1):\n",
    "        \n",
    "        d1 = {}\n",
    "        \n",
    "\n",
    "        dataTestX = sampleX[run]\n",
    "        dataTestY = sampleY[run]\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        for i in sampleX.keys():\n",
    "\n",
    "            if i != run:\n",
    "\n",
    "                n += len(sampleX[i])\n",
    "\n",
    "        dataTrainX = np.zeros((n,len(sampleX[1].T)),dtype = int)\n",
    "        dataTrainY = np.zeros((n,),dtype = int)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sample in sampleX.keys():\n",
    "\n",
    "            if sample != run:\n",
    "\n",
    "                 for i in range(len(sampleX[sample])):\n",
    "                    for j in range(len(sampleX[sample].T)):\n",
    "                        dataTrainX[count,j] = sampleX[sample][i,j]\n",
    "\n",
    "                    dataTrainY[count] = sampleY[sample][i]\n",
    "                    count += 1\n",
    "\n",
    "        d1['trainX'] = dataTrainX\n",
    "        d1['trainY'] = dataTrainY\n",
    "        d1['testX'] = dataTestX\n",
    "        d1['testY'] = dataTestY\n",
    "        \n",
    "        samples[run] = d1\n",
    "    \n",
    "    return samples\n",
    "    \n",
    "def kSampleData(k,X,Y):\n",
    "    \n",
    "    x = int (len(X) / k)\n",
    "    allElements = np.zeros((len(X),),dtype = int)\n",
    "    \n",
    "    count1 = 1\n",
    "    sampleX = {}\n",
    "    sampleY = {}\n",
    "   \n",
    "    \n",
    "    while count1 <= k:\n",
    "        count2 = 1\n",
    "        sampleData = []\n",
    "        \n",
    "        if count1 == k:\n",
    "            x =  len(X) - ((k-1) * x)\n",
    "        \n",
    "        dataX = np.zeros((x,len(X.T)),dtype = int)\n",
    "        dataY = np.zeros((x,),dtype = int)\n",
    "        \n",
    "        while count2 <= x:\n",
    "            \n",
    "            aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            while allElements[aRand] == 1:\n",
    "                \n",
    "                aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            allElements[aRand] = 1\n",
    "            sampleData.append(aRand)\n",
    "            count2 += 1\n",
    "            \n",
    "        for i in range(len(sampleData)):\n",
    "            for j in range(len(X.T)):\n",
    "                dataX[i,j] = X[sampleData[i],j]\n",
    "            \n",
    "            dataY[i] = Y[sampleData[i]]\n",
    "            \n",
    "        sampleX[count1] = dataX\n",
    "        sampleY[count1] = dataY\n",
    "        count1 +=1\n",
    "        \n",
    "    return tables(sampleX,sampleY,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createNewTable(snps,X):\n",
    "    \n",
    "    newX = np.zeros((len(X),len(snps)),dtype = np.int32)\n",
    "    count=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(newX)):\n",
    "        for j in range(len(newX.T)):\n",
    "            newX[i,j] = -1\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        \n",
    "        newX[:,i] = X[:,snps[i]]\n",
    "        \n",
    "        \n",
    "    print(\"new shape = \",newX.shape)\n",
    "            \n",
    "    return newX \n",
    "\n",
    "\n",
    "\n",
    "def featuresIds(oldSnps,snps):\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        features[i] = snps[i]\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def crossValidiation(X, Y, k = 1, continious = True, classifier = None,OLS = False,Logistic = False):\n",
    "    \n",
    "    if not classifier:\n",
    "        print(\"wrong!!!!!!! you have to choise a classifier\")\n",
    "        return\n",
    "    \n",
    "    results = {}\n",
    "    accuracy = {}\n",
    "    auc = {}\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    f1Score = {}\n",
    "    \n",
    "    sumResults = 0.0\n",
    "    sumAccuracy = 0.0\n",
    "    sumAuc = 0.0\n",
    "    sumRecall = 0.0\n",
    "    sumPrecision = 0.0\n",
    "    sumF1Score = 0.0\n",
    "    \n",
    "    samples = kSampleData(k,X,Y)\n",
    "    \n",
    "    for run in range(1, k + 1):\n",
    "        \n",
    "        trainX = samples[run]['trainX']\n",
    "        trainY = samples[run]['trainY']\n",
    "        \n",
    "        #trainX,trainY = balancedData(trainX,trainY)\n",
    "        \n",
    "        testX = samples[run]['testX']\n",
    "        testY = samples[run]['testY']\n",
    "        \n",
    "        \n",
    "        if OLS:\n",
    "            classifier = sm.OLS(trainY,trainX)\n",
    "            yPredict = classifier.fit().predict(testX)\n",
    "        else:\n",
    "\n",
    "            classifier.fit(trainX, trainY)\n",
    "            yPredict = classifier.predict(testX)\n",
    "        \n",
    "        if continious:\n",
    "            \n",
    "            for i in range(len(yPredict)):\n",
    "                \n",
    "                if (abs(0 - yPredict[i]) - abs(1 - yPredict[i])) <= 1e-10 :\n",
    "                    yPredict[i] = 0\n",
    "                else:\n",
    "                    yPredict[i] = 1\n",
    "                    \n",
    "        if Logistic:\n",
    "            \n",
    "            probabilities = classifier.predict_proba(testX)\n",
    "            \n",
    "            for i in range(len(probabilities)):\n",
    "                if probabilities[i][1] >= 0.8:\n",
    "                    yPredict[i] = 1\n",
    "                else:\n",
    "                    yPredict[i] = 0\n",
    "          \n",
    "        accuracy[run] = metrics.accuracy_score(testY,yPredict)#(yPredict,testY)#\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(testY,yPredict)\n",
    "        auc[run] = metrics.auc(fpr,tpr)\n",
    "        recall[run] = metrics.recall_score(testY,yPredict)\n",
    "        precision[run] = metrics.precision_score(testY,yPredict)\n",
    "        f1Score[run] = f1_score(testY, yPredict, average='binary')\n",
    "        \n",
    "    \n",
    "    for i in accuracy.keys():\n",
    "        sumAccuracy = sumAccuracy + accuracy[i]\n",
    "        sumAuc = sumAuc + auc[i]\n",
    "        sumRecall = sumRecall + recall[i]\n",
    "        sumPrecision = sumPrecision + precision[i]\n",
    "        sumF1Score = sumF1Score + f1Score[i]\n",
    "    \n",
    "    results['accuracy'] = sumAccuracy / k\n",
    "    results['auc'] = sumAuc / k\n",
    "    results['recall'] = sumRecall / k\n",
    "    results['precision'] = sumPrecision / k\n",
    "    results['f1'] = sumF1Score / k\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def writeCoef(path,snpsIds,sc,idToName,name = None):\n",
    "        \n",
    "        if not name:\n",
    "            print(\"give a name to file\")\n",
    "            return\n",
    "        \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt \"  \n",
    "    \n",
    "        i=1\n",
    "        while os.path.exists(p):\n",
    "            \n",
    "            p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "            i += 1\n",
    "        \n",
    "        snps = []\n",
    "        for i in range(len(snpsIds)):\n",
    "            s = snpsIds[i]\n",
    "            snps.append(idToName[s])\n",
    "            \n",
    "        print(\"snpsIds = \",len(snpsIds))\n",
    "        print(\"idToName = \",len(idToName))\n",
    "        \n",
    "        write = open(p,'w')\n",
    "        for i in range(len(snps)):\n",
    "            \n",
    "            write.write(str(snps[i])+'\\t'+str(sc[i])+'\\n')\n",
    "            \n",
    "        write.close()\n",
    "        \n",
    "        \n",
    "def writeNSemanticSnps(path, metric = None,columns = None, snps = None, name =None):\n",
    "    \n",
    "    if not name:\n",
    "        print(\"give a name to file\")\n",
    "        return\n",
    "        \n",
    "    p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt\"\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(p):\n",
    "            \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "        i += 1\n",
    "     \n",
    "    write = open(p,'w')\n",
    "    \n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        s = snps[i]\n",
    "        write.write(str(columns[s]) +',' + str(metric[i]) + '\\n')\n",
    "                \n",
    "            \n",
    "    write.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.73  , 0.7344, ..., 0.738 , 0.7363, 0.735 ],\n",
       "       [0.73  , 1.    , 0.7246, ..., 0.727 , 0.73  , 0.723 ],\n",
       "       [0.7344, 0.7246, 1.    , ..., 0.727 , 0.728 , 0.7236],\n",
       "       ...,\n",
       "       [0.738 , 0.727 , 0.727 , ..., 1.    , 0.7266, 0.9106],\n",
       "       [0.7363, 0.73  , 0.728 , ..., 0.7266, 1.    , 0.723 ],\n",
       "       [0.735 , 0.723 , 0.7236, ..., 0.9106, 0.723 , 1.    ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Υπολογιστής\\\\'\n",
    "df = open('C:\\\\Users\\\\anton\\\\OneDrive\\\\Υπολογιστής\\\\cram.txt','r')\n",
    "\n",
    "columns = df.readline().split(',')[1:]\n",
    "lines = df.readlines()\n",
    "\n",
    "table = np.zeros((len(columns),len(columns)), dtype = np.float32)\n",
    "\n",
    "for i in range(1,len(lines)):\n",
    "    if i != 12002:\n",
    "        row = lines[i].split(',')\n",
    "        for j in range(1,len(row)):\n",
    "            if i>12002:\n",
    "                table[i-2,j-1] = float(row[j])\n",
    "                \n",
    "            else:\n",
    "                table[i-1,j-1] = float(row[j])\n",
    "        \n",
    "        \n",
    "df.close()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  5517\n",
      "len snpsRed =  5517\n"
     ]
    }
   ],
   "source": [
    "thres = 0.8\n",
    "down =99\n",
    "up =100\n",
    "\n",
    "snpsRed = []\n",
    "snpsRed = s.lowCorrelation(table, threshold=thres, up=up, down=down)#oso megalytero threshold toso perissotero omoia einai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _counterSnps(n):\n",
    "    snpsCount = {}\n",
    "    for i in range(n):\n",
    "        snpsCount[i] = 0\n",
    "    \n",
    "    return snpsCount\n",
    "\n",
    "\n",
    "def _highClass(X,b,c):\n",
    "\n",
    "    snpsCount = _counterSnps(len(X.T))\n",
    "\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        for j in range(i+1,len(X.T)):\n",
    "\n",
    "            if X[i,j] - b < 1e-10 and X[i,j] >= c:\n",
    "\n",
    "                snpsCount[i] = snpsCount[i] + 1\n",
    "                snpsCount[j] = snpsCount[j] + 1\n",
    "\n",
    "    return snpsCount\n",
    "\n",
    "\n",
    "def highCorrelation(X, b,up,down, c=-2):\n",
    "\n",
    "    snpsRed = []\n",
    "    count = 0\n",
    "    \n",
    "    snpsCount = _highClass(X,b,c)\n",
    "\n",
    "    \n",
    "    return snpsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpsRed = highCorrelation(table,0.7,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before =  313\n",
      "after =  313\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\anton\\\\OneDrive\\\\Υπολογιστής\\\\'\n",
    "\n",
    "ids={}\n",
    "ids['coef']={}\n",
    "    \n",
    "coefs=list(snpsRed.values())\n",
    "print(\"before = \",len(set(coefs)))\n",
    "#for i in range(len(coefs)):\n",
    "#   coefs[i] = abs(coefs[i])\n",
    "\n",
    "print(\"after = \",len(set(coefs)))\n",
    "\n",
    "idToName = {}\n",
    "nameToId = {}\n",
    "\n",
    "for i in range(len(coefs)):\n",
    "    nameToId[coefs[i]] = []\n",
    "\n",
    "for i in range(len(coefs)):\n",
    "    nameToId[coefs[i]].append(i)\n",
    "    idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "ids['coef']['nameToId'] = nameToId\n",
    "ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "sc = sorted(coefs,reverse=True)\n",
    "\n",
    "top_30 = []\n",
    "\n",
    "for i in range(30):\n",
    "\n",
    "    snp = ids['coef']['nameToId'][sc[i]][0]\n",
    "    ids['coef']['nameToId'][sc[i]].remove(snp)\n",
    "    top_30.append(snpsRed[snp])\n",
    "    \n",
    "\n",
    "writeNSemanticSnps(path, metric = sc,columns = columns, snps = top_30, name ='nsemantic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
