{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonis\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Antonis\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from random import randint\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Write import Write\n",
    "from IO.Read import Read\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "\n",
    "\n",
    "def setIdToName(aList):\n",
    "    \n",
    "    ids = {}\n",
    "    nameToId = {}\n",
    "    idToName = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in aList:\n",
    "        \n",
    "        nameToId[i] = count\n",
    "        idToName[count] = i\n",
    "        count += 1\n",
    "        \n",
    "    ids['nameToId'] = nameToId\n",
    "    ids['idToName'] = idToName\n",
    "    \n",
    "    return ids\n",
    "\n",
    "\n",
    "def setSnpsCode(patients,chromosomes):\n",
    "    \n",
    "    for i in patients.keys():\n",
    "        patients[i].snpCode(chromosomes)\n",
    "        \n",
    "    return patients\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def tables(sampleX,sampleY,k):\n",
    "  \n",
    "    samples = {}\n",
    "    \n",
    "    for run in range(1,k+1):\n",
    "        \n",
    "        d1 = {}\n",
    "        \n",
    "\n",
    "        dataTestX = sampleX[run]\n",
    "        dataTestY = sampleY[run]\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        for i in sampleX.keys():\n",
    "\n",
    "            if i != run:\n",
    "\n",
    "                n += len(sampleX[i])\n",
    "\n",
    "        dataTrainX = np.zeros((n,len(sampleX[1].T)),dtype = int)\n",
    "        dataTrainY = np.zeros((n,),dtype = int)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for sample in sampleX.keys():\n",
    "\n",
    "            if sample != run:\n",
    "\n",
    "                 for i in range(len(sampleX[sample])):\n",
    "                    for j in range(len(sampleX[sample].T)):\n",
    "                        dataTrainX[count,j] = sampleX[sample][i,j]\n",
    "\n",
    "                    dataTrainY[count] = sampleY[sample][i]\n",
    "                    count += 1\n",
    "\n",
    "        d1['trainX'] = dataTrainX\n",
    "        d1['trainY'] = dataTrainY\n",
    "        d1['testX'] = dataTestX\n",
    "        d1['testY'] = dataTestY\n",
    "        \n",
    "        samples[run] = d1\n",
    "    \n",
    "    return samples\n",
    "    \n",
    "def kSampleData(k,X,Y):\n",
    "    \n",
    "    x = int (len(X) / k)\n",
    "    allElements = np.zeros((len(X),),dtype = int)\n",
    "    \n",
    "    count1 = 1\n",
    "    sampleX = {}\n",
    "    sampleY = {}\n",
    "   \n",
    "    \n",
    "    while count1 <= k:\n",
    "        count2 = 1\n",
    "        sampleData = []\n",
    "        \n",
    "        if count1 == k:\n",
    "            x =  len(X) - ((k-1) * x)\n",
    "        \n",
    "        dataX = np.zeros((x,len(X.T)),dtype = int)\n",
    "        dataY = np.zeros((x,),dtype = int)\n",
    "        \n",
    "        while count2 <= x:\n",
    "            \n",
    "            aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            while allElements[aRand] == 1:\n",
    "                \n",
    "                aRand = randint(0,len(X)-1)\n",
    "            \n",
    "            allElements[aRand] = 1\n",
    "            sampleData.append(aRand)\n",
    "            count2 += 1\n",
    "            \n",
    "        for i in range(len(sampleData)):\n",
    "            for j in range(len(X.T)):\n",
    "                dataX[i,j] = X[sampleData[i],j]\n",
    "            \n",
    "            dataY[i] = Y[sampleData[i]]\n",
    "            \n",
    "        sampleX[count1] = dataX\n",
    "        sampleY[count1] = dataY\n",
    "        count1 +=1\n",
    "        \n",
    "    return tables(sampleX,sampleY,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createNewTable(snps,X):\n",
    "    \n",
    "    newX = np.zeros((len(X),len(snps)),dtype = int)\n",
    "    count=0\n",
    "    \n",
    "    for i in range(len(newX)):\n",
    "        for j in range(len(newX.T)):\n",
    "            newX[i,j] = -1\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        \n",
    "        newX[:,i] = X[:,snps[i]]\n",
    "       \n",
    "        \n",
    "    print(\"new shape = \",newX.shape)\n",
    "            \n",
    "    return newX\n",
    "\n",
    "def featuresIds(snps):\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for i in range(len(snps)):\n",
    "        features[i] = snps[i]\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def crossValidiation(X, Y, k = 1, continious = True, classifier = None,OLS = False,Logistic = False):\n",
    "    \n",
    "    if not classifier:\n",
    "        print(\"wrong!!!!!!! you have to choise a classifier\")\n",
    "        return\n",
    "    \n",
    "    results = {}\n",
    "    accuracy = {}\n",
    "    auc = {}\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    f1Score = {}\n",
    "    \n",
    "    sumResults = 0.0\n",
    "    sumAccuracy = 0.0\n",
    "    sumAuc = 0.0\n",
    "    sumRecall = 0.0\n",
    "    sumPrecision = 0.0\n",
    "    sumF1Score = 0.0\n",
    "    \n",
    "    samples = kSampleData(k,X,Y)\n",
    "    \n",
    "    for run in range(1, k + 1):\n",
    "        \n",
    "        trainX = samples[run]['trainX']\n",
    "        trainY = samples[run]['trainY']\n",
    "        \n",
    "        #trainX,trainY = balancedData(trainX,trainY)\n",
    "        \n",
    "        testX = samples[run]['testX']\n",
    "        testY = samples[run]['testY']\n",
    "        \n",
    "        \n",
    "        if OLS:\n",
    "            classifier = sm.OLS(trainY,trainX)\n",
    "            yPredict = classifier.fit().predict(testX)\n",
    "        else:\n",
    "\n",
    "            classifier.fit(trainX, trainY)\n",
    "            yPredict = classifier.predict(testX)\n",
    "        \n",
    "        if continious:\n",
    "            \n",
    "            for i in range(len(yPredict)):\n",
    "                \n",
    "                if (abs(0 - yPredict[i]) - abs(1 - yPredict[i])) <= 1e-10 :\n",
    "                    yPredict[i] = 0\n",
    "                else:\n",
    "                    yPredict[i] = 1\n",
    "                    \n",
    "        if Logistic:\n",
    "            \n",
    "            probabilities = classifier.predict_proba(testX)\n",
    "            \n",
    "            for i in range(len(probabilities)):\n",
    "                if probabilities[i][1] >= 0.8:\n",
    "                    yPredict[i] = 1\n",
    "                else:\n",
    "                    yPredict[i] = 0\n",
    "          \n",
    "        accuracy[run] = metrics.accuracy_score(testY,yPredict)#(yPredict,testY)#\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(testY,yPredict)\n",
    "        auc[run] = metrics.auc(fpr,tpr)\n",
    "        recall[run] = metrics.recall_score(testY,yPredict)\n",
    "        precision[run] = metrics.precision_score(testY,yPredict)\n",
    "        f1Score[run] = f1_score(testY, yPredict, average='binary')\n",
    "        \n",
    "    \n",
    "    for i in accuracy.keys():\n",
    "        sumAccuracy = sumAccuracy + accuracy[i]\n",
    "        sumAuc = sumAuc + auc[i]\n",
    "        sumRecall = sumRecall + recall[i]\n",
    "        sumPrecision = sumPrecision + precision[i]\n",
    "        sumF1Score = sumF1Score + f1Score[i]\n",
    "    \n",
    "    results['accuracy'] = sumAccuracy / k\n",
    "    results['auc'] = sumAuc / k\n",
    "    results['recall'] = sumRecall / k\n",
    "    results['precision'] = sumPrecision / k\n",
    "    results['f1'] = sumF1Score / k\n",
    "    \n",
    "    return results\n",
    "\n",
    "def writeResultConf(path,name,results):\n",
    "    \n",
    "    folder = path + name + 'Confu' + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '\\\\'\n",
    "    #file = path + name + 'Confu' + '.txt'\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(folder):\n",
    "        folder = path + name + 'Confu' + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i) + '\\\\'\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    "    os.makedirs(folder)\n",
    "    \n",
    "    file = folder + name + 'Confu' + '.txt' \n",
    "    \n",
    "    write = open(file,'w')\n",
    "    \n",
    "    write.write(name + '\\n')\n",
    "    \n",
    "    for i in results:\n",
    "        \n",
    "        results1 = results[i]\n",
    "        write.write(\"Category = \" + i + '\\n')\n",
    "        \n",
    "        for j in results1:\n",
    "            \n",
    "            write.write(j + \" = \" + str(results1[j]) + '\\n')\n",
    "            \n",
    "        write.write('\\n')\n",
    "        write.write('\\n')\n",
    "        \n",
    "    write.close()\n",
    "\n",
    "    \n",
    "\n",
    "def writeResult(path,name,results):\n",
    "    \n",
    "    folder = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '\\\\'\n",
    "    #file = path + name  + '.txt'\n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(folder):\n",
    "        folder = path + name + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i) + '\\\\'\n",
    "       \n",
    "        i += 1\n",
    "        \n",
    "    os.makedirs(folder)\n",
    "    \n",
    "    file = folder + name + '.txt'\n",
    "    \n",
    "    write = open(file,'w')\n",
    "    \n",
    "    write.write(name + '\\n')\n",
    "    \n",
    "    for i in results:\n",
    "        \n",
    "        results1 = results[i]\n",
    "        write.write(\"Category = \" + i + '\\n')\n",
    "        \n",
    "        for j in results1:\n",
    "            \n",
    "            write.write(j + \" = \" + str(results1[j]) + '\\n')\n",
    "            \n",
    "        write.write('\\n')\n",
    "        write.write('\\n')\n",
    "        \n",
    "    write.close()\n",
    "\n",
    "def balancedData(X,Y):\n",
    "    \n",
    "    cases = 0\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 1:\n",
    "            cases += 1\n",
    "            \n",
    "    Xbalanced = np.zeros((2*cases,len(X.T)))\n",
    "    Ybalanced = np.zeros(2*cases)\n",
    "    controls = 0\n",
    "    count = 0\n",
    "    for i in range(len(Y)):\n",
    "        if(Y[i] == 0 and controls < cases):\n",
    "            Xbalanced[count,:] = X[i,:]\n",
    "            Ybalanced[count] = Y[i]\n",
    "            controls +=1\n",
    "            count += 1\n",
    "        elif Y[i] == 1:\n",
    "            Xbalanced[count,:] = X[i,:]\n",
    "            Ybalanced[count] = Y[i]\n",
    "            count += 1\n",
    "            \n",
    "    print(\"len x = \", Xbalanced.shape)\n",
    "    print(\"len y = \", Ybalanced.shape)\n",
    "    \n",
    "    return Xbalanced, Ybalanced\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\assoc\\\\pvalue = 0.0001\\\\'\n",
    "path = 'D:\\\\newSet\\\\assoc\\\\pvalue = 0.0001\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\assoc\\\\pvalue = 5e-08\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\assoc\\\\pvalue = 1e-05\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\assoc\\\\pvalue = 0.001\\\\'\n",
    "#path = 'C:\\\\Users\\\\ANTONIS\\\\Desktop\\\\newSet\\\\assoc\\\\pvalue = 0.01\\\\'\n",
    "\n",
    "numberOfChromosomes = 22#'ari8mos twn xromoswmatwn'\n",
    "patientsTrain = {}\n",
    "patientsTest = {}\n",
    "allPatients = {}\n",
    "\n",
    "chromosomes = {}\n",
    "\n",
    "read = Read(path,numberOfChromosomes)\n",
    "write = Write(path,numberOfChromosomes)\n",
    "\n",
    "patients = read.readPatients('Patients.txt')\n",
    "chromosomes = read.readSnps(\".assoc\")\n",
    "write.writePatientsList(patients,'patient.txt')\n",
    "write.writeSnpsList(chromosomes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run train_lgen bat and test_leg bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mphka\n",
      "mphka2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4980, 5415)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "snps = read.getListOfSnps()\n",
    "ids = {} \n",
    "\n",
    "\n",
    "ids['patients'] = setIdToName(list(patients.keys()))\n",
    "ids['snps'] = setIdToName(snps)\n",
    "\n",
    "\n",
    "if os.path.exists(path + 'snpCode.txt'):\n",
    "    print(\"mphka\")\n",
    "    X, Y = read.readSnpsCode(patients,ids)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    write.writeSnpLog(read.getNumberOfPatients(),read.getNumberOfSnps(),chromosomes)\n",
    "    X, Y = read.readSnpsCode(patients,ids)\n",
    "    \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(Y)):\\n    if Y[i] == 0 :\\n        Y[i] = -1\\n\\nsum0 = 0\\nsum1 = 0\\nsum2 = 0\\nsumelse = 0\\nfor i in range(len(Y)):\\n    if Y[i] == 0 :\\n        sum0 += 1\\n    elif Y[i] == 1:\\n        sum1 +=1\\n    elif Y[i] == -1:\\n        sum2 +=1\\n    else:\\n        sumelse +=1\\nprint(\"sum0 = \", sum0)\\nprint(\"sum1 = \", sum1)\\nprint(\"sum-1 = \", sum2)\\nprint(\"sumelse = \", sumelse)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 0 :\n",
    "        Y[i] = -1\n",
    "\n",
    "sum0 = 0\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "sumelse = 0\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 0 :\n",
    "        sum0 += 1\n",
    "    elif Y[i] == 1:\n",
    "        sum1 +=1\n",
    "    elif Y[i] == -1:\n",
    "        sum2 +=1\n",
    "    else:\n",
    "        sumelse +=1\n",
    "print(\"sum0 = \", sum0)\n",
    "print(\"sum1 = \", sum1)\n",
    "print(\"sum-1 = \", sum2)\n",
    "print(\"sumelse = \", sumelse)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mergex =  (4980, 5415)\n",
      "xTrain =  (4482, 5415)\n",
      "xTest =  (498, 5415)\n",
      "yTrain =  (4482,)\n",
      "yTest =  (498,)\n"
     ]
    }
   ],
   "source": [
    "xTraining, xTest, yTraining1, yTest = train_test_split(X, Y, test_size=0.1, random_state=randint(0,2017))\n",
    "print(\"mergex = \",X.shape)\n",
    "print(\"xTrain = \",xTraining.shape)\n",
    "print(\"xTest = \",xTest.shape)\n",
    "print(\"yTrain = \",yTraining1.shape)\n",
    "print(\"yTest = \",yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor = Correlation(X)\n",
    "#cor = RSquare(X)\n",
    "\n",
    "#cor = Correlation(xTraining)\n",
    "#cor = RSquare(xTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snpReduc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snpsIds =  3309\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "snpReduc['high'] = cor.getHighCorrelationSnps(0.7)\n",
    "write.writeSnpsUsed(snpReduc['high'],ids['snps']['idToName'],chromosomes,'high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snpsIds =  2106\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "snpsRed = []\n",
    "snpReduc['low'] = cor.getLowCorrelationSnps(0.7)\n",
    "write.writeSnpsUsed(snpReduc['low'],ids['snps']['idToName'],chromosomes,'low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sepearte cases and Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases =  (935, 5415)\n",
      "controls =  (3547, 5415)\n"
     ]
    }
   ],
   "source": [
    "cases = []\n",
    "controls = []\n",
    "yCo = []\n",
    "yCa = []\n",
    "idsCa = {}\n",
    "idsCos = {}\n",
    "\n",
    "caIds = {}\n",
    "cosIds = {}\n",
    "\n",
    "for i in range(len(yTraining1)):\n",
    "    if yTraining1[i] == 0 :\n",
    "        controls.append(i)\n",
    "        \n",
    "    elif yTraining1[i] == 1:\n",
    "        cases.append(i)\n",
    "        \n",
    "count = 0\n",
    "\n",
    "for i in controls:\n",
    "    idsCos[i] = count\n",
    "    cosIds[count] = i\n",
    "    count += 1\n",
    "    \n",
    "count = 0\n",
    "\n",
    "for i in cases:\n",
    "    idsCa[i] = count\n",
    "    caIds[count] = i\n",
    "    count += 1\n",
    "        \n",
    "control = np.zeros((len(controls),len(xTraining.T)))\n",
    "case = np.zeros((len(cases),len(xTraining.T)))\n",
    "\n",
    "for i in controls:\n",
    "    pos = idsCos[i]\n",
    "    control[pos,:] = xTraining[i,:]\n",
    "   # yCo.append(Y[pos])\n",
    "    \n",
    "for i in cases:\n",
    "    pos = idsCa[i]\n",
    "    case[pos,:] = xTraining[i,:]\n",
    "   # yCa.append(Y[pos])\n",
    "\n",
    "print(\"cases = \",case.shape)\n",
    "print(\"controls = \",control.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r21 = RSquare(control)\n",
    "#r22 = RSquare(case)\n",
    "\n",
    "r21 = Correlation(control)\n",
    "r22 = Correlation(case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowCo = r21.getLowCorrelationSnps(0.7)\n",
    "highCo = r21.getHighCorrelationSnps(0.7)\n",
    "\n",
    "lowCa = r22.getLowCorrelationSnps(0.7)\n",
    "highCa = r22.getHighCorrelationSnps(0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# low &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len snpsRed =  2036\n",
      "snpsIds =  2036\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "snpsRed = []\n",
    "tomi = list(set(lowCo) & set(lowCa))\n",
    "snpsRed = tomi\n",
    "print(\"len snpsRed = \",len(set(snpsRed)))\n",
    "snpReduc['low&'] = snpsRed\n",
    "write.writeSnpsUsed(snpReduc['low&'],ids['snps']['idToName'],chromosomes,'low&')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# low U "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len snpsRed =  1367\n",
      "snpsIds =  1367\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "snpsRed = []\n",
    "allLows = []\n",
    "\n",
    "for i in lowCo:\n",
    "    if not i in tomi:\n",
    "        snpsRed.append(i)\n",
    "    \n",
    "for i in lowCa:\n",
    "    if i not in tomi:\n",
    "        if i not in snpsRed:\n",
    "            snpsRed.append(i)\n",
    "\n",
    "print(\"len snpsRed = \",len(snpsRed))\n",
    "union = snpsRed\n",
    "snpReduc['lowU'] = snpsRed\n",
    "write.writeSnpsUsed(snpReduc['lowU'],ids['snps']['idToName'],chromosomes,'lowU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# low - (( U ) + (&))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len snsRed =  0\n",
      "snpsIds =  0\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "snpsRed = []\n",
    "alll = []\n",
    "\n",
    "for i in lowCo:\n",
    "    alll.append(i)\n",
    "    \n",
    "for i in lowCa:\n",
    "    alll.append(i)\n",
    "    \n",
    "for i in alll:\n",
    "    if (i not in union) and (i not in tomi):\n",
    "        snpsRed.append(i)\n",
    "        \n",
    "print(\"len snsRed = \", len(snpsRed))\n",
    "snpReduc['lowEktosUnionTomi'] = snpsRed\n",
    "write.writeSnpsUsed(snpReduc['lowEktosUnionTomi'],ids['snps']['idToName'],chromosomes,'lowEktosUnionTomi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# high&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len snpsRed =  2012\n",
      "snpsIds =  2012\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "snpsRed = []\n",
    "\n",
    "snpsRed = list(set(highCa) & set(highCo))\n",
    "print(\"len snpsRed = \",len(set(snpsRed)))\n",
    "snpReduc['high&'] = snpsRed\n",
    "write.writeSnpsUsed(snpReduc['high&'],ids['snps']['idToName'],chromosomes,'high&')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# highU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len snpsRed =  1367\n",
      "set len snpsRed =  1367\n",
      "snpsIds =  1367\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "snpsRed = []\n",
    "tomi = []\n",
    "tomi = list(set(highCo) & set(highCa))\n",
    "\n",
    "for i in highCo:\n",
    "    if i not in tomi:\n",
    "        snpsRed.append(i)\n",
    "    \n",
    "for i in highCa:\n",
    "    if i not in tomi:\n",
    "        if i not in snpsRed:\n",
    "            snpsRed.append(i)\n",
    "\n",
    "\n",
    "print(\"len snpsRed = \",len(snpsRed))\n",
    "print(\"set len snpsRed = \",len(set(snpsRed)))\n",
    "union = snpsRed\n",
    "snpReduc['highU'] = snpsRed\n",
    "write.writeSnpsUsed(snpReduc['highU'],ids['snps']['idToName'],chromosomes,'highU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(snpReduc['highU']) - set(snpReduc['lowU']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# high - ((U) + (&)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len snsRed =  4024\n",
      "snpsIds =  4024\n",
      "idToName =  5415\n"
     ]
    }
   ],
   "source": [
    "tomi = snpsRed\n",
    "snpsRed = []\n",
    "alll = []\n",
    "\n",
    "for i in highCo:\n",
    "    alll.append(i)\n",
    "    \n",
    "for i in highCa:\n",
    "    alll.append(i)\n",
    "    \n",
    "for i in alll:\n",
    "    if (i not in union) & (i not in tomi):\n",
    "        snpsRed.append(i)\n",
    "        \n",
    "print(\"len snsRed = \", len(snpsRed))\n",
    "snpReduc['highEktosUnionTomi'] = snpsRed\n",
    "write.writeSnpsUsed(snpReduc['highEktosUnionTomi'],ids['snps']['idToName'],chromosomes,'highEktosUnionTomi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['low','high','low&','lowU','high&','highU']\n",
    "#categories = ['low','high']\n",
    "#categories = ['low','lowTopReduced','lowLowReduced']\n",
    "writeResults = {}\n",
    "writeResults2 = {}\n",
    "for i in categories:\n",
    "    writeResults[i] = {}\n",
    "    writeResults2[i] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresIdss = {}\n",
    "featuresIdss['low'] = featuresIds(snpReduc['low'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low\n",
      "new shape =  (4980, 2106)\n",
      "new shape =  (4482, 2106)\n",
      "new shape =  (498, 2106)\n",
      "(4980, 6318)\n",
      "(4482, 6318)\n",
      "(498, 6318)\n",
      "0.86546184739\n",
      "[[414   1]\n",
      " [ 66  17]]\n",
      "error 2 =  0.13453815261\n",
      "RMSE2 =  0.366794428271\n",
      "AUC =  0.601204819277\n",
      "recal =  0.204819277108\n",
      "precision =  0.944444444444\n",
      "f1Score =  0.336633663366\n",
      "accuracy =  0.826907630522\n",
      "AUC =  0.581341009298\n",
      "recal =  0.165735038772\n",
      "precision =  0.934090062112\n",
      "f1 =  0.278341130112\n",
      "\n",
      "Category =  high\n",
      "new shape =  (4980, 3309)\n",
      "new shape =  (4482, 3309)\n",
      "new shape =  (498, 3309)\n",
      "(4980, 9927)\n",
      "(4482, 9927)\n",
      "(498, 9927)\n",
      "0.849397590361\n",
      "[[413   2]\n",
      " [ 73  10]]\n",
      "error 2 =  0.150602409639\n",
      "RMSE2 =  0.388075262853\n",
      "AUC =  0.557831325301\n",
      "recal =  0.120481927711\n",
      "precision =  0.833333333333\n",
      "f1Score =  0.210526315789\n",
      "accuracy =  0.810441767068\n",
      "AUC =  0.551972394264\n",
      "recal =  0.114789748758\n",
      "precision =  0.726550818463\n",
      "f1 =  0.197099486536\n",
      "\n",
      "Category =  low&\n",
      "new shape =  (4980, 2036)\n",
      "new shape =  (4482, 2036)\n",
      "new shape =  (498, 2036)\n",
      "(4980, 6108)\n",
      "(4482, 6108)\n",
      "(498, 6108)\n",
      "0.873493975904\n",
      "[[415   0]\n",
      " [ 63  20]]\n",
      "error 2 =  0.126506024096\n",
      "RMSE2 =  0.355676853473\n",
      "AUC =  0.620481927711\n",
      "recal =  0.240963855422\n",
      "precision =  1.0\n",
      "f1Score =  0.388349514563\n",
      "accuracy =  0.828313253012\n",
      "AUC =  0.583122128382\n",
      "recal =  0.16778296846\n",
      "precision =  0.967726190476\n",
      "f1 =  0.283407214432\n",
      "\n",
      "Category =  lowU\n",
      "new shape =  (4980, 1367)\n",
      "new shape =  (4482, 1367)\n",
      "new shape =  (498, 1367)\n",
      "(4980, 4101)\n",
      "(4482, 4101)\n",
      "(498, 4101)\n",
      "0.885542168675\n",
      "[[409   6]\n",
      " [ 51  32]]\n",
      "error 2 =  0.114457831325\n",
      "RMSE2 =  0.338316170653\n",
      "AUC =  0.685542168675\n",
      "recal =  0.385542168675\n",
      "precision =  0.842105263158\n",
      "f1Score =  0.528925619835\n",
      "accuracy =  0.867670682731\n",
      "AUC =  0.698118591122\n",
      "recal =  0.410142612155\n",
      "precision =  0.884013410961\n",
      "f1 =  0.557853439314\n",
      "\n",
      "Category =  high&\n",
      "new shape =  (4980, 2012)\n",
      "new shape =  (4482, 2012)\n",
      "new shape =  (498, 2012)\n",
      "(4980, 6036)\n",
      "(4482, 6036)\n",
      "(498, 6036)\n",
      "0.833333333333\n",
      "[[409   6]\n",
      " [ 77   6]]\n",
      "error 2 =  0.166666666667\n",
      "RMSE2 =  0.408248290464\n",
      "AUC =  0.528915662651\n",
      "recal =  0.0722891566265\n",
      "precision =  0.5\n",
      "f1Score =  0.126315789474\n",
      "accuracy =  0.799397590361\n",
      "AUC =  0.531296323838\n",
      "recal =  0.0774570686803\n",
      "precision =  0.586982510953\n",
      "f1 =  0.135879122619\n",
      "\n",
      "Category =  highU\n",
      "new shape =  (4980, 1367)\n",
      "new shape =  (4482, 1367)\n",
      "new shape =  (498, 1367)\n",
      "(4980, 4101)\n",
      "(4482, 4101)\n",
      "(498, 4101)\n",
      "0.879518072289\n",
      "[[406   9]\n",
      " [ 51  32]]\n",
      "error 2 =  0.120481927711\n",
      "RMSE2 =  0.34710506725\n",
      "AUC =  0.681927710843\n",
      "recal =  0.385542168675\n",
      "precision =  0.780487804878\n",
      "f1Score =  0.516129032258\n",
      "accuracy =  0.866666666667\n",
      "AUC =  0.695909147996\n",
      "recal =  0.406643011055\n",
      "precision =  0.874503049136\n",
      "f1 =  0.553261290414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for i in categories:\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=500, random_state=2018)\n",
    "    clf.fit(xTraining1, yTraining1)\n",
    "    \n",
    "    yPredict2 = clf.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict2))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "    error2 = mean_squared_error(yTest, yPredict2)\n",
    "    print(\"error 2 = \",error2)\n",
    "    RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "    print(\"RMSE2 = \",RMSE2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "    \n",
    "    \n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "for i in categories:\n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "    clf.fit(xTraining1, yTraining1)\n",
    "    \n",
    "    yPredict2 = clf.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict2))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "    error2 = mean_squared_error(yTest, yPredict2)\n",
    "    print(\"error 2 = \",error2)\n",
    "    RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "    print(\"RMSE2 = \",RMSE2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "    \n",
    "    \n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low\n",
      "new shape =  (4980, 2106)\n",
      "new shape =  (4482, 2106)\n",
      "new shape =  (498, 2106)\n",
      "(4980, 6318)\n",
      "(4482, 6318)\n",
      "(498, 6318)\n",
      "0.955823293173\n",
      "[[403   4]\n",
      " [ 18  73]]\n",
      "error 2 =  0.0441767068273\n",
      "RMSE2 =  0.210182555954\n",
      "AUC =  0.896184896185\n",
      "recal =  0.802197802198\n",
      "precision =  0.948051948052\n",
      "f1Score =  0.869047619048\n",
      "\n",
      "accuracy =  0.952610441767\n",
      "AUC =  0.90033729065\n",
      "recal =  0.811844127959\n",
      "precision =  0.950464212768\n",
      "f1 =  0.875398557881\n",
      "\n",
      "Category =  high\n",
      "new shape =  (4980, 3309)\n",
      "new shape =  (4482, 3309)\n",
      "new shape =  (498, 3309)\n",
      "(4980, 9927)\n",
      "(4482, 9927)\n",
      "(498, 9927)\n",
      "0.853413654618\n",
      "[[370  37]\n",
      " [ 36  55]]\n",
      "error 2 =  0.146586345382\n",
      "RMSE2 =  0.382865962683\n",
      "AUC =  0.756743256743\n",
      "recal =  0.604395604396\n",
      "precision =  0.597826086957\n",
      "f1Score =  0.601092896175\n",
      "\n",
      "accuracy =  0.855421686747\n",
      "AUC =  0.760901174656\n",
      "recal =  0.600580422172\n",
      "precision =  0.660298256203\n",
      "f1 =  0.627476223947\n",
      "\n",
      "Category =  low&\n",
      "new shape =  (4980, 2030)\n",
      "new shape =  (4482, 2030)\n",
      "new shape =  (498, 2030)\n",
      "(4980, 6090)\n",
      "(4482, 6090)\n",
      "(498, 6090)\n",
      "0.957831325301\n",
      "[[400   7]\n",
      " [ 14  77]]\n",
      "error 2 =  0.0421686746988\n",
      "RMSE2 =  0.205350127097\n",
      "AUC =  0.914477414477\n",
      "recal =  0.846153846154\n",
      "precision =  0.916666666667\n",
      "f1Score =  0.88\n",
      "\n",
      "accuracy =  0.948995983936\n",
      "AUC =  0.893811317385\n",
      "recal =  0.80071009996\n",
      "precision =  0.939529640658\n",
      "f1 =  0.864049067656\n",
      "\n",
      "Category =  lowU\n",
      "new shape =  (4980, 1377)\n",
      "new shape =  (4482, 1377)\n",
      "new shape =  (498, 1377)\n",
      "(4980, 4131)\n",
      "(4482, 4131)\n",
      "(498, 4131)\n",
      "0.692771084337\n",
      "[[318  89]\n",
      " [ 64  27]]\n",
      "error 2 =  0.307228915663\n",
      "RMSE2 =  0.554282342911\n",
      "AUC =  0.539015039015\n",
      "recal =  0.296703296703\n",
      "precision =  0.23275862069\n",
      "f1Score =  0.260869565217\n",
      "\n",
      "accuracy =  0.634939759036\n",
      "AUC =  0.54221763618\n",
      "recal =  0.385661750255\n",
      "precision =  0.258205126188\n",
      "f1 =  0.29859390848\n",
      "\n",
      "Category =  high&\n",
      "new shape =  (4980, 2008)\n",
      "new shape =  (4482, 2008)\n",
      "new shape =  (498, 2008)\n",
      "(4980, 6024)\n",
      "(4482, 6024)\n",
      "(498, 6024)\n",
      "0.825301204819\n",
      "[[364  43]\n",
      " [ 44  47]]\n",
      "error 2 =  0.174698795181\n",
      "RMSE2 =  0.417969849607\n",
      "AUC =  0.705416205416\n",
      "recal =  0.516483516484\n",
      "precision =  0.522222222222\n",
      "f1Score =  0.519337016575\n",
      "\n",
      "accuracy =  0.820080321285\n",
      "AUC =  0.709467419851\n",
      "recal =  0.523485111084\n",
      "precision =  0.563593335617\n",
      "f1 =  0.541679351669\n",
      "\n",
      "Category =  highU\n",
      "new shape =  (4980, 1377)\n",
      "new shape =  (4482, 1377)\n",
      "new shape =  (498, 1377)\n",
      "(4980, 4131)\n",
      "(4482, 4131)\n",
      "(498, 4131)\n",
      "0.692771084337\n",
      "[[318  89]\n",
      " [ 64  27]]\n",
      "error 2 =  0.307228915663\n",
      "RMSE2 =  0.554282342911\n",
      "AUC =  0.539015039015\n",
      "recal =  0.296703296703\n",
      "precision =  0.23275862069\n",
      "f1Score =  0.260869565217\n",
      "\n",
      "accuracy =  0.576907630522\n",
      "AUC =  0.513474517831\n",
      "recal =  0.406557083755\n",
      "precision =  0.221495700198\n",
      "f1 =  0.277240590368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    \n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    \n",
    "    #clf = SVC(kernel='linear')\n",
    "    clf = NuSVC(kernel='rbf',nu=0.01)\n",
    "    clf.fit(xTraining1, yTraining1)\n",
    "    yPredict2 = clf.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict2))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict2))\n",
    "    error2 = mean_squared_error(yTest, yPredict2)\n",
    "    print(\"error 2 = \",error2)\n",
    "    RMSE2 = mean_squared_error(yTest,yPredict2)**0.5\n",
    "    print(\"RMSE2 = \",RMSE2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict2)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict2))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict2))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict2, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict2)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict2)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict2)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict2)\n",
    "    r1['f1'] = f1_score(yTest, yPredict2, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len snps'] = len(snpReduc[i])\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "writeResult(path,'nonLinear',writeResults)\n",
    "writeResultConf(path,'nonLinear',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#re = cross_val_score(clf, XX, Y, cv=10)\n",
    "#print(sum(re)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in categories:\n",
    "  \n",
    "    r1 = {}\n",
    "    \n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    \n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    ''' enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)'''\n",
    "    \n",
    "    \n",
    "\n",
    "#    lr_clf = linear_model.LogisticRegression()\n",
    "    lr_clf = linear_model.LogisticRegressionCV()\n",
    "    lr_clf.fit(xTraining1, yTraining1)\n",
    "    yPredict4 = lr_clf.predict(xTest1)\n",
    "\n",
    "    print(metrics.accuracy_score(yTest,yPredict4))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "    error4 = mean_squared_error(yTest, yPredict4)\n",
    "    print(\"error 4 = \",error4)\n",
    "    RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "    print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict4)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict4)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict4)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict4)\n",
    "    r1['f1'] = f1_score(yTest, yPredict4, average='binary')\n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = lr_clf, continious = False)\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len snps'] = len(snpReduc[i])\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'llr',writeResults)\n",
    "writeResultConf(path,'llr',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = createNewTable(snpReduc['low'],X)\n",
    "lr_clf = linear_model.LogisticRegressionCV()\n",
    "lr_clf.fit(XX, Y)\n",
    "\n",
    "coefs=lr_clf.coef_[0]\n",
    "top_20 = np.argpartition(coefs, -200)[-200:]\n",
    "low_20 = np.argpartition(coefs, 200)[:200]\n",
    "removedSnps = []\n",
    "\n",
    "for i in range(len(snpReduc['low'])):\n",
    "    if i not in top_20:\n",
    "        removedSnps.append(snpReduc['low'][i])\n",
    "        \n",
    "snpReduc['lowTopReduced'] = removedSnps\n",
    "\n",
    "removedSnps = []\n",
    "for i in range(len(snpReduc['low'])):\n",
    "    if i not in low_20:\n",
    "        removedSnps.append(snpReduc['low'][i])\n",
    "\n",
    "snpReduc['lowLowReduced'] = removedSnps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = createNewTable(snpReduc['low'],X)\n",
    "lr_clf = linear_model.LogisticRegressionCV()\n",
    "lr_clf.fit(XX, Y)\n",
    "\n",
    "coefs=lr_clf.coef_[0]\n",
    "top_30 = np.argpartition(coefs, -30)[-30:]\n",
    "#low_20 = np.argpartition(coefs, 100)[:100]\n",
    "removedSnps = []\n",
    "\n",
    "for i in range(len(snpReduc['low'])):\n",
    "    if i in top_30:\n",
    "        removedSnps.append(snpReduc['low'][i])\n",
    "\n",
    "write.writeSnpsUsed(removedSnps,ids['snps']['idToName'],chromosomes,'top_30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    \n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(xTraining1, yTraining1)\n",
    "    yPredict6 = gnb.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict6))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "    error6 = mean_squared_error(yTest, yPredict6)\n",
    "    print(\"error 6 = \",error6)\n",
    "    RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "    print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "    r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10,classifier = gnb, continious = False)\n",
    "    \n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    print()\n",
    "    results['len snps'] = len(snpReduc[i])\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'gnb',writeResults)\n",
    "writeResultConf(path,'gnb',writeResults2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERNOULLI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''xTraining1 = createNewTable(snpReduc['low'],xTraining)\n",
    "lr_clf = linear_model.LogisticRegressionCV()\n",
    "lr_clf.fit(xTraining1, yTraining1)\n",
    "\n",
    "coefs=lr_clf.coef_[0]\n",
    "top_20 = np.argpartition(coefs, -50)[-50:]\n",
    "#top_20 = np.argpartition(coefs, 50)[:50]\n",
    "removedSnps = []\n",
    "for i in range(len(snpReduc['low'])):\n",
    "    if i not in top_20:\n",
    "        removedSnps.append(snpReduc['low'][i])'''\n",
    "\n",
    "\n",
    "snpReduc['lowReduced'] = removedSnps\n",
    "\n",
    "for i in categories:\n",
    "   \n",
    "    r1 = {}\n",
    "    \n",
    "    print(\"Category = \",i)\n",
    "    print(\"snpReduc = \", len(snpReduc[i]))\n",
    "   \n",
    "   \n",
    "  \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "\n",
    "   \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "\n",
    "    bern = BernoulliNB()\n",
    "    bern.fit(xTraining1, yTraining1)\n",
    "    yPredict6 = bern.predict(xTest1)\n",
    "    print(metrics.accuracy_score(yTest,yPredict6))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "    error6 = mean_squared_error(yTest, yPredict6)\n",
    "    print(\"error 6 = \",error6)\n",
    "    RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "    print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "    r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "    \n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10,classifier = bern, continious = False)\n",
    "    \n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    print()\n",
    "   # results['len snps'] = len(snpReduc[i])\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'bernoulli',writeResults)\n",
    "writeResultConf(path,'bernoulli',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''l= [5,6,7,2,3,4,10,6,7,9,8,5]\n",
    "top_3 = np.argpartition(l,3)[:3]\n",
    "print(top_3)\n",
    "removedSnps=[]\n",
    "for i in range(len(l)):\n",
    "    if i not in top_3:\n",
    "        removedSnps.append(l[i])\n",
    "print(removedSnps)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = createNewTable(snpReduc['low'],X)\n",
    "#enc = OneHotEncoder(n_values =3) \n",
    "#enc.fit(XX) \n",
    "#XX = enc.fit_transform(XX)\n",
    "#XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "re = cross_val_score(bern, XX, Y, cv=10)\n",
    "print(sum(re)/10)\n",
    "\n",
    "print()\n",
    "XX = X\n",
    "#enc = OneHotEncoder(n_values =3) \n",
    "#enc.fit(XX) \n",
    "#XX = enc.fit_transform(XX)\n",
    "#XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "re = cross_val_score(bern, XX, Y, cv=10)\n",
    "print(sum(re)/10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category =  low\n",
      "new shape =  (4980, 2106)\n",
      "new shape =  (4482, 2106)\n",
      "new shape =  (498, 2106)\n",
      "(4980, 6318)\n",
      "(4482, 6318)\n",
      "(498, 6318)\n",
      "0.765060240964\n",
      "[[343  41]\n",
      " [ 76  38]]\n",
      "error 4 =  0.234939759036\n",
      "RMSE4 =  0.484705847949\n",
      "AUC =  0.61328125\n",
      "recal =  0.333333333333\n",
      "precision =  0.481012658228\n",
      "f1Score =  0.39378238342\n",
      "\n",
      "accuracy =  0.794779116466\n",
      "AUC =  0.628138934616\n",
      "recal =  0.346879956611\n",
      "precision =  0.496001099678\n",
      "f1 =  0.405497328769\n",
      "\n",
      "Category =  high\n",
      "new shape =  (4980, 3309)\n",
      "new shape =  (4482, 3309)\n",
      "new shape =  (498, 3309)\n",
      "(4980, 9927)\n",
      "(4482, 9927)\n",
      "(498, 9927)\n",
      "0.781124497992\n",
      "[[341  43]\n",
      " [ 66  48]]\n",
      "error 4 =  0.218875502008\n",
      "RMSE4 =  0.467841321399\n",
      "AUC =  0.654536732456\n",
      "recal =  0.421052631579\n",
      "precision =  0.527472527473\n",
      "f1Score =  0.468292682927\n",
      "\n",
      "accuracy =  0.781726907631\n",
      "AUC =  0.629576698597\n",
      "recal =  0.372134081556\n",
      "precision =  0.458857101033\n",
      "f1 =  0.409181318102\n",
      "\n",
      "Category =  low&\n",
      "new shape =  (4980, 2038)\n",
      "new shape =  (4482, 2038)\n",
      "new shape =  (498, 2038)\n",
      "(4980, 6114)\n",
      "(4482, 6114)\n",
      "(498, 6114)\n",
      "0.753012048193\n",
      "[[342  42]\n",
      " [ 81  33]]\n",
      "error 4 =  0.246987951807\n",
      "RMSE4 =  0.496978824305\n",
      "AUC =  0.590049342105\n",
      "recal =  0.289473684211\n",
      "precision =  0.44\n",
      "f1Score =  0.349206349206\n",
      "\n",
      "accuracy =  0.798393574297\n",
      "AUC =  0.63232157962\n",
      "recal =  0.350926818639\n",
      "precision =  0.508093351304\n",
      "f1 =  0.413505379932\n",
      "\n",
      "Category =  lowU\n",
      "new shape =  (4980, 1344)\n",
      "new shape =  (4482, 1344)\n",
      "new shape =  (498, 1344)\n",
      "(4980, 4032)\n",
      "(4482, 4032)\n",
      "(498, 4032)\n",
      "0.85140562249\n",
      "[[354  30]\n",
      " [ 44  70]]\n",
      "error 4 =  0.14859437751\n",
      "RMSE4 =  0.385479412563\n",
      "AUC =  0.76795504386\n",
      "recal =  0.614035087719\n",
      "precision =  0.7\n",
      "f1Score =  0.654205607477\n",
      "\n",
      "accuracy =  0.854417670683\n",
      "AUC =  0.729002727051\n",
      "recal =  0.515753536895\n",
      "precision =  0.69727295641\n",
      "f1 =  0.590692701907\n",
      "\n",
      "Category =  high&\n",
      "new shape =  (4980, 2033)\n",
      "new shape =  (4482, 2033)\n",
      "new shape =  (498, 2033)\n",
      "(4980, 6099)\n",
      "(4482, 6099)\n",
      "(498, 6099)\n",
      "0.700803212851\n",
      "[[312  72]\n",
      " [ 77  37]]\n",
      "error 4 =  0.299196787149\n",
      "RMSE4 =  0.546988836402\n",
      "AUC =  0.568530701754\n",
      "recal =  0.324561403509\n",
      "precision =  0.339449541284\n",
      "f1Score =  0.331838565022\n",
      "\n",
      "accuracy =  0.735542168675\n",
      "AUC =  0.577835968555\n",
      "recal =  0.311496407029\n",
      "precision =  0.339807040583\n",
      "f1 =  0.324179585962\n",
      "\n",
      "Category =  highU\n",
      "new shape =  (4980, 1344)\n",
      "new shape =  (4482, 1344)\n",
      "new shape =  (498, 1344)\n",
      "(4980, 4032)\n",
      "(4482, 4032)\n",
      "(498, 4032)\n",
      "0.831325301205\n",
      "[[354  30]\n",
      " [ 54  60]]\n",
      "error 4 =  0.168674698795\n",
      "RMSE4 =  0.410700254194\n",
      "AUC =  0.724095394737\n",
      "recal =  0.526315789474\n",
      "precision =  0.666666666667\n",
      "f1Score =  0.588235294118\n",
      "\n",
      "accuracy =  0.859236947791\n",
      "AUC =  0.740317736215\n",
      "recal =  0.539193676401\n",
      "precision =  0.702160984275\n",
      "f1 =  0.608426234685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "for i in categories:\n",
    "    \n",
    "    r1 = {}\n",
    "    \n",
    "    print(\"Category = \",i)\n",
    "    \n",
    "    XX = createNewTable(snpReduc[i],X)\n",
    "    xTraining1 = createNewTable(snpReduc[i],xTraining)\n",
    "    xTest1 = createNewTable(snpReduc[i],xTest)\n",
    "    \n",
    "    enc = OneHotEncoder(n_values =3) \n",
    "    enc.fit(XX) \n",
    "    XX = enc.fit_transform(XX)\n",
    "    XX = XX.toarray()\n",
    "    print(XX.shape)\n",
    "\n",
    "    enc.fit(xTraining1) \n",
    "    xTraining1 = enc.fit_transform(xTraining1)\n",
    "    xTraining1 = xTraining1.toarray()\n",
    "    print(xTraining1.shape)\n",
    "\n",
    "    enc.fit(xTest1) \n",
    "    xTest1 = enc.fit_transform(xTest1)\n",
    "    xTest1 = xTest1.toarray()\n",
    "    print(xTest1.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(xTraining1, yTraining1)\n",
    "    yPredict4 = clf.predict(xTest1)\n",
    "\n",
    "    print(metrics.accuracy_score(yTest,yPredict4))\n",
    "    print(metrics.confusion_matrix(yTest,yPredict4))\n",
    "    error4 = mean_squared_error(yTest, yPredict4)\n",
    "    print(\"error 4 = \",error4)\n",
    "    RMSE4 = mean_squared_error(yTest,yPredict4)**0.5\n",
    "    print(\"RMSE4 = \",RMSE4)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict4)\n",
    "    print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "    print(\"recal = \",metrics.recall_score(yTest,yPredict4))\n",
    "    print(\"precision = \",metrics.precision_score(yTest,yPredict4))\n",
    "    print(\"f1Score = \",f1_score(yTest, yPredict4, average='binary'))\n",
    "    \n",
    "    r1['confu'] = metrics.confusion_matrix(yTest,yPredict4)\n",
    "    r1['accu'] = metrics.accuracy_score(yTest,yPredict4)\n",
    "    r1['auc'] = metrics.auc(fpr,tpr)\n",
    "    r1['recal'] = metrics.recall_score(yTest,yPredict4)\n",
    "    r1['precision'] = metrics.precision_score(yTest,yPredict4)\n",
    "    r1['f1'] = f1_score(yTest, yPredict4, average='binary')\n",
    "    writeResults2[i] = r1\n",
    "    \n",
    "    print()\n",
    "\n",
    "    results = crossValidiation(XX, Y, k = 10, classifier = clf, continious = False)\n",
    "    print(\"accuracy = \",results['accuracy'])\n",
    "    print(\"AUC = \", results['auc'])\n",
    "    print(\"recal = \",results['recall'])\n",
    "    print(\"precision = \",results['precision'])\n",
    "    print(\"f1 = \",results['f1'])\n",
    "    results['len snps'] = len(snpReduc[i])\n",
    "    writeResults[i] = results\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "#writeResult(path,'tree',writeResults)\n",
    "#writeResultConf(path,'tree',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape =  (4482, 2106)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U73') dtype('<U73') dtype('<U73')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-109bb6efa265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myTraining1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                          \u001b[0mfilled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                          special_characters=False)  \n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Antonis\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters)\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mrecurse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"impurity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[0mrecurse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;31m# If required, draw leaf nodes at same depth as each other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Antonis\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mrecurse\u001b[1;34m(tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[0;32m    319\u001b[0m             out_file.write('%d [label=%s'\n\u001b[0;32m    320\u001b[0m                            % (node_id,\n\u001b[1;32m--> 321\u001b[1;33m                               node_to_str(tree, node_id, criterion)))\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfilled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Antonis\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mnode_to_str\u001b[1;34m(tree, node_id, criterion)\u001b[0m\n\u001b[0;32m    289\u001b[0m                                           \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                                           characters[2])\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mnode_string\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;31m# Clean up any trailing newlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U73') dtype('<U73') dtype('<U73')"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "xTraining1 = createNewTable(snpReduc['low'],xTraining)\n",
    "clf = clf.fit(xTraining1, yTraining1)\n",
    "treeee = open(path+'treeLayers.dot','w')\n",
    "dot_data = tree.export_graphviz(clf, out_file=treeee, \n",
    "                         feature_names=snpReduc['low'],  \n",
    "                         class_names=yTraining1,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=False)  \n",
    "graph = graphviz.Source(dot_data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "enc = OneHotEncoder(n_values =3) \n",
    "enc.fit(X) \n",
    "XX = enc.fit_transform(X)\n",
    "XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "enc.fit(xTraining) \n",
    "xTraining1 = enc.fit_transform(xTraining)\n",
    "xTraining1 = xTraining1.toarray()\n",
    "print(xTraining1.shape)\n",
    "\n",
    "enc.fit(xTest) \n",
    "xTest1 = enc.fit_transform(xTest)\n",
    "xTest1 = xTest1.toarray()\n",
    "print(xTest1.shape)\n",
    "    \n",
    "\n",
    "bern = BernoulliNB()\n",
    "bern.fit(xTraining1, yTraining1)\n",
    "yPredict6 = bern.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "\n",
    "\n",
    "writeResults2['all'] = r1\n",
    "    \n",
    "print()\n",
    "\n",
    "results = crossValidiation(XX, Y, k = 10,classifier = bern, continious = False)\n",
    "    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len snps'] = len(XX.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'bernoulli_all',writeResults)\n",
    "writeResultConf(path,'bernoulli_all',writeResults2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "enc = OneHotEncoder(n_values =3) \n",
    "enc.fit(X) \n",
    "XX = enc.fit_transform(X)\n",
    "XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "enc.fit(xTraining) \n",
    "xTraining1 = enc.fit_transform(xTraining)\n",
    "xTraining1 = xTraining1.toarray()\n",
    "print(xTraining1.shape)\n",
    "\n",
    "enc.fit(xTest) \n",
    "xTest1 = enc.fit_transform(xTest)\n",
    "xTest1 = xTest1.toarray()\n",
    "print(xTest1.shape)\n",
    "    \n",
    "\n",
    "bern = SVC(kernel='linear')\n",
    "bern.fit(xTraining1, yTraining1)\n",
    "yPredict6 = bern.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "   \n",
    "writeResults2['all'] = r1\n",
    "    \n",
    "print()\n",
    "\n",
    "results = crossValidiation(XX, Y, k = 10,classifier = bern, continious = False)\n",
    "    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len snps'] = len(XX.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'svm_all',writeResults)\n",
    "writeResultConf(path,'svm_all',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "enc = OneHotEncoder(n_values =3) \n",
    "enc.fit(X) \n",
    "XX = enc.fit_transform(X)\n",
    "XX = XX.toarray()\n",
    "print(XX.shape)\n",
    "\n",
    "enc.fit(xTraining) \n",
    "xTraining1 = enc.fit_transform(xTraining)\n",
    "xTraining1 = xTraining1.toarray()\n",
    "print(xTraining1.shape)\n",
    "\n",
    "enc.fit(xTest) \n",
    "xTest1 = enc.fit_transform(xTest)\n",
    "xTest1 = xTest1.toarray()\n",
    "print(xTest1.shape)\n",
    "    \n",
    "\n",
    "bern = linear_model.LogisticRegression()\n",
    "bern.fit(xTraining1, yTraining1)\n",
    "yPredict6 = bern.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "   \n",
    "writeResults2['all'] = r1\n",
    "\n",
    "print()\n",
    "\n",
    "results = crossValidiation(XX, Y, k = 10,classifier = bern, continious = False)\n",
    "    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len snps'] = len(XX.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'llr_all',writeResults)\n",
    "writeResultConf(path,'llr_all',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = {}\n",
    "writeResults2={}\n",
    "writeResults={}\n",
    "\n",
    "#enc = OneHotEncoder(n_values =3) \n",
    "#enc.fit(X) \n",
    "#XX = enc.fit_transform(X)\n",
    "#XX = XX.toarray()\n",
    "#print(XX.shape)\n",
    "\n",
    "#enc.fit(xTraining) \n",
    "#xTraining1 = enc.fit_transform(xTraining)\n",
    "#xTraining1 = xTraining1.toarray()\n",
    "#print(xTraining1.shape)\n",
    "\n",
    "#enc.fit(xTest) \n",
    "#xTest1 = enc.fit_transform(xTest)\n",
    "#xTest1 = xTest1.toarray()\n",
    "#print(xTest1.shape)\n",
    "    \n",
    "\n",
    "bern = tree.DecisionTreeClassifier()\n",
    "bern.fit(xTraining1, yTraining1)\n",
    "yPredict6 = bern.predict(xTest1)\n",
    "print(metrics.accuracy_score(yTest,yPredict6))\n",
    "print(metrics.confusion_matrix(yTest,yPredict6))\n",
    "error6 = mean_squared_error(yTest, yPredict6)\n",
    "print(\"error 6 = \",error6)\n",
    "RMSE6 = mean_squared_error(yTest,yPredict6)**0.5\n",
    "print(\"RMSE6 = \",RMSE6)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yTest,yPredict6)\n",
    "print(\"AUC = \", metrics.auc(fpr,tpr))\n",
    "print(\"recal = \",metrics.recall_score(yTest,yPredict6))\n",
    "print(\"precision = \",metrics.precision_score(yTest,yPredict6))\n",
    "print(\"f1Score = \",f1_score(yTest, yPredict6, average='binary'))\n",
    "\n",
    "r1['confu'] = metrics.confusion_matrix(yTest,yPredict6)\n",
    "r1['accu'] = metrics.accuracy_score(yTest,yPredict6)\n",
    "r1['auc'] = metrics.auc(fpr,tpr)\n",
    "r1['recal'] = metrics.recall_score(yTest,yPredict6)\n",
    "r1['precision'] = metrics.precision_score(yTest,yPredict6)\n",
    "r1['f1'] = f1_score(yTest, yPredict6, average='binary')\n",
    "   \n",
    "writeResults2['all'] = r1\n",
    "\n",
    "print()\n",
    "\n",
    "results = crossValidiation(XX, Y, k = 10,classifier = bern, continious = False)\n",
    "    \n",
    "print(\"accuracy = \",results['accuracy'])\n",
    "print(\"AUC = \", results['auc'])\n",
    "print(\"recal = \",results['recall'])\n",
    "print(\"precision = \",results['precision'])\n",
    "print(\"f1 = \",results['f1'])\n",
    "\n",
    "\n",
    "results['len snps'] = len(XX.T)\n",
    "writeResults['all'] = results\n",
    "    \n",
    "print()\n",
    "    \n",
    "    \n",
    "writeResult(path,'llr_all',writeResults)\n",
    "writeResultConf(path,'llr_all',writeResults2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
