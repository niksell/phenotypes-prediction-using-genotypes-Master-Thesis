{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libs\n",
    "import findspark\n",
    "findspark.init(\"/home/antonis/spark-2.3.0-bin-hadoop2.7\")\n",
    "\n",
    "import os.path\n",
    "import pandas\n",
    "import math\n",
    "import time\n",
    "\n",
    "from metrics.Correlation import Correlation\n",
    "from IO.Output import Output\n",
    "from IO.Input import Input\n",
    "from metrics.RSquare import RSquare\n",
    "from DataSet.Dataset import DataSet\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import countDistinct,avg,stddev\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                               OneHotEncoder , StringIndexer)\n",
    "import DataSet.SnpsSelection as s\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def writeCoef(path,snpsIds,sc,idToName,corr, name = None):\n",
    "        \n",
    "    if not name:\n",
    "        print(\"give a name to file\")\n",
    "        return\n",
    "        \n",
    "    p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ).txt \"  \n",
    "    \n",
    "    i=1\n",
    "    while os.path.exists(p):\n",
    "            \n",
    "        p = path + name  + \" ( \" + time.strftime(\"%d-%m-%Y\") + \" ) \" + '_' + str(i)+\".txt\"\n",
    "        i += 1\n",
    "        \n",
    "    snps = []\n",
    "    for i in range(len(snpsIds)):\n",
    "        s = snpsIds[i]\n",
    "        #snps.append(idToName[s])\n",
    "        snps.append(s)\n",
    "            \n",
    "    print(\"snpsIds = \",len(snpsIds))\n",
    "    print(\"idToName = \",len(idToName))\n",
    "        \n",
    "    write = open(p,'w')\n",
    "    write.write(\"len = \"+str(len(sc))+'\\n')\n",
    "    write.write('corr = '+str(corr)+'\\n')\n",
    "    for i in range(len(snps)):\n",
    "            \n",
    "        write.write(str(snps[i])+'\\t'+str(sc[i])+'\\n')\n",
    "            \n",
    "    write.close()\n",
    "\n",
    "\n",
    "def calcCoeff(path,coefs, columns,corr):\n",
    "    \n",
    "    ids = {}\n",
    "    ids['coef']={}\n",
    "   \n",
    "    print(\"before = \",len(set(coefs)))\n",
    "    #for i in range(len(coefs)):\n",
    "     #   coefs[i] = abs(coefs[i])\n",
    "\n",
    "    print(\"after = \",len(set(coefs)))\n",
    "\n",
    "    idToName = {}\n",
    "    nameToId = {}\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]] = []\n",
    "\n",
    "    for i in range(len(coefs)):\n",
    "        nameToId[coefs[i]].append(i)\n",
    "        idToName[i] = coefs[i]\n",
    "\n",
    "\n",
    "    ids['coef']['nameToId'] = nameToId\n",
    "    ids['coef']['idToName'] = idToName\n",
    "\n",
    "\n",
    "    sc = sorted(coefs,reverse=True)\n",
    "\n",
    "    top_30 = []\n",
    "\n",
    "    for i in range(30):\n",
    "\n",
    "        snp = ids['coef']['nameToId'][sc[i]][0]\n",
    "        ids['coef']['nameToId'][sc[i]].remove(snp)\n",
    "        top_30.append(columns[snp])\n",
    "     #   top_30.append(snp)\n",
    "\n",
    "    #snpReduc['low'] = top_30\n",
    "    writeCoef(path,top_30,sc,columns,corr, name = 'mycutoffabs')\n",
    "    \n",
    "    \n",
    "def showMetrics(c,value=1):\n",
    "    \n",
    "    predictionAndLabels = c.map(lambda lp: (lp.prediction, float(lp.label)))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    print(\"confusion matrix = \", metrics.confusionMatrix().toArray())\n",
    "\n",
    "    print(\"accuracy = \", metrics.accuracy)\n",
    "    print(\"recal = \", metrics.recall(value))\n",
    "    print(\"precision = \", metrics.precision(value))\n",
    "    print(\"f1 = \", metrics.fMeasure(1.0))\n",
    "    \n",
    "    \n",
    "def showMyMetric(results,v1 = 1,v2 = 0):\n",
    "    \n",
    "    if v1 == v2:\n",
    "        print(\"wrong values!!!v1 is the same with v2!!!!\")\n",
    "       \n",
    "    \n",
    "    r = results.rdd\n",
    "    r3 = r.collect()\n",
    "\n",
    "    same0 = 0\n",
    "    same1 = 0\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    sumall = 0\n",
    "    for i in r3:\n",
    "\n",
    "        if i[v1] == 0:\n",
    "            sum0 += 1\n",
    "            if i[v2] == 0:\n",
    "                same0 += 1\n",
    "        elif i[v1] == 1:\n",
    "            sum1 += 1\n",
    "            if i[v2] == 1:\n",
    "                same1 += 1\n",
    "        sumall += 1\n",
    "\n",
    "    print('sum0 = ', sum0)\n",
    "    print('sum1 = ', sum1)\n",
    "    print('same0 = ', same0)\n",
    "    print('same1 = ', same1)\n",
    "    print('all = ', sumall)\n",
    "    print('all2 = ', sum0+sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = (SparkConf()\n",
    "    .set(\"spark.driver.maxResultSize\", \"20g\")\n",
    "    .set('spark_executor_cores',\"3\")\n",
    "    .set('spark.graphx.pregel.checkpointInterval','-1')\n",
    "    .set('spark.network.timeout','100000000')\n",
    "    .set('spark.executor.heartbeatInterval','10000000'))\n",
    "\n",
    "#spark = SparkSession.builder.appName('melanoma').getOrCreate()\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/'\n",
    "\n",
    "#pathSnp = '/media/antonis/red/newSet/maf/maf = 0.05/assoc/pvalue = 0.001/snpCodeTest.csv'\n",
    "#pathSnp = '/media/antonis/red/newSet/maf/maf = 0.05/assoc/pvalue = 0.01/snp2.txt'\n",
    "#pathSnp = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/snp2.txt'\n",
    "pathSnp = '/media/antonis/red/newdata/maf = 0.05/pvalue = 0.001/snpCodeTest1.csv'\n",
    "\n",
    "#pathSnp = '/media/antonis/Antonis_Moulopoulos/newSet/pvalue = 0.001/snp1.txt'\n",
    "#pathSnp = '/media/antonis/Antonis_Moulopoulos/newdata/maf = 0.05/pvalue = 0.001/snp2.txt'\n",
    "\n",
    "\n",
    "data = spark.read.option(\"maxColumns\", 80000).csv(pathSnp,inferSchema=True,header=True)\n",
    "data=data.withColumnRenamed('TARGET','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data columns =  12144\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "print(\"data columns = \",len(data.columns))\n",
    "\n",
    "features = []\n",
    "for i in data.columns:\n",
    "    if 'rs' not in i and i !='label':\n",
    "        features.append(i)\n",
    "print(len(features))\n",
    "#print((features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.select('patients','label').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns =  12003\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "d = data.drop('patients')\n",
    "for i in features:\n",
    "    d = d.drop(i)\n",
    "print(\"columns = \",len(d.columns))\n",
    "\n",
    "train_data,test_data = d.randomSplit([0.9,0.1],seed=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Label1 to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label1 =  1924\n",
      "l1 =  1924.0\n",
      "label0 =  215997\n",
      "x =  0.00890753112311745\n",
      "label0 =  215997\n",
      "label1 =  1924\n",
      "l1 =  1924.0\n",
      "train =  2920\n",
      "test =  239256\n",
      "all =  242176\n",
      "d =  242176\n"
     ]
    }
   ],
   "source": [
    "label1 = train_data.filter(\"label == 1\").count()\n",
    "label0 = train_data.filter(\"label == 0\").count()\n",
    "\n",
    "\n",
    "l1 = (label1/2) + ((label1/2))\n",
    "\n",
    "x = (l1 * 100) / label0\n",
    "\n",
    "\n",
    "x = x / 100\n",
    "\n",
    "print(\"label1 = \", label1)\n",
    "print(\"l1 = \",l1)\n",
    "print(\"label0 = \", label0)\n",
    "print(\"x = \", x)\n",
    "\n",
    "t0 = train_data.filter('label == 0')\n",
    "t1 = train_data.filter('label == 1')\n",
    "\n",
    "train0,t2 = t0.randomSplit([x,1-x],seed = 11)\n",
    "train1,t3 = t1.randomSplit([0.5,0.5],seed = 11)\n",
    "\n",
    "train_data = train0.union(train1)\n",
    "\n",
    "t2 = t2.union(t3)\n",
    "test_data = test_data.union(t2)\n",
    "\n",
    "t0 = train_data.count()\n",
    "t1 = test_data.count()\n",
    "\n",
    "print(\"label0 = \",label0)\n",
    "print('label1 = ', label1)\n",
    "print(\"l1 = \",l1)\n",
    "print('len test label1 = ',train_data.filter('label==1').count())\n",
    "print('len test label0 = ',train_data.filter('label==0').count())\n",
    "print('train = ', t0)\n",
    "print('test = ', t1)\n",
    "print('all = ', t0 + t1)\n",
    "print('d = ',d.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnBalanced Label1 to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = train_data.filter(\"label == 1\").count()\n",
    "label0 = train_data.filter(\"label == 0\").count()\n",
    "\n",
    "\n",
    "l1 = (label1/2) + ((label1/2) * 0.5)\n",
    "\n",
    "x = (l1 * 100) / label0\n",
    "\n",
    "\n",
    "x = x / 100\n",
    "\n",
    "print(\"label1 = \", label1)\n",
    "print(\"l1 = \",l1)\n",
    "print(\"label0 = \", label0)\n",
    "print(\"x = \", x)\n",
    "\n",
    "t0 = train_data.filter('label == 0')\n",
    "\n",
    "train0,t2 = t0.randomSplit([x,1-x],seed = 11)\n",
    "train1 = train_data.filter(\"label == 1\")\n",
    "\n",
    "train_data = train0.union(train1)\n",
    "test_data = test_data.union(t2)\n",
    "\n",
    "t0 = train_data.count()\n",
    "t1 = test_data.count()\n",
    "\n",
    "print(\"label0 = \",label0)\n",
    "print('label1 = ', label1)\n",
    "print(\"l1 = \",l1)\n",
    "print('train = ', t0)\n",
    "print('test = ', t1)\n",
    "print('all = ', t0 + t1)\n",
    "print('d = ',d.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dokimh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "li = len(d.columns)\n",
    "\n",
    "input_data = train_data.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "train0 = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "final_data1 = train0.select('features')\n",
    "corr = Correlation.corr(final_data1, \"features\")\n",
    "corr = corr.head()[0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  8003\n",
      "len snpsRed =  8003\n"
     ]
    }
   ],
   "source": [
    "snpsRed = []\n",
    "snpsRed = s.lowCorrelation(corr, threshold=0.2, up=100, down=99)#oso megalytero threshold toso perissotero omoia einai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len features1 =  12002\n",
      "len snpsRed1 =  8004\n",
      "len features2 =  3999\n",
      "columns dok train =  8004\n",
      "columns dok test =  8004\n",
      "first column =  rs143167631\n",
      "last column =  label\n",
      "test first column =  rs143167631\n",
      "test last column =  label\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = []\n",
    "\n",
    "for i in range(0,len(d.columns)):\n",
    "    if 'rs' in d.columns[i] and d.columns[i] !='label':\n",
    "        features.append(d.columns[i])\n",
    "\n",
    "print(\"len features1 = \",len(features))\n",
    "\n",
    "snpsRed1 = []\n",
    "for i in snpsRed:\n",
    "    snpsRed1.append(features[i])\n",
    "\n",
    "snpsRed1.append('label')\n",
    "\n",
    "print('len snpsRed1 = ', len(snpsRed1))\n",
    "    \n",
    "features = []\n",
    "for i in range(0,len(d.columns)):\n",
    "    if d.columns[i] not in snpsRed1:\n",
    "        features.append(d.columns[i])\n",
    "print(\"len features2 = \",len(features))\n",
    "\n",
    "dok_train = train_data.drop(*features)\n",
    "dok_test = test_data.drop(*features)\n",
    "\n",
    "print(\"columns dok train = \",len(dok_train.columns))\n",
    "print(\"columns dok test = \",len(dok_test.columns))\n",
    "li = len(dok_train.columns)\n",
    "\n",
    "print('first column = ', dok_train.columns[0])\n",
    "print('last column = ', dok_train.columns[li - 1])\n",
    "\n",
    "print('test first column = ', dok_test.columns[0])\n",
    "print('test last column = ', dok_test.columns[li - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_data = test_data.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\\ntest = spark.createDataFrame(input_data, [\"label\", \"features\"])\\n\\ninput_data = train_data.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\\ntrain = spark.createDataFrame(input_data, [\"label\", \"features\"])'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = len(dok_train.columns)\n",
    "#li = len(test_data.columns)\n",
    "\n",
    "\n",
    "input_data = dok_test.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "test = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "input_data = dok_train.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "train = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "'''input_data = test_data.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "test = spark.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "\n",
    "input_data = train_data.rdd.map(lambda x: (x[li-1], DenseVector(x[:li-1])))\n",
    "train = spark.createDataFrame(input_data, [\"label\", \"features\"])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# telos dokimhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train =  (8003,)\n",
      "test =  (8003,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train = \",train.head()[1].toArray().shape)\n",
    "print(\"test = \",test.head()[1].toArray().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features',labelCol='label',maxIter=10)\n",
    "lr_model = log_reg.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.7880411087558726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.7909133853963526'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = lr_model.transform(test)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "print(\"auc = \",AUC)\n",
    "'''0.7909133853963526'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pipeline = Pipeline(stages=[log_reg])\\nmodelEvaluator=RegressionEvaluator(predictionCol='prediction', labelCol='label',metricName='mse')\\nparamGrid = ParamGridBuilder().build()\\n\\ncrossval = CrossValidator(estimator=log_reg,\\n                          estimatorParamMaps=paramGrid,\\n                          evaluator=modelEvaluator,\\n                          numFolds=4)\\n\\ncvModel = crossval.fit(train)\\ncross_results = cvModel.transform(test)\\nresults = cross_results.select('prediction','label')\\n#results.show(10)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Param for metric name in evaluation. Supports: - \"rmse\" (default): root mean squared error - \n",
    "\"mse\": mean squared error - \"r2\": R^2^ metric - \"mae\": mean absolute error metricName='mae' '''\n",
    "\n",
    "'''pipeline = Pipeline(stages=[log_reg])\n",
    "modelEvaluator=RegressionEvaluator(predictionCol='prediction', labelCol='label',metricName='mse')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=log_reg,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Param for metric name in evaluation. Supports: - \"rmse\" (default): root mean squared error - \n",
    "\"mse\": mean squared error - \"r2\": R^2^ metric - \"mae\": mean absolute error metricName='mae' '''\n",
    "\n",
    "pipeline = Pipeline(stages=[log_reg])\n",
    "modelEvaluator=MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',metricName='accuracy')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=log_reg,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "\n",
    "\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgResults = cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(d.columns))\n",
    "#print(d.columns[len(d.columns)-1])\n",
    "calcCoeff(path,lr_model.coefficientMatrix.toArray()[0],d.columns,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainingSummary = cvModel.bestModel.stages[-1].summary\\ntrainingSummary.roc.show()\\nprint(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''trainingSummary = cvModel.bestModel.stages[-1].summary\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix =  [[210082.  27973.]\n",
      " [   368.    833.]]\n",
      "accuracy =  0.8815452904002408\n",
      "recal =  0.6935886761032473\n",
      "precision =  0.02891758661389988\n",
      "f1 =  0.055520378578331725\n",
      "sum0 =  238055\n",
      "sum1 =  1201\n",
      "same0 =  210082\n",
      "same1 =  833\n",
      "all =  239256\n",
      "all2 =  239256\n"
     ]
    }
   ],
   "source": [
    "showMetrics(cross_results.rdd,value=1)\n",
    "showMyMetric(results,v1 = 1,v2 = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol='features',labelCol='label', numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=50, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)\n",
    "rf_model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rf_model.transform(test)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelEvaluator=RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showMetrics(cross_results.rdd,value=1)\n",
    "showMyMetric(results,v1 = 1,v2 = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVCModel' object has no attribute 'setThreshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1999cc4909b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlsvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlsvcModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlsvcModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVCModel' object has no attribute 'setThreshold'"
     ]
    }
   ],
   "source": [
    "#lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "lsvc = LinearSVC(featuresCol='features',labelCol='label',maxIter=10)\n",
    "lsvcModel = lsvc.fit(train)\n",
    "lsvc.setThreshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = lsvcModel.transform(test)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',metricName='accuracy')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lsvc,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "\n",
    "\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix =  [[238055.      0.]\n",
      " [  1201.      0.]]\n",
      "accuracy =  0.9949802721770823\n",
      "recal =  0.0\n",
      "precision =  0.0\n",
      "f1 =  0.0\n",
      "sum0 =  238055\n",
      "sum1 =  1201\n",
      "same0 =  238055\n",
      "same1 =  0\n",
      "all =  239256\n",
      "all2 =  239256\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVCModel' object has no attribute 'clearThreshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b8d283d63c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshowMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshowMyMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlsvcModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclearThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVCModel' object has no attribute 'clearThreshold'"
     ]
    }
   ],
   "source": [
    "showMetrics(cross_results.rdd,value=1)\n",
    "showMyMetric(results,v1 = 1,v2 = 0)\n",
    "lsvc.clearThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcCoeff(path,lr_model.coefficientMatrix.toArray()[0],d.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len test label1 =  956\n",
      "len test label0 =  1964\n"
     ]
    }
   ],
   "source": [
    "'''print('len test label1 = ',train_data.filter('label==1').count())\n",
    "print('len test label0 = ',train_data.filter('label==0').count())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(predictionCol='prediction', labelCol='label',smoothing=0.2)\n",
    "nbg = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166498967634439"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nbg.transform(test)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',metricName='accuracy')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=nb,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "\n",
    "\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix =  [[177083.  60972.]\n",
      " [   373.    828.]]\n",
      "accuracy =  0.7436009964222423\n",
      "recal =  0.6894254787676936\n",
      "precision =  0.013398058252427184\n",
      "f1 =  0.026285297058776844\n",
      "sum0 =  238055\n",
      "sum1 =  1201\n",
      "same0 =  177083\n",
      "same1 =  828\n",
      "all =  239256\n",
      "all2 =  239256\n"
     ]
    }
   ],
   "source": [
    "showMetrics(cross_results.rdd,value=1)\n",
    "showMyMetric(results,v1 = 1,v2 = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-44979b70d87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtreeD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreeD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#tree = treeD.fit(train0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1160\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "'''features = []\n",
    "\n",
    "for i in dok_train.columns:\n",
    "    features.append(i)\n",
    "\n",
    "assempler = VectorAssembler(inputCols=features,outputCol='features')\n",
    "output = assempler.transform(data)\n",
    "\n",
    "tr = output.select('label','features').rdd.map(lambda row: LabeledPoint(row.label, row.features))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "treeD = DecisionTree.trainClassifier(tr, numClasses=2, categoricalFeaturesInfo={}, \n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)'''\n",
    "\n",
    "treeD = DecisionTreeClassifier(predictionCol='prediction', labelCol='label')\n",
    "tree = treeD.fit(train)\n",
    "\n",
    "#tree = treeD.fit(train0)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tree.transform(test)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelEvaluator=MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',metricName='accuracy')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=treeD,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "\n",
    "\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showMetrics(cross_results.rdd,value=1)\n",
    "showMyMetric(results,v1 = 1,v2 = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFile = path+'treeRules.txt'\n",
    "f = open(modelFile,\"w\") \n",
    "f.write(tree.toDebugString)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Trees (GBTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGBT = GradientBoostedTrees.trainClassifier(train,categoricalFeaturesInfo={}, numIterations=10)\n",
    "\n",
    "#modelGBT = GradientBoostedTrees(predictionCol='prediction', labelCol='label')\n",
    "gbt = treeD.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gbt.transform(test)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluate = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')\n",
    "AUC = evaluate.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator=RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=4)\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "cross_results = cvModel.transform(test)\n",
    "results = cross_results.select('prediction','label')\n",
    "#results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showMetrics(cross_results.rdd,value=1)\n",
    "showMyMetric(results,v1 = 1,v2 = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
